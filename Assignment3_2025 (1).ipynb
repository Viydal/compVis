{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMOJD0_jdzzg"
      },
      "source": [
        "## Computer vision 2025 Assignment 3\n",
        "## Deep Learning for Perception Tasks\n",
        "\n",
        "This assignment contains 2 questions. The first question probes understanding of deep learning for classification. The second question requires you to write a short description of a Computer Vision method. You wil need to submit two separate PDF files, one for each question.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64]) torch.int64\n",
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Set up\n",
        "import numpy as np # This is for mathematical operations\n",
        "\n",
        "# this is used in plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pylab as pl\n",
        "from IPython import display\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%reload_ext autoreload\n",
        "\n",
        "#### Tutorial Code\n",
        "####PyTorch has two primitives to work with data: torch.utils.data.DataLoader and torch.utils.data.Dataset.\n",
        "#####Dataset stores samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset.\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Download training data from open datasets.\n",
        "##Every TorchVision Dataset includes two arguments:\n",
        "##transform and target_transform to modify the samples and labels respectively.\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    break\n",
        "\n",
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "       )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)\n",
        "\n",
        "###Define the loss function and the optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "            \n",
        "    average_loss = total_loss / len(dataloader)\n",
        "    return average_loss\n",
        "            \n",
        "##Define a test function\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Question 1: A simple classifier, 20 marks (60% of the assignment)\n",
        "\n",
        "For this exercise, we provide demo code showing how to train a network on a small dataset called Fashion-MNIST. Please run through the code \"tutorial-style\" to get a sense of what it is doing. Then use the code alongside lecture notes and other resources to understand how to use pytorch libraries to implement, train and use a neural network.\n",
        "\n",
        "For the Fashion-MNIST dataset the labels from 0-9 correspond to various clothing classes so you might find it convenient to create a python list as follows:\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "You will need to answer various questions about the system, how it operates, the results of experiments with it and make modifications to it yourself. You can change the training scheme and the network structure.\n",
        "\n",
        "Organize your own text and code cell to show the answer of each question below.\n",
        "\n",
        "Detailed requirements:\n",
        "\n",
        "### Q1.1 (1 point)\n",
        "\n",
        "Extract 3 images of different types of clothing from the training dataset, print out the size/shape of the training images, and display the three with their corresponding labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image shape: torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "images = []\n",
        "for image, label in training_data:\n",
        "  images.append((image, label))\n",
        "  \n",
        "  if len(images) == 3:\n",
        "    break\n",
        "  \n",
        "print(f\"image shape: {images[0][0].shape}\")\n",
        "\n",
        "for i, (image, label) in enumerate(images):\n",
        "  plt.subplot(1, 3, i+1)\n",
        "  plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "  plt.title(f\"{class_names[label]}\")\n",
        "  plt.axis(\"off\")\n",
        "  plt.show\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Q1.2 (2 point) \n",
        "\n",
        "Run the training code for 10 epochs, for different values of the learning rate. Fill in the table below and plot the loss curves for each experiment:\n",
        "\n",
        "|Lr|Accuracy|\n",
        "|---|---|\n",
        "|1   | 19.9%    |\n",
        "|0.1|  87.3%        |\n",
        "|0.01|  83.3%      |\n",
        "|0.001  |71.2%      |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training with learning rate: 1\n",
            "\n",
            "\n",
            "Epoch 1\n",
            "loss: 2.307425  [    0/60000]\n",
            "loss: 2.125997  [ 6400/60000]\n",
            "loss: 2.317875  [12800/60000]\n",
            "loss: 1.911886  [19200/60000]\n",
            "loss: 1.925378  [25600/60000]\n",
            "loss: 1.811856  [32000/60000]\n",
            "loss: 1.482233  [38400/60000]\n",
            "loss: 1.684308  [44800/60000]\n",
            "loss: 1.685725  [51200/60000]\n",
            "loss: 1.694344  [57600/60000]\n",
            "\n",
            "Epoch 2\n",
            "loss: 1.765984  [    0/60000]\n",
            "loss: 1.533358  [ 6400/60000]\n",
            "loss: 1.754290  [12800/60000]\n",
            "loss: 1.817563  [19200/60000]\n",
            "loss: 1.688511  [25600/60000]\n",
            "loss: 1.756233  [32000/60000]\n",
            "loss: 1.699882  [38400/60000]\n",
            "loss: 1.681558  [44800/60000]\n",
            "loss: 1.716398  [51200/60000]\n",
            "loss: 1.681877  [57600/60000]\n",
            "\n",
            "Epoch 3\n",
            "loss: 1.863034  [    0/60000]\n",
            "loss: 1.765268  [ 6400/60000]\n",
            "loss: 1.822227  [12800/60000]\n",
            "loss: 1.793330  [19200/60000]\n",
            "loss: 1.591726  [25600/60000]\n",
            "loss: 1.737462  [32000/60000]\n",
            "loss: 1.567035  [38400/60000]\n",
            "loss: 1.758349  [44800/60000]\n",
            "loss: 1.721022  [51200/60000]\n",
            "loss: 1.686075  [57600/60000]\n",
            "\n",
            "Epoch 4\n",
            "loss: 1.826392  [    0/60000]\n",
            "loss: 1.737746  [ 6400/60000]\n",
            "loss: 1.745176  [12800/60000]\n",
            "loss: 1.748701  [19200/60000]\n",
            "loss: 1.530609  [25600/60000]\n",
            "loss: 1.874058  [32000/60000]\n",
            "loss: 1.656903  [38400/60000]\n",
            "loss: 1.674448  [44800/60000]\n",
            "loss: 1.704554  [51200/60000]\n",
            "loss: 1.677398  [57600/60000]\n",
            "\n",
            "Epoch 5\n",
            "loss: 1.661851  [    0/60000]\n",
            "loss: 1.688313  [ 6400/60000]\n",
            "loss: 1.635396  [12800/60000]\n",
            "loss: 1.391969  [19200/60000]\n",
            "loss: 1.940734  [25600/60000]\n",
            "loss: 1.710073  [32000/60000]\n",
            "loss: 1.685581  [38400/60000]\n",
            "loss: 1.673612  [44800/60000]\n",
            "loss: 1.700052  [51200/60000]\n",
            "loss: 1.665436  [57600/60000]\n",
            "\n",
            "Epoch 6\n",
            "loss: 1.760562  [    0/60000]\n",
            "loss: 1.628083  [ 6400/60000]\n",
            "loss: 1.726272  [12800/60000]\n",
            "loss: 1.780557  [19200/60000]\n",
            "loss: 1.725022  [25600/60000]\n",
            "loss: 1.743574  [32000/60000]\n",
            "loss: 1.651757  [38400/60000]\n",
            "loss: 1.691147  [44800/60000]\n",
            "loss: 1.683236  [51200/60000]\n",
            "loss: 1.683057  [57600/60000]\n",
            "\n",
            "Epoch 7\n",
            "loss: 1.633512  [    0/60000]\n",
            "loss: 1.575679  [ 6400/60000]\n",
            "loss: 1.643642  [12800/60000]\n",
            "loss: 1.612609  [19200/60000]\n",
            "loss: 1.566523  [25600/60000]\n",
            "loss: 1.723507  [32000/60000]\n",
            "loss: 1.709836  [38400/60000]\n",
            "loss: 1.690607  [44800/60000]\n",
            "loss: 1.706280  [51200/60000]\n",
            "loss: 1.629856  [57600/60000]\n",
            "\n",
            "Epoch 8\n",
            "loss: 1.688520  [    0/60000]\n",
            "loss: 1.801640  [ 6400/60000]\n",
            "loss: 1.715859  [12800/60000]\n",
            "loss: 1.640812  [19200/60000]\n",
            "loss: 1.641603  [25600/60000]\n",
            "loss: 1.696908  [32000/60000]\n",
            "loss: 1.578460  [38400/60000]\n",
            "loss: 2.064394  [44800/60000]\n",
            "loss: 1.664732  [51200/60000]\n",
            "loss: 1.678522  [57600/60000]\n",
            "\n",
            "Epoch 9\n",
            "loss: 1.676506  [    0/60000]\n",
            "loss: 1.688596  [ 6400/60000]\n",
            "loss: 1.738376  [12800/60000]\n",
            "loss: 1.788195  [19200/60000]\n",
            "loss: 1.575119  [25600/60000]\n",
            "loss: 1.725508  [32000/60000]\n",
            "loss: 1.651812  [38400/60000]\n",
            "loss: 1.672288  [44800/60000]\n",
            "loss: 1.679380  [51200/60000]\n",
            "loss: 1.714409  [57600/60000]\n",
            "\n",
            "Epoch 10\n",
            "loss: 1.879589  [    0/60000]\n",
            "loss: 1.757544  [ 6400/60000]\n",
            "loss: 1.734106  [12800/60000]\n",
            "loss: 1.734366  [19200/60000]\n",
            "loss: 1.574655  [25600/60000]\n",
            "loss: 1.724886  [32000/60000]\n",
            "loss: 1.651037  [38400/60000]\n",
            "loss: 1.673583  [44800/60000]\n",
            "loss: 1.676306  [51200/60000]\n",
            "loss: 1.680702  [57600/60000]\n",
            "Final test:\n",
            "Test Error: \n",
            " Accuracy: 19.9%, Avg loss: 1.712990 \n",
            "\n",
            "\n",
            "Training with learning rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 1\n",
            "loss: 2.307525  [    0/60000]\n",
            "loss: 0.898186  [ 6400/60000]\n",
            "loss: 0.580136  [12800/60000]\n",
            "loss: 0.711017  [19200/60000]\n",
            "loss: 0.605779  [25600/60000]\n",
            "loss: 0.518019  [32000/60000]\n",
            "loss: 0.546354  [38400/60000]\n",
            "loss: 0.585683  [44800/60000]\n",
            "loss: 0.612034  [51200/60000]\n",
            "loss: 0.465268  [57600/60000]\n",
            "\n",
            "Epoch 2\n",
            "loss: 0.428890  [    0/60000]\n",
            "loss: 0.430968  [ 6400/60000]\n",
            "loss: 0.391224  [12800/60000]\n",
            "loss: 0.430049  [19200/60000]\n",
            "loss: 0.413921  [25600/60000]\n",
            "loss: 0.451378  [32000/60000]\n",
            "loss: 0.410384  [38400/60000]\n",
            "loss: 0.493681  [44800/60000]\n",
            "loss: 0.509097  [51200/60000]\n",
            "loss: 0.433109  [57600/60000]\n",
            "\n",
            "Epoch 3\n",
            "loss: 0.328963  [    0/60000]\n",
            "loss: 0.360942  [ 6400/60000]\n",
            "loss: 0.319941  [12800/60000]\n",
            "loss: 0.353324  [19200/60000]\n",
            "loss: 0.342214  [25600/60000]\n",
            "loss: 0.421275  [32000/60000]\n",
            "loss: 0.357223  [38400/60000]\n",
            "loss: 0.446340  [44800/60000]\n",
            "loss: 0.451557  [51200/60000]\n",
            "loss: 0.402541  [57600/60000]\n",
            "\n",
            "Epoch 4\n",
            "loss: 0.278557  [    0/60000]\n",
            "loss: 0.330394  [ 6400/60000]\n",
            "loss: 0.267685  [12800/60000]\n",
            "loss: 0.316389  [19200/60000]\n",
            "loss: 0.317699  [25600/60000]\n",
            "loss: 0.407740  [32000/60000]\n",
            "loss: 0.332024  [38400/60000]\n",
            "loss: 0.418320  [44800/60000]\n",
            "loss: 0.412611  [51200/60000]\n",
            "loss: 0.385610  [57600/60000]\n",
            "\n",
            "Epoch 5\n",
            "loss: 0.246217  [    0/60000]\n",
            "loss: 0.311399  [ 6400/60000]\n",
            "loss: 0.232552  [12800/60000]\n",
            "loss: 0.289000  [19200/60000]\n",
            "loss: 0.313095  [25600/60000]\n",
            "loss: 0.389116  [32000/60000]\n",
            "loss: 0.311095  [38400/60000]\n",
            "loss: 0.381743  [44800/60000]\n",
            "loss: 0.384524  [51200/60000]\n",
            "loss: 0.370171  [57600/60000]\n",
            "\n",
            "Epoch 6\n",
            "loss: 0.224079  [    0/60000]\n",
            "loss: 0.295442  [ 6400/60000]\n",
            "loss: 0.215910  [12800/60000]\n",
            "loss: 0.273371  [19200/60000]\n",
            "loss: 0.297774  [25600/60000]\n",
            "loss: 0.377320  [32000/60000]\n",
            "loss: 0.285702  [38400/60000]\n",
            "loss: 0.347433  [44800/60000]\n",
            "loss: 0.357737  [51200/60000]\n",
            "loss: 0.371873  [57600/60000]\n",
            "\n",
            "Epoch 7\n",
            "loss: 0.197364  [    0/60000]\n",
            "loss: 0.285361  [ 6400/60000]\n",
            "loss: 0.204136  [12800/60000]\n",
            "loss: 0.256781  [19200/60000]\n",
            "loss: 0.297257  [25600/60000]\n",
            "loss: 0.373694  [32000/60000]\n",
            "loss: 0.272877  [38400/60000]\n",
            "loss: 0.321400  [44800/60000]\n",
            "loss: 0.338875  [51200/60000]\n",
            "loss: 0.362165  [57600/60000]\n",
            "\n",
            "Epoch 8\n",
            "loss: 0.174545  [    0/60000]\n",
            "loss: 0.282783  [ 6400/60000]\n",
            "loss: 0.187125  [12800/60000]\n",
            "loss: 0.244242  [19200/60000]\n",
            "loss: 0.301147  [25600/60000]\n",
            "loss: 0.366156  [32000/60000]\n",
            "loss: 0.256735  [38400/60000]\n",
            "loss: 0.302191  [44800/60000]\n",
            "loss: 0.316200  [51200/60000]\n",
            "loss: 0.351225  [57600/60000]\n",
            "\n",
            "Epoch 9\n",
            "loss: 0.160989  [    0/60000]\n",
            "loss: 0.269887  [ 6400/60000]\n",
            "loss: 0.179688  [12800/60000]\n",
            "loss: 0.229479  [19200/60000]\n",
            "loss: 0.298408  [25600/60000]\n",
            "loss: 0.355790  [32000/60000]\n",
            "loss: 0.244901  [38400/60000]\n",
            "loss: 0.278629  [44800/60000]\n",
            "loss: 0.312428  [51200/60000]\n",
            "loss: 0.342967  [57600/60000]\n",
            "\n",
            "Epoch 10\n",
            "loss: 0.152600  [    0/60000]\n",
            "loss: 0.251792  [ 6400/60000]\n",
            "loss: 0.165777  [12800/60000]\n",
            "loss: 0.224156  [19200/60000]\n",
            "loss: 0.295929  [25600/60000]\n",
            "loss: 0.350203  [32000/60000]\n",
            "loss: 0.234923  [38400/60000]\n",
            "loss: 0.272296  [44800/60000]\n",
            "loss: 0.302093  [51200/60000]\n",
            "loss: 0.325411  [57600/60000]\n",
            "Final test:\n",
            "Test Error: \n",
            " Accuracy: 87.3%, Avg loss: 0.349463 \n",
            "\n",
            "\n",
            "Training with learning rate: 0.01\n",
            "\n",
            "\n",
            "Epoch 1\n",
            "loss: 2.309251  [    0/60000]\n",
            "loss: 2.166468  [ 6400/60000]\n",
            "loss: 1.802468  [12800/60000]\n",
            "loss: 1.509323  [19200/60000]\n",
            "loss: 1.148697  [25600/60000]\n",
            "loss: 1.061609  [32000/60000]\n",
            "loss: 1.016017  [38400/60000]\n",
            "loss: 0.874547  [44800/60000]\n",
            "loss: 0.870073  [51200/60000]\n",
            "loss: 0.817856  [57600/60000]\n",
            "\n",
            "Epoch 2\n",
            "loss: 0.805761  [    0/60000]\n",
            "loss: 0.868168  [ 6400/60000]\n",
            "loss: 0.601358  [12800/60000]\n",
            "loss: 0.777296  [19200/60000]\n",
            "loss: 0.659874  [25600/60000]\n",
            "loss: 0.653501  [32000/60000]\n",
            "loss: 0.726059  [38400/60000]\n",
            "loss: 0.684352  [44800/60000]\n",
            "loss: 0.697934  [51200/60000]\n",
            "loss: 0.639242  [57600/60000]\n",
            "\n",
            "Epoch 3\n",
            "loss: 0.571557  [    0/60000]\n",
            "loss: 0.667435  [ 6400/60000]\n",
            "loss: 0.452222  [12800/60000]\n",
            "loss: 0.654999  [19200/60000]\n",
            "loss: 0.570743  [25600/60000]\n",
            "loss: 0.576262  [32000/60000]\n",
            "loss: 0.604163  [38400/60000]\n",
            "loss: 0.640867  [44800/60000]\n",
            "loss: 0.667224  [51200/60000]\n",
            "loss: 0.547044  [57600/60000]\n",
            "\n",
            "Epoch 4\n",
            "loss: 0.480455  [    0/60000]\n",
            "loss: 0.577472  [ 6400/60000]\n",
            "loss: 0.395178  [12800/60000]\n",
            "loss: 0.591481  [19200/60000]\n",
            "loss: 0.514800  [25600/60000]\n",
            "loss: 0.537548  [32000/60000]\n",
            "loss: 0.546047  [38400/60000]\n",
            "loss: 0.643091  [44800/60000]\n",
            "loss: 0.651732  [51200/60000]\n",
            "loss: 0.486947  [57600/60000]\n",
            "\n",
            "Epoch 5\n",
            "loss: 0.424830  [    0/60000]\n",
            "loss: 0.532811  [ 6400/60000]\n",
            "loss: 0.363284  [12800/60000]\n",
            "loss: 0.551211  [19200/60000]\n",
            "loss: 0.470407  [25600/60000]\n",
            "loss: 0.507100  [32000/60000]\n",
            "loss: 0.513691  [38400/60000]\n",
            "loss: 0.642162  [44800/60000]\n",
            "loss: 0.629456  [51200/60000]\n",
            "loss: 0.450935  [57600/60000]\n",
            "\n",
            "Epoch 6\n",
            "loss: 0.385051  [    0/60000]\n",
            "loss: 0.505566  [ 6400/60000]\n",
            "loss: 0.340135  [12800/60000]\n",
            "loss: 0.524125  [19200/60000]\n",
            "loss: 0.440343  [25600/60000]\n",
            "loss: 0.482579  [32000/60000]\n",
            "loss: 0.491169  [38400/60000]\n",
            "loss: 0.630934  [44800/60000]\n",
            "loss: 0.606221  [51200/60000]\n",
            "loss: 0.431972  [57600/60000]\n",
            "\n",
            "Epoch 7\n",
            "loss: 0.353217  [    0/60000]\n",
            "loss: 0.485014  [ 6400/60000]\n",
            "loss: 0.321114  [12800/60000]\n",
            "loss: 0.506331  [19200/60000]\n",
            "loss: 0.419775  [25600/60000]\n",
            "loss: 0.465113  [32000/60000]\n",
            "loss: 0.474188  [38400/60000]\n",
            "loss: 0.616029  [44800/60000]\n",
            "loss: 0.585363  [51200/60000]\n",
            "loss: 0.420392  [57600/60000]\n",
            "\n",
            "Epoch 8\n",
            "loss: 0.329751  [    0/60000]\n",
            "loss: 0.468087  [ 6400/60000]\n",
            "loss: 0.305892  [12800/60000]\n",
            "loss: 0.493483  [19200/60000]\n",
            "loss: 0.403991  [25600/60000]\n",
            "loss: 0.451397  [32000/60000]\n",
            "loss: 0.459840  [38400/60000]\n",
            "loss: 0.600736  [44800/60000]\n",
            "loss: 0.568554  [51200/60000]\n",
            "loss: 0.413440  [57600/60000]\n",
            "\n",
            "Epoch 9\n",
            "loss: 0.311994  [    0/60000]\n",
            "loss: 0.452340  [ 6400/60000]\n",
            "loss: 0.293624  [12800/60000]\n",
            "loss: 0.482744  [19200/60000]\n",
            "loss: 0.388841  [25600/60000]\n",
            "loss: 0.440012  [32000/60000]\n",
            "loss: 0.446656  [38400/60000]\n",
            "loss: 0.586783  [44800/60000]\n",
            "loss: 0.553788  [51200/60000]\n",
            "loss: 0.408242  [57600/60000]\n",
            "\n",
            "Epoch 10\n",
            "loss: 0.297882  [    0/60000]\n",
            "loss: 0.438355  [ 6400/60000]\n",
            "loss: 0.282886  [12800/60000]\n",
            "loss: 0.472288  [19200/60000]\n",
            "loss: 0.374577  [25600/60000]\n",
            "loss: 0.430325  [32000/60000]\n",
            "loss: 0.434624  [38400/60000]\n",
            "loss: 0.574540  [44800/60000]\n",
            "loss: 0.541345  [51200/60000]\n",
            "loss: 0.404844  [57600/60000]\n",
            "Final test:\n",
            "Test Error: \n",
            " Accuracy: 83.3%, Avg loss: 0.461511 \n",
            "\n",
            "\n",
            "Training with learning rate: 0.001\n",
            "\n",
            "\n",
            "Epoch 1\n",
            "loss: 2.311097  [    0/60000]\n",
            "loss: 2.289804  [ 6400/60000]\n",
            "loss: 2.277745  [12800/60000]\n",
            "loss: 2.269876  [19200/60000]\n",
            "loss: 2.241346  [25600/60000]\n",
            "loss: 2.215335  [32000/60000]\n",
            "loss: 2.227458  [38400/60000]\n",
            "loss: 2.191967  [44800/60000]\n",
            "loss: 2.188626  [51200/60000]\n",
            "loss: 2.163385  [57600/60000]\n",
            "\n",
            "Epoch 2\n",
            "loss: 2.164262  [    0/60000]\n",
            "loss: 2.152359  [ 6400/60000]\n",
            "loss: 2.098877  [12800/60000]\n",
            "loss: 2.117198  [19200/60000]\n",
            "loss: 2.066902  [25600/60000]\n",
            "loss: 1.999997  [32000/60000]\n",
            "loss: 2.031014  [38400/60000]\n",
            "loss: 1.951635  [44800/60000]\n",
            "loss: 1.950501  [51200/60000]\n",
            "loss: 1.886693  [57600/60000]\n",
            "\n",
            "Epoch 3\n",
            "loss: 1.915235  [    0/60000]\n",
            "loss: 1.884552  [ 6400/60000]\n",
            "loss: 1.767284  [12800/60000]\n",
            "loss: 1.812512  [19200/60000]\n",
            "loss: 1.718473  [25600/60000]\n",
            "loss: 1.649322  [32000/60000]\n",
            "loss: 1.674527  [38400/60000]\n",
            "loss: 1.574982  [44800/60000]\n",
            "loss: 1.594511  [51200/60000]\n",
            "loss: 1.496141  [57600/60000]\n",
            "\n",
            "Epoch 4\n",
            "loss: 1.575662  [    0/60000]\n",
            "loss: 1.544347  [ 6400/60000]\n",
            "loss: 1.391349  [12800/60000]\n",
            "loss: 1.476922  [19200/60000]\n",
            "loss: 1.369953  [25600/60000]\n",
            "loss: 1.339750  [32000/60000]\n",
            "loss: 1.362123  [38400/60000]\n",
            "loss: 1.286534  [44800/60000]\n",
            "loss: 1.319905  [51200/60000]\n",
            "loss: 1.227334  [57600/60000]\n",
            "\n",
            "Epoch 5\n",
            "loss: 1.320740  [    0/60000]\n",
            "loss: 1.308319  [ 6400/60000]\n",
            "loss: 1.140786  [12800/60000]\n",
            "loss: 1.259083  [19200/60000]\n",
            "loss: 1.139992  [25600/60000]\n",
            "loss: 1.142603  [32000/60000]\n",
            "loss: 1.170355  [38400/60000]\n",
            "loss: 1.111679  [44800/60000]\n",
            "loss: 1.148548  [51200/60000]\n",
            "loss: 1.070766  [57600/60000]\n",
            "\n",
            "Epoch 6\n",
            "loss: 1.151701  [    0/60000]\n",
            "loss: 1.161430  [ 6400/60000]\n",
            "loss: 0.977961  [12800/60000]\n",
            "loss: 1.120816  [19200/60000]\n",
            "loss: 0.997301  [25600/60000]\n",
            "loss: 1.009974  [32000/60000]\n",
            "loss: 1.051041  [38400/60000]\n",
            "loss: 1.000318  [44800/60000]\n",
            "loss: 1.035970  [51200/60000]\n",
            "loss: 0.971929  [57600/60000]\n",
            "\n",
            "Epoch 7\n",
            "loss: 1.033741  [    0/60000]\n",
            "loss: 1.066116  [ 6400/60000]\n",
            "loss: 0.866312  [12800/60000]\n",
            "loss: 1.028064  [19200/60000]\n",
            "loss: 0.906466  [25600/60000]\n",
            "loss: 0.915919  [32000/60000]\n",
            "loss: 0.972165  [38400/60000]\n",
            "loss: 0.926800  [44800/60000]\n",
            "loss: 0.957242  [51200/60000]\n",
            "loss: 0.904731  [57600/60000]\n",
            "\n",
            "Epoch 8\n",
            "loss: 0.946385  [    0/60000]\n",
            "loss: 0.999304  [ 6400/60000]\n",
            "loss: 0.785623  [12800/60000]\n",
            "loss: 0.962596  [19200/60000]\n",
            "loss: 0.845079  [25600/60000]\n",
            "loss: 0.846884  [32000/60000]\n",
            "loss: 0.916399  [38400/60000]\n",
            "loss: 0.876601  [44800/60000]\n",
            "loss: 0.899985  [51200/60000]\n",
            "loss: 0.855476  [57600/60000]\n",
            "\n",
            "Epoch 9\n",
            "loss: 0.878799  [    0/60000]\n",
            "loss: 0.948708  [ 6400/60000]\n",
            "loss: 0.724391  [12800/60000]\n",
            "loss: 0.913751  [19200/60000]\n",
            "loss: 0.801235  [25600/60000]\n",
            "loss: 0.794916  [32000/60000]\n",
            "loss: 0.874212  [38400/60000]\n",
            "loss: 0.841204  [44800/60000]\n",
            "loss: 0.857046  [51200/60000]\n",
            "loss: 0.817363  [57600/60000]\n",
            "\n",
            "Epoch 10\n",
            "loss: 0.824688  [    0/60000]\n",
            "loss: 0.907658  [ 6400/60000]\n",
            "loss: 0.676194  [12800/60000]\n",
            "loss: 0.875967  [19200/60000]\n",
            "loss: 0.768025  [25600/60000]\n",
            "loss: 0.755187  [32000/60000]\n",
            "loss: 0.840154  [38400/60000]\n",
            "loss: 0.814824  [44800/60000]\n",
            "loss: 0.823649  [51200/60000]\n",
            "loss: 0.786513  [57600/60000]\n",
            "Final test:\n",
            "Test Error: \n",
            " Accuracy: 71.2%, Avg loss: 0.785869 \n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "learning_rates = [1, 0.1, 0.01, 0.001]\n",
        "loss_history = {}\n",
        "\n",
        "def training_code(learning_rate, epochs=10):\n",
        "  print(f\"\\nTraining with learning rate: {learning_rate}\\n\")\n",
        "  \n",
        "  model = NeuralNetwork().to(device)\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "  \n",
        "  epoch_losses = []\n",
        "  \n",
        "  for t in range(epochs):\n",
        "    print(f\"\\nEpoch {t + 1}\")\n",
        "    average_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
        "    epoch_losses.append(average_loss)\n",
        "    \n",
        "  print(f\"Final test:\")\n",
        "  test(test_dataloader, model, loss_fn)\n",
        "  \n",
        "  return epoch_losses\n",
        "\n",
        "for rate in learning_rates:\n",
        "  losses = training_code(rate)\n",
        "  loss_history[rate] = losses\n",
        "  \n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "for learning_rate, losses in loss_history.items():\n",
        "  plt.plot(losses, label=f\"learning rate: {learning_rate}\")\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.title(\"loss curves\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "### Q1.3 (3 point) \n",
        "Report the number of epochs when the network converges (or number of epochs for the best accuracy, if it fails to converge). Fill in the table below and plot the loss curve for each experiment. Please run the code for more than 10 epochs (e.g., 50 or 100) and report when you observe convergence:\n",
        "\n",
        "|Lr|Accuracy|Epoch|\n",
        "|---|---|---|\n",
        "|1   |      |     |\n",
        "|0.1|          |    |\n",
        "|0.01|         |    |\n",
        "|0.001  |        |     |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training with learning rate: 1\n",
            "\n",
            "\n",
            "Epoch 1\n",
            "loss: 2.313456  [    0/60000]\n",
            "loss: 2.184691  [ 6400/60000]\n",
            "loss: 2.026674  [12800/60000]\n",
            "loss: 2.162079  [19200/60000]\n",
            "loss: 2.291786  [25600/60000]\n",
            "loss: 1.719159  [32000/60000]\n",
            "loss: 1.730340  [38400/60000]\n",
            "loss: 1.642997  [44800/60000]\n",
            "loss: 1.734970  [51200/60000]\n",
            "loss: 1.768693  [57600/60000]\n",
            "\n",
            "Epoch 2\n",
            "loss: 1.563943  [    0/60000]\n",
            "loss: 1.431338  [ 6400/60000]\n",
            "loss: 1.377929  [12800/60000]\n",
            "loss: 2.233965  [19200/60000]\n",
            "loss: 1.560731  [25600/60000]\n",
            "loss: 1.593906  [32000/60000]\n",
            "loss: 1.615766  [38400/60000]\n",
            "loss: 1.593812  [44800/60000]\n",
            "loss: 1.643795  [51200/60000]\n",
            "loss: 1.729605  [57600/60000]\n",
            "\n",
            "Epoch 3\n",
            "loss: 1.633466  [    0/60000]\n",
            "loss: 1.533319  [ 6400/60000]\n",
            "loss: 1.802694  [12800/60000]\n",
            "loss: 1.696405  [19200/60000]\n",
            "loss: 1.721919  [25600/60000]\n",
            "loss: 1.684708  [32000/60000]\n",
            "loss: 1.464569  [38400/60000]\n",
            "loss: 1.654692  [44800/60000]\n",
            "loss: 1.708328  [51200/60000]\n",
            "loss: 1.720952  [57600/60000]\n",
            "\n",
            "Epoch 4\n",
            "loss: 1.713294  [    0/60000]\n",
            "loss: 1.684403  [ 6400/60000]\n",
            "loss: 1.751553  [12800/60000]\n",
            "loss: 1.676821  [19200/60000]\n",
            "loss: 1.565672  [25600/60000]\n",
            "loss: 1.545178  [32000/60000]\n",
            "loss: 1.627613  [38400/60000]\n",
            "loss: 1.651322  [44800/60000]\n",
            "loss: 1.625216  [51200/60000]\n",
            "loss: 1.639088  [57600/60000]\n",
            "\n",
            "Epoch 5\n",
            "loss: 1.672268  [    0/60000]\n",
            "loss: 1.644695  [ 6400/60000]\n",
            "loss: 1.715973  [12800/60000]\n",
            "loss: 1.659001  [19200/60000]\n",
            "loss: 1.595754  [25600/60000]\n",
            "loss: 1.646260  [32000/60000]\n",
            "loss: 1.600185  [38400/60000]\n",
            "loss: 1.648871  [44800/60000]\n",
            "loss: 1.634537  [51200/60000]\n",
            "loss: 1.630269  [57600/60000]\n",
            "\n",
            "Epoch 6\n",
            "loss: 1.516200  [    0/60000]\n",
            "loss: 1.567525  [ 6400/60000]\n",
            "loss: 1.707062  [12800/60000]\n",
            "loss: 1.674981  [19200/60000]\n",
            "loss: 1.566043  [25600/60000]\n",
            "loss: 1.643573  [32000/60000]\n",
            "loss: 1.552833  [38400/60000]\n",
            "loss: 1.648046  [44800/60000]\n",
            "loss: 1.616961  [51200/60000]\n",
            "loss: 1.656129  [57600/60000]\n",
            "\n",
            "Epoch 7\n",
            "loss: 1.674614  [    0/60000]\n",
            "loss: 1.395953  [ 6400/60000]\n",
            "loss: 1.459387  [12800/60000]\n",
            "loss: 1.372041  [19200/60000]\n",
            "loss: 1.560951  [25600/60000]\n",
            "loss: 1.496975  [32000/60000]\n",
            "loss: 1.420371  [38400/60000]\n",
            "loss: 1.545113  [44800/60000]\n",
            "loss: 1.659083  [51200/60000]\n",
            "loss: 1.657525  [57600/60000]\n",
            "\n",
            "Epoch 8\n",
            "loss: 1.755752  [    0/60000]\n",
            "loss: 1.582685  [ 6400/60000]\n",
            "loss: 1.636566  [12800/60000]\n",
            "loss: 1.654001  [19200/60000]\n",
            "loss: 1.539292  [25600/60000]\n",
            "loss: 1.640249  [32000/60000]\n",
            "loss: 1.408358  [38400/60000]\n",
            "loss: 1.595270  [44800/60000]\n",
            "loss: 1.529944  [51200/60000]\n",
            "loss: 1.658680  [57600/60000]\n",
            "\n",
            "Epoch 9\n",
            "loss: 1.629467  [    0/60000]\n",
            "loss: 1.616562  [ 6400/60000]\n",
            "loss: 1.862953  [12800/60000]\n",
            "loss: 1.682792  [19200/60000]\n",
            "loss: 1.602586  [25600/60000]\n",
            "loss: 1.732474  [32000/60000]\n",
            "loss: 1.580841  [38400/60000]\n",
            "loss: 1.653890  [44800/60000]\n",
            "loss: 1.632823  [51200/60000]\n",
            "loss: 1.632354  [57600/60000]\n",
            "\n",
            "Epoch 10\n",
            "loss: 1.678323  [    0/60000]\n",
            "loss: 1.614159  [ 6400/60000]\n",
            "loss: 1.672302  [12800/60000]\n",
            "loss: 1.667390  [19200/60000]\n",
            "loss: 1.636570  [25600/60000]\n",
            "loss: 1.667062  [32000/60000]\n",
            "loss: 1.688617  [38400/60000]\n",
            "loss: 1.652493  [44800/60000]\n",
            "loss: 1.652809  [51200/60000]\n",
            "loss: 1.628210  [57600/60000]\n",
            "\n",
            "Epoch 11\n",
            "loss: 1.669193  [    0/60000]\n",
            "loss: 1.604365  [ 6400/60000]\n",
            "loss: 1.700343  [12800/60000]\n",
            "loss: 1.672776  [19200/60000]\n",
            "loss: 1.667330  [25600/60000]\n",
            "loss: 1.640466  [32000/60000]\n",
            "loss: 1.685956  [38400/60000]\n",
            "loss: 1.642039  [44800/60000]\n",
            "loss: 1.653785  [51200/60000]\n",
            "loss: 1.705962  [57600/60000]\n",
            "\n",
            "Epoch 12\n",
            "loss: 1.680600  [    0/60000]\n",
            "loss: 1.595362  [ 6400/60000]\n",
            "loss: 1.574125  [12800/60000]\n",
            "loss: 1.668817  [19200/60000]\n",
            "loss: 1.581301  [25600/60000]\n",
            "loss: 1.590996  [32000/60000]\n",
            "loss: 1.598524  [38400/60000]\n",
            "loss: 1.646680  [44800/60000]\n",
            "loss: 1.683662  [51200/60000]\n",
            "loss: 1.755304  [57600/60000]\n",
            "\n",
            "Epoch 13\n",
            "loss: 1.591935  [    0/60000]\n",
            "loss: 2.105134  [ 6400/60000]\n",
            "loss: 1.667782  [12800/60000]\n",
            "loss: 1.859286  [19200/60000]\n",
            "loss: 1.643644  [25600/60000]\n",
            "loss: 1.753001  [32000/60000]\n",
            "loss: 1.670952  [38400/60000]\n",
            "loss: 1.681257  [44800/60000]\n",
            "loss: 1.685275  [51200/60000]\n",
            "loss: 1.680157  [57600/60000]\n",
            "\n",
            "Epoch 14\n",
            "loss: 1.775502  [    0/60000]\n",
            "loss: 1.581520  [ 6400/60000]\n",
            "loss: 27.537746  [12800/60000]\n",
            "loss: 1.752453  [19200/60000]\n",
            "loss: 1.679605  [25600/60000]\n",
            "loss: 1.771760  [32000/60000]\n",
            "loss: 1.727724  [38400/60000]\n",
            "loss: 1.658568  [44800/60000]\n",
            "loss: 1.670318  [51200/60000]\n",
            "loss: 1.716102  [57600/60000]\n",
            "\n",
            "Epoch 15\n",
            "loss: 1.999660  [    0/60000]\n",
            "loss: 1.795271  [ 6400/60000]\n",
            "loss: 1.783520  [12800/60000]\n",
            "loss: 1.801439  [19200/60000]\n",
            "loss: 1.665047  [25600/60000]\n",
            "loss: 1.823166  [32000/60000]\n",
            "loss: 1.695416  [38400/60000]\n",
            "loss: 1.662194  [44800/60000]\n",
            "loss: 1.688207  [51200/60000]\n",
            "loss: 1.702839  [57600/60000]\n",
            "\n",
            "Epoch 16\n",
            "loss: 1.882549  [    0/60000]\n",
            "loss: 1.643963  [ 6400/60000]\n",
            "loss: 1.750805  [12800/60000]\n",
            "loss: 1.721646  [19200/60000]\n",
            "loss: 1.761280  [25600/60000]\n",
            "loss: 1.751443  [32000/60000]\n",
            "loss: 1.707076  [38400/60000]\n",
            "loss: 1.708936  [44800/60000]\n",
            "loss: 1.651547  [51200/60000]\n",
            "loss: 1.673078  [57600/60000]\n",
            "\n",
            "Epoch 17\n",
            "loss: 1.817928  [    0/60000]\n",
            "loss: 1.659604  [ 6400/60000]\n",
            "loss: 1.768031  [12800/60000]\n",
            "loss: 1.674445  [19200/60000]\n",
            "loss: 1.693163  [25600/60000]\n",
            "loss: 1.784323  [32000/60000]\n",
            "loss: 1.768518  [38400/60000]\n",
            "loss: 1.764728  [44800/60000]\n",
            "loss: 1.700462  [51200/60000]\n",
            "loss: 1.691950  [57600/60000]\n",
            "\n",
            "Epoch 18\n",
            "loss: 1.722780  [    0/60000]\n",
            "loss: 1.731338  [ 6400/60000]\n",
            "loss: 1.720824  [12800/60000]\n",
            "loss: 1.724826  [19200/60000]\n",
            "loss: 1.654874  [25600/60000]\n",
            "loss: 1.716595  [32000/60000]\n",
            "loss: 1.694986  [38400/60000]\n",
            "loss: 1.756754  [44800/60000]\n",
            "loss: 1.662986  [51200/60000]\n",
            "loss: 1.658608  [57600/60000]\n",
            "\n",
            "Epoch 19\n",
            "loss: 1.674367  [    0/60000]\n",
            "loss: 1.637326  [ 6400/60000]\n",
            "loss: 1.732528  [12800/60000]\n",
            "loss: 1.672920  [19200/60000]\n",
            "loss: 1.436406  [25600/60000]\n",
            "loss: 1.825302  [32000/60000]\n",
            "loss: 1.671771  [38400/60000]\n",
            "loss: 1.756886  [44800/60000]\n",
            "loss: 1.657970  [51200/60000]\n",
            "loss: 1.673325  [57600/60000]\n",
            "\n",
            "Epoch 20\n",
            "loss: 1.682166  [    0/60000]\n",
            "loss: 1.646586  [ 6400/60000]\n",
            "loss: 1.717609  [12800/60000]\n",
            "loss: 2.064722  [19200/60000]\n",
            "loss: 1.801059  [25600/60000]\n",
            "loss: 1.783869  [32000/60000]\n",
            "loss: 1.726580  [38400/60000]\n",
            "loss: 1.757225  [44800/60000]\n",
            "loss: 1.657400  [51200/60000]\n",
            "loss: 1.684312  [57600/60000]\n",
            "\n",
            "Epoch 21\n",
            "loss: 1.823232  [    0/60000]\n",
            "loss: 1.686606  [ 6400/60000]\n",
            "loss: 1.780300  [12800/60000]\n",
            "loss: 1.737688  [19200/60000]\n",
            "loss: 1.663997  [25600/60000]\n",
            "loss: 1.750673  [32000/60000]\n",
            "loss: 1.723649  [38400/60000]\n",
            "loss: 1.754752  [44800/60000]\n",
            "loss: 1.649343  [51200/60000]\n",
            "loss: 1.676935  [57600/60000]\n",
            "\n",
            "Epoch 22\n",
            "loss: 1.816788  [    0/60000]\n",
            "loss: 1.682270  [ 6400/60000]\n",
            "loss: 1.766995  [12800/60000]\n",
            "loss: 1.659895  [19200/60000]\n",
            "loss: 1.746916  [25600/60000]\n",
            "loss: 1.777647  [32000/60000]\n",
            "loss: 1.730525  [38400/60000]\n",
            "loss: 1.709455  [44800/60000]\n",
            "loss: 1.653958  [51200/60000]\n",
            "loss: 1.663554  [57600/60000]\n",
            "\n",
            "Epoch 23\n",
            "loss: 1.820217  [    0/60000]\n",
            "loss: 1.730711  [ 6400/60000]\n",
            "loss: 1.779925  [12800/60000]\n",
            "loss: 1.713490  [19200/60000]\n",
            "loss: 1.677345  [25600/60000]\n",
            "loss: 1.746184  [32000/60000]\n",
            "loss: 1.723333  [38400/60000]\n",
            "loss: 1.781401  [44800/60000]\n",
            "loss: 1.649458  [51200/60000]\n",
            "loss: 1.711229  [57600/60000]\n",
            "\n",
            "Epoch 24\n",
            "loss: 1.673415  [    0/60000]\n",
            "loss: 1.690506  [ 6400/60000]\n",
            "loss: 1.726869  [12800/60000]\n",
            "loss: 1.680307  [19200/60000]\n",
            "loss: 1.689503  [25600/60000]\n",
            "loss: 1.669513  [32000/60000]\n",
            "loss: 1.670622  [38400/60000]\n",
            "loss: 1.709016  [44800/60000]\n",
            "loss: 1.655384  [51200/60000]\n",
            "loss: 1.663396  [57600/60000]\n",
            "\n",
            "Epoch 25\n",
            "loss: 1.720933  [    0/60000]\n",
            "loss: 1.639351  [ 6400/60000]\n",
            "loss: 1.723721  [12800/60000]\n",
            "loss: 1.654941  [19200/60000]\n",
            "loss: 1.703740  [25600/60000]\n",
            "loss: 1.765628  [32000/60000]\n",
            "loss: 1.682447  [38400/60000]\n",
            "loss: 1.704108  [44800/60000]\n",
            "loss: 1.658113  [51200/60000]\n",
            "loss: 1.666872  [57600/60000]\n",
            "\n",
            "Epoch 26\n",
            "loss: 1.719764  [    0/60000]\n",
            "loss: 1.639831  [ 6400/60000]\n",
            "loss: 1.731551  [12800/60000]\n",
            "loss: 1.678389  [19200/60000]\n",
            "loss: 1.655940  [25600/60000]\n",
            "loss: 1.716461  [32000/60000]\n",
            "loss: 1.668123  [38400/60000]\n",
            "loss: 1.710138  [44800/60000]\n",
            "loss: 1.652506  [51200/60000]\n",
            "loss: 1.662949  [57600/60000]\n",
            "\n",
            "Epoch 27\n",
            "loss: 1.717870  [    0/60000]\n",
            "loss: 1.637708  [ 6400/60000]\n",
            "loss: 1.736335  [12800/60000]\n",
            "loss: 1.718445  [19200/60000]\n",
            "loss: 1.682869  [25600/60000]\n",
            "loss: 1.751477  [32000/60000]\n",
            "loss: 1.692472  [38400/60000]\n",
            "loss: 1.898294  [44800/60000]\n",
            "loss: 1.782798  [51200/60000]\n",
            "loss: 1.837125  [57600/60000]\n",
            "\n",
            "Epoch 28\n",
            "loss: 1.830164  [    0/60000]\n",
            "loss: 1.717672  [ 6400/60000]\n",
            "loss: 1.730857  [12800/60000]\n",
            "loss: 1.715748  [19200/60000]\n",
            "loss: 1.683092  [25600/60000]\n",
            "loss: 1.712998  [32000/60000]\n",
            "loss: 1.699775  [38400/60000]\n",
            "loss: 1.710926  [44800/60000]\n",
            "loss: 1.651517  [51200/60000]\n",
            "loss: 1.657269  [57600/60000]\n",
            "\n",
            "Epoch 29\n",
            "loss: 1.668865  [    0/60000]\n",
            "loss: 1.636878  [ 6400/60000]\n",
            "loss: 1.726866  [12800/60000]\n",
            "loss: 1.660339  [19200/60000]\n",
            "loss: 1.683466  [25600/60000]\n",
            "loss: 1.717407  [32000/60000]\n",
            "loss: 1.669239  [38400/60000]\n",
            "loss: 1.709470  [44800/60000]\n",
            "loss: 1.652205  [51200/60000]\n",
            "loss: 1.660679  [57600/60000]\n",
            "\n",
            "Epoch 30\n",
            "loss: 1.747165  [    0/60000]\n",
            "loss: 1.732238  [ 6400/60000]\n",
            "loss: 1.798787  [12800/60000]\n",
            "loss: 1.806072  [19200/60000]\n",
            "loss: 1.635805  [25600/60000]\n",
            "loss: 1.710528  [32000/60000]\n",
            "loss: 1.707487  [38400/60000]\n",
            "loss: 1.676868  [44800/60000]\n",
            "loss: 1.695305  [51200/60000]\n",
            "loss: 1.694535  [57600/60000]\n",
            "\n",
            "Epoch 31\n",
            "loss: 1.893742  [    0/60000]\n",
            "loss: 1.727958  [ 6400/60000]\n",
            "loss: 1.789334  [12800/60000]\n",
            "loss: 1.740235  [19200/60000]\n",
            "loss: 1.668269  [25600/60000]\n",
            "loss: 1.767905  [32000/60000]\n",
            "loss: 1.730859  [38400/60000]\n",
            "loss: 1.676486  [44800/60000]\n",
            "loss: 1.671694  [51200/60000]\n",
            "loss: 1.690826  [57600/60000]\n",
            "\n",
            "Epoch 32\n",
            "loss: 1.916284  [    0/60000]\n",
            "loss: 1.728268  [ 6400/60000]\n",
            "loss: 1.789524  [12800/60000]\n",
            "loss: 1.746271  [19200/60000]\n",
            "loss: 1.665579  [25600/60000]\n",
            "loss: 1.765679  [32000/60000]\n",
            "loss: 1.816385  [38400/60000]\n",
            "loss: 1.675933  [44800/60000]\n",
            "loss: 1.682772  [51200/60000]\n",
            "loss: 1.691535  [57600/60000]\n",
            "\n",
            "Epoch 33\n",
            "loss: 1.910377  [    0/60000]\n",
            "loss: 1.756030  [ 6400/60000]\n",
            "loss: 1.766617  [12800/60000]\n",
            "loss: 1.876023  [19200/60000]\n",
            "loss: 1.873247  [25600/60000]\n",
            "loss: 1.746102  [32000/60000]\n",
            "loss: 1.692259  [38400/60000]\n",
            "loss: 1.781441  [44800/60000]\n",
            "loss: 1.723623  [51200/60000]\n",
            "loss: 1.709820  [57600/60000]\n",
            "\n",
            "Epoch 34\n",
            "loss: 1.914061  [    0/60000]\n",
            "loss: 1.761350  [ 6400/60000]\n",
            "loss: 1.752586  [12800/60000]\n",
            "loss: 1.844712  [19200/60000]\n",
            "loss: 1.693213  [25600/60000]\n",
            "loss: 1.744610  [32000/60000]\n",
            "loss: 1.690609  [38400/60000]\n",
            "loss: 1.759608  [44800/60000]\n",
            "loss: 1.735189  [51200/60000]\n",
            "loss: 1.707842  [57600/60000]\n",
            "\n",
            "Epoch 35\n",
            "loss: 1.918499  [    0/60000]\n",
            "loss: 1.722052  [ 6400/60000]\n",
            "loss: 1.777889  [12800/60000]\n",
            "loss: 1.810227  [19200/60000]\n",
            "loss: 1.642940  [25600/60000]\n",
            "loss: 1.766400  [32000/60000]\n",
            "loss: 1.709220  [38400/60000]\n",
            "loss: 1.771474  [44800/60000]\n",
            "loss: 1.722275  [51200/60000]\n",
            "loss: 1.705939  [57600/60000]\n",
            "\n",
            "Epoch 36\n",
            "loss: 1.922643  [    0/60000]\n",
            "loss: 1.738194  [ 6400/60000]\n",
            "loss: 1.777089  [12800/60000]\n",
            "loss: 1.791789  [19200/60000]\n",
            "loss: 1.645354  [25600/60000]\n",
            "loss: 1.757158  [32000/60000]\n",
            "loss: 1.691612  [38400/60000]\n",
            "loss: 1.691501  [44800/60000]\n",
            "loss: 1.695886  [51200/60000]\n",
            "loss: 1.700325  [57600/60000]\n",
            "\n",
            "Epoch 37\n",
            "loss: 1.886980  [    0/60000]\n",
            "loss: 1.731943  [ 6400/60000]\n",
            "loss: 1.773317  [12800/60000]\n",
            "loss: 1.850719  [19200/60000]\n",
            "loss: 1.619147  [25600/60000]\n",
            "loss: 1.763805  [32000/60000]\n",
            "loss: 1.686394  [38400/60000]\n",
            "loss: 1.765950  [44800/60000]\n",
            "loss: 1.724192  [51200/60000]\n",
            "loss: 1.666214  [57600/60000]\n",
            "\n",
            "Epoch 38\n",
            "loss: 2.144964  [    0/60000]\n",
            "loss: 1.758443  [ 6400/60000]\n",
            "loss: 1.819868  [12800/60000]\n",
            "loss: 1.797950  [19200/60000]\n",
            "loss: 1.899391  [25600/60000]\n",
            "loss: 1.893252  [32000/60000]\n",
            "loss: 1.787267  [38400/60000]\n",
            "loss: 1.672870  [44800/60000]\n",
            "loss: 1.766623  [51200/60000]\n",
            "loss: 1.674220  [57600/60000]\n",
            "\n",
            "Epoch 39\n",
            "loss: 1.836300  [    0/60000]\n",
            "loss: 1.673664  [ 6400/60000]\n",
            "loss: 1.743557  [12800/60000]\n",
            "loss: 1.779732  [19200/60000]\n",
            "loss: 1.659554  [25600/60000]\n",
            "loss: 1.737539  [32000/60000]\n",
            "loss: 1.687832  [38400/60000]\n",
            "loss: 1.696125  [44800/60000]\n",
            "loss: 1.731146  [51200/60000]\n",
            "loss: 1.694257  [57600/60000]\n",
            "\n",
            "Epoch 40\n",
            "loss: 1.898967  [    0/60000]\n",
            "loss: 1.728850  [ 6400/60000]\n",
            "loss: 1.767781  [12800/60000]\n",
            "loss: 1.793511  [19200/60000]\n",
            "loss: 1.620136  [25600/60000]\n",
            "loss: 1.743575  [32000/60000]\n",
            "loss: 1.688929  [38400/60000]\n",
            "loss: 1.756702  [44800/60000]\n",
            "loss: 1.678330  [51200/60000]\n",
            "loss: 1.796330  [57600/60000]\n",
            "\n",
            "Epoch 41\n",
            "loss: 1.997380  [    0/60000]\n",
            "loss: 1.755172  [ 6400/60000]\n",
            "loss: 1.812312  [12800/60000]\n",
            "loss: 1.785619  [19200/60000]\n",
            "loss: 2.002963  [25600/60000]\n",
            "loss: 1.758440  [32000/60000]\n",
            "loss: 1.685844  [38400/60000]\n",
            "loss: 1.674633  [44800/60000]\n",
            "loss: 1.791804  [51200/60000]\n",
            "loss: 1.680476  [57600/60000]\n",
            "\n",
            "Epoch 42\n",
            "loss: 1.692222  [    0/60000]\n",
            "loss: 1.688132  [ 6400/60000]\n",
            "loss: 1.736831  [12800/60000]\n",
            "loss: 1.932522  [19200/60000]\n",
            "loss: 1.578153  [25600/60000]\n",
            "loss: 1.725962  [32000/60000]\n",
            "loss: 1.693087  [38400/60000]\n",
            "loss: 1.742659  [44800/60000]\n",
            "loss: 1.686404  [51200/60000]\n",
            "loss: 1.660668  [57600/60000]\n",
            "\n",
            "Epoch 43\n",
            "loss: 1.745237  [    0/60000]\n",
            "loss: 1.687172  [ 6400/60000]\n",
            "loss: 1.731147  [12800/60000]\n",
            "loss: 1.663516  [19200/60000]\n",
            "loss: 1.649347  [25600/60000]\n",
            "loss: 1.669867  [32000/60000]\n",
            "loss: 1.673229  [38400/60000]\n",
            "loss: 1.769117  [44800/60000]\n",
            "loss: 1.653497  [51200/60000]\n",
            "loss: 1.662439  [57600/60000]\n",
            "\n",
            "Epoch 44\n",
            "loss: 1.721430  [    0/60000]\n",
            "loss: 1.687640  [ 6400/60000]\n",
            "loss: 1.727156  [12800/60000]\n",
            "loss: 1.661156  [19200/60000]\n",
            "loss: 1.648821  [25600/60000]\n",
            "loss: 1.669713  [32000/60000]\n",
            "loss: 1.701560  [38400/60000]\n",
            "loss: 1.707552  [44800/60000]\n",
            "loss: 1.650250  [51200/60000]\n",
            "loss: 1.660172  [57600/60000]\n",
            "\n",
            "Epoch 45\n",
            "loss: 1.672261  [    0/60000]\n",
            "loss: 1.695729  [ 6400/60000]\n",
            "loss: 1.736037  [12800/60000]\n",
            "loss: 1.665721  [19200/60000]\n",
            "loss: 1.661652  [25600/60000]\n",
            "loss: 1.718808  [32000/60000]\n",
            "loss: 1.682840  [38400/60000]\n",
            "loss: 1.761219  [44800/60000]\n",
            "loss: 1.655083  [51200/60000]\n",
            "loss: 1.665478  [57600/60000]\n",
            "\n",
            "Epoch 46\n",
            "loss: 1.718616  [    0/60000]\n",
            "loss: 1.691146  [ 6400/60000]\n",
            "loss: 1.724313  [12800/60000]\n",
            "loss: 1.662199  [19200/60000]\n",
            "loss: 1.653874  [25600/60000]\n",
            "loss: 1.765885  [32000/60000]\n",
            "loss: 1.684721  [38400/60000]\n",
            "loss: 1.758963  [44800/60000]\n",
            "loss: 1.655836  [51200/60000]\n",
            "loss: 1.690400  [57600/60000]\n",
            "\n",
            "Epoch 47\n",
            "loss: 1.741527  [    0/60000]\n",
            "loss: 1.720393  [ 6400/60000]\n",
            "loss: 1.806324  [12800/60000]\n",
            "loss: 1.790812  [19200/60000]\n",
            "loss: 1.645329  [25600/60000]\n",
            "loss: 1.756605  [32000/60000]\n",
            "loss: 1.701674  [38400/60000]\n",
            "loss: 1.769085  [44800/60000]\n",
            "loss: 1.832220  [51200/60000]\n",
            "loss: 1.679398  [57600/60000]\n",
            "\n",
            "Epoch 48\n",
            "loss: 1.975461  [    0/60000]\n",
            "loss: 1.690043  [ 6400/60000]\n",
            "loss: 1.734414  [12800/60000]\n",
            "loss: 2.333861  [19200/60000]\n",
            "loss: 1.892186  [25600/60000]\n",
            "loss: 1.827942  [32000/60000]\n",
            "loss: 1.689831  [38400/60000]\n",
            "loss: 1.685923  [44800/60000]\n",
            "loss: 1.705718  [51200/60000]\n",
            "loss: 1.708998  [57600/60000]\n",
            "\n",
            "Epoch 49\n",
            "loss: 1.780152  [    0/60000]\n",
            "loss: 1.698795  [ 6400/60000]\n",
            "loss: 1.747168  [12800/60000]\n",
            "loss: 1.807790  [19200/60000]\n",
            "loss: 1.586825  [25600/60000]\n",
            "loss: 1.736619  [32000/60000]\n",
            "loss: 1.763301  [38400/60000]\n",
            "loss: 1.675556  [44800/60000]\n",
            "loss: 1.735076  [51200/60000]\n",
            "loss: 1.677762  [57600/60000]\n",
            "\n",
            "Epoch 50\n",
            "loss: 1.860631  [    0/60000]\n",
            "loss: 1.693027  [ 6400/60000]\n",
            "loss: 1.742802  [12800/60000]\n",
            "loss: 1.797901  [19200/60000]\n",
            "loss: 1.648161  [25600/60000]\n",
            "loss: 1.733291  [32000/60000]\n",
            "loss: 1.693730  [38400/60000]\n",
            "loss: 1.673691  [44800/60000]\n",
            "loss: 1.744107  [51200/60000]\n",
            "loss: 1.674895  [57600/60000]\n",
            "\n",
            "Epoch 51\n",
            "loss: 1.951478  [    0/60000]\n",
            "loss: 1.691629  [ 6400/60000]\n",
            "loss: 1.739900  [12800/60000]\n",
            "loss: 1.793759  [19200/60000]\n",
            "loss: 1.646669  [25600/60000]\n",
            "loss: 1.732097  [32000/60000]\n",
            "loss: 1.655089  [38400/60000]\n",
            "loss: 1.759896  [44800/60000]\n",
            "loss: 1.718260  [51200/60000]\n",
            "loss: 1.674688  [57600/60000]\n",
            "\n",
            "Epoch 52\n",
            "loss: 2.035778  [    0/60000]\n",
            "loss: 1.689368  [ 6400/60000]\n",
            "loss: 1.739501  [12800/60000]\n",
            "loss: 1.757065  [19200/60000]\n",
            "loss: 1.693695  [25600/60000]\n",
            "loss: 1.794958  [32000/60000]\n",
            "loss: 1.651487  [38400/60000]\n",
            "loss: 1.749551  [44800/60000]\n",
            "loss: 1.776658  [51200/60000]\n",
            "loss: 1.705837  [57600/60000]\n",
            "\n",
            "Epoch 53\n",
            "loss: 1.781524  [    0/60000]\n",
            "loss: 1.699296  [ 6400/60000]\n",
            "loss: 1.750134  [12800/60000]\n",
            "loss: 1.794351  [19200/60000]\n",
            "loss: 1.591460  [25600/60000]\n",
            "loss: 1.737944  [32000/60000]\n",
            "loss: 1.686549  [38400/60000]\n",
            "loss: 1.676879  [44800/60000]\n",
            "loss: 1.726099  [51200/60000]\n",
            "loss: 1.710690  [57600/60000]\n",
            "\n",
            "Epoch 54\n",
            "loss: 1.865506  [    0/60000]\n",
            "loss: 1.692232  [ 6400/60000]\n",
            "loss: 1.741751  [12800/60000]\n",
            "loss: 1.785980  [19200/60000]\n",
            "loss: 1.643901  [25600/60000]\n",
            "loss: 1.733294  [32000/60000]\n",
            "loss: 1.696050  [38400/60000]\n",
            "loss: 1.672816  [44800/60000]\n",
            "loss: 1.751761  [51200/60000]\n",
            "loss: 1.671014  [57600/60000]\n",
            "\n",
            "Epoch 55\n",
            "loss: 2.003631  [    0/60000]\n",
            "loss: 1.696385  [ 6400/60000]\n",
            "loss: 1.811242  [12800/60000]\n",
            "loss: 1.830939  [19200/60000]\n",
            "loss: 1.696020  [25600/60000]\n",
            "loss: 1.846908  [32000/60000]\n",
            "loss: 1.702916  [38400/60000]\n",
            "loss: 1.673008  [44800/60000]\n",
            "loss: 1.742988  [51200/60000]\n",
            "loss: 1.729135  [57600/60000]\n",
            "\n",
            "Epoch 56\n",
            "loss: 1.694025  [    0/60000]\n",
            "loss: 1.697762  [ 6400/60000]\n",
            "loss: 1.741396  [12800/60000]\n",
            "loss: 1.777097  [19200/60000]\n",
            "loss: 1.648952  [25600/60000]\n",
            "loss: 1.728495  [32000/60000]\n",
            "loss: 1.693027  [38400/60000]\n",
            "loss: 1.672794  [44800/60000]\n",
            "loss: 1.753645  [51200/60000]\n",
            "loss: 1.677387  [57600/60000]\n",
            "\n",
            "Epoch 57\n",
            "loss: 1.777170  [    0/60000]\n",
            "loss: 1.691767  [ 6400/60000]\n",
            "loss: 1.736140  [12800/60000]\n",
            "loss: 1.785597  [19200/60000]\n",
            "loss: 1.637675  [25600/60000]\n",
            "loss: 1.726698  [32000/60000]\n",
            "loss: 1.697236  [38400/60000]\n",
            "loss: 1.671751  [44800/60000]\n",
            "loss: 1.756444  [51200/60000]\n",
            "loss: 1.676761  [57600/60000]\n",
            "\n",
            "Epoch 58\n",
            "loss: 1.778970  [    0/60000]\n",
            "loss: 1.694041  [ 6400/60000]\n",
            "loss: 1.736270  [12800/60000]\n",
            "loss: 1.780098  [19200/60000]\n",
            "loss: 1.726577  [25600/60000]\n",
            "loss: 1.839942  [32000/60000]\n",
            "loss: 1.713585  [38400/60000]\n",
            "loss: 1.673464  [44800/60000]\n",
            "loss: 1.812388  [51200/60000]\n",
            "loss: 1.681710  [57600/60000]\n",
            "\n",
            "Epoch 59\n",
            "loss: 1.861341  [    0/60000]\n",
            "loss: 1.692741  [ 6400/60000]\n",
            "loss: 1.735016  [12800/60000]\n",
            "loss: 1.742215  [19200/60000]\n",
            "loss: 1.632174  [25600/60000]\n",
            "loss: 1.730149  [32000/60000]\n",
            "loss: 1.716294  [38400/60000]\n",
            "loss: 1.673856  [44800/60000]\n",
            "loss: 1.814435  [51200/60000]\n",
            "loss: 1.681938  [57600/60000]\n",
            "\n",
            "Epoch 60\n",
            "loss: 1.940716  [    0/60000]\n",
            "loss: 1.692128  [ 6400/60000]\n",
            "loss: 1.735264  [12800/60000]\n",
            "loss: 1.742035  [19200/60000]\n",
            "loss: 1.637739  [25600/60000]\n",
            "loss: 1.923097  [32000/60000]\n",
            "loss: 1.713378  [38400/60000]\n",
            "loss: 1.673452  [44800/60000]\n",
            "loss: 1.813024  [51200/60000]\n",
            "loss: 1.677418  [57600/60000]\n",
            "\n",
            "Epoch 61\n",
            "loss: 1.935173  [    0/60000]\n",
            "loss: 1.692094  [ 6400/60000]\n",
            "loss: 1.735586  [12800/60000]\n",
            "loss: 1.741874  [19200/60000]\n",
            "loss: 1.637144  [25600/60000]\n",
            "loss: 1.842522  [32000/60000]\n",
            "loss: 1.713156  [38400/60000]\n",
            "loss: 1.673740  [44800/60000]\n",
            "loss: 1.812354  [51200/60000]\n",
            "loss: 1.677121  [57600/60000]\n",
            "\n",
            "Epoch 62\n",
            "loss: 1.935273  [    0/60000]\n",
            "loss: 1.694182  [ 6400/60000]\n",
            "loss: 1.798754  [12800/60000]\n",
            "loss: 1.891741  [19200/60000]\n",
            "loss: 1.628928  [25600/60000]\n",
            "loss: 1.730932  [32000/60000]\n",
            "loss: 1.650352  [38400/60000]\n",
            "loss: 1.674276  [44800/60000]\n",
            "loss: 1.807666  [51200/60000]\n",
            "loss: 1.680084  [57600/60000]\n",
            "\n",
            "Epoch 63\n",
            "loss: 1.769194  [    0/60000]\n",
            "loss: 1.686628  [ 6400/60000]\n",
            "loss: 1.732572  [12800/60000]\n",
            "loss: 1.741834  [19200/60000]\n",
            "loss: 1.631881  [25600/60000]\n",
            "loss: 1.724892  [32000/60000]\n",
            "loss: 1.650849  [38400/60000]\n",
            "loss: 1.672578  [44800/60000]\n",
            "loss: 1.815616  [51200/60000]\n",
            "loss: 1.686030  [57600/60000]\n",
            "\n",
            "Epoch 64\n",
            "loss: 1.774451  [    0/60000]\n",
            "loss: 1.686779  [ 6400/60000]\n",
            "loss: 1.731616  [12800/60000]\n",
            "loss: 1.741170  [19200/60000]\n",
            "loss: 1.631203  [25600/60000]\n",
            "loss: 1.724406  [32000/60000]\n",
            "loss: 1.714751  [38400/60000]\n",
            "loss: 1.672096  [44800/60000]\n",
            "loss: 2.146958  [51200/60000]\n",
            "loss: 1.769697  [57600/60000]\n",
            "\n",
            "Epoch 65\n",
            "loss: 2.107878  [    0/60000]\n",
            "loss: 1.691318  [ 6400/60000]\n",
            "loss: 1.737125  [12800/60000]\n",
            "loss: 1.745324  [19200/60000]\n",
            "loss: 1.633073  [25600/60000]\n",
            "loss: 1.848237  [32000/60000]\n",
            "loss: 1.714544  [38400/60000]\n",
            "loss: 1.674385  [44800/60000]\n",
            "loss: 1.813108  [51200/60000]\n",
            "loss: 1.680184  [57600/60000]\n",
            "\n",
            "Epoch 66\n",
            "loss: 1.927696  [    0/60000]\n",
            "loss: 1.688910  [ 6400/60000]\n",
            "loss: 1.733344  [12800/60000]\n",
            "loss: 1.801325  [19200/60000]\n",
            "loss: 1.793848  [25600/60000]\n",
            "loss: 1.828351  [32000/60000]\n",
            "loss: 1.757632  [38400/60000]\n",
            "loss: 1.674841  [44800/60000]\n",
            "loss: 1.797300  [51200/60000]\n",
            "loss: 1.761965  [57600/60000]\n",
            "\n",
            "Epoch 67\n",
            "loss: 1.901540  [    0/60000]\n",
            "loss: 1.691328  [ 6400/60000]\n",
            "loss: 1.800232  [12800/60000]\n",
            "loss: 1.865247  [19200/60000]\n",
            "loss: 1.645044  [25600/60000]\n",
            "loss: 1.728279  [32000/60000]\n",
            "loss: 1.698248  [38400/60000]\n",
            "loss: 1.673386  [44800/60000]\n",
            "loss: 1.741417  [51200/60000]\n",
            "loss: 1.715536  [57600/60000]\n",
            "\n",
            "Epoch 68\n",
            "loss: 1.689992  [    0/60000]\n",
            "loss: 1.696386  [ 6400/60000]\n",
            "loss: 1.737128  [12800/60000]\n",
            "loss: 1.750834  [19200/60000]\n",
            "loss: 1.636315  [25600/60000]\n",
            "loss: 1.864366  [32000/60000]\n",
            "loss: 1.715036  [38400/60000]\n",
            "loss: 1.672597  [44800/60000]\n",
            "loss: 1.804237  [51200/60000]\n",
            "loss: 1.675736  [57600/60000]\n",
            "\n",
            "Epoch 69\n",
            "loss: 1.773721  [    0/60000]\n",
            "loss: 1.690498  [ 6400/60000]\n",
            "loss: 1.733298  [12800/60000]\n",
            "loss: 1.799058  [19200/60000]\n",
            "loss: 1.639841  [25600/60000]\n",
            "loss: 1.797431  [32000/60000]\n",
            "loss: 1.708924  [38400/60000]\n",
            "loss: 1.671606  [44800/60000]\n",
            "loss: 1.783939  [51200/60000]\n",
            "loss: 1.770005  [57600/60000]\n",
            "\n",
            "Epoch 70\n",
            "loss: 1.949207  [    0/60000]\n",
            "loss: 1.693105  [ 6400/60000]\n",
            "loss: 1.732631  [12800/60000]\n",
            "loss: 1.799302  [19200/60000]\n",
            "loss: 1.639140  [25600/60000]\n",
            "loss: 1.725171  [32000/60000]\n",
            "loss: 1.695720  [38400/60000]\n",
            "loss: 1.743000  [44800/60000]\n",
            "loss: 1.659101  [51200/60000]\n",
            "loss: 1.675787  [57600/60000]\n",
            "\n",
            "Epoch 71\n",
            "loss: 1.683918  [    0/60000]\n",
            "loss: 1.735902  [ 6400/60000]\n",
            "loss: 1.744635  [12800/60000]\n",
            "loss: 1.682129  [19200/60000]\n",
            "loss: 1.661093  [25600/60000]\n",
            "loss: 1.736419  [32000/60000]\n",
            "loss: 1.696715  [38400/60000]\n",
            "loss: 1.761443  [44800/60000]\n",
            "loss: 1.697453  [51200/60000]\n",
            "loss: 1.687413  [57600/60000]\n",
            "\n",
            "Epoch 72\n",
            "loss: 1.698238  [    0/60000]\n",
            "loss: 1.695263  [ 6400/60000]\n",
            "loss: 1.742945  [12800/60000]\n",
            "loss: 1.816384  [19200/60000]\n",
            "loss: 1.646795  [25600/60000]\n",
            "loss: 1.726973  [32000/60000]\n",
            "loss: 1.691543  [38400/60000]\n",
            "loss: 1.671704  [44800/60000]\n",
            "loss: 1.747766  [51200/60000]\n",
            "loss: 1.678999  [57600/60000]\n",
            "\n",
            "Epoch 73\n",
            "loss: 1.689646  [    0/60000]\n",
            "loss: 1.692844  [ 6400/60000]\n",
            "loss: 1.766915  [12800/60000]\n",
            "loss: 1.811053  [19200/60000]\n",
            "loss: 1.592395  [25600/60000]\n",
            "loss: 1.763860  [32000/60000]\n",
            "loss: 1.694115  [38400/60000]\n",
            "loss: 1.766377  [44800/60000]\n",
            "loss: 1.693410  [51200/60000]\n",
            "loss: 1.728422  [57600/60000]\n",
            "\n",
            "Epoch 74\n",
            "loss: 1.722465  [    0/60000]\n",
            "loss: 1.733889  [ 6400/60000]\n",
            "loss: 1.767421  [12800/60000]\n",
            "loss: 1.816610  [19200/60000]\n",
            "loss: 1.587207  [25600/60000]\n",
            "loss: 1.752046  [32000/60000]\n",
            "loss: 1.686398  [38400/60000]\n",
            "loss: 1.765786  [44800/60000]\n",
            "loss: 1.692604  [51200/60000]\n",
            "loss: 1.727340  [57600/60000]\n",
            "\n",
            "Epoch 75\n",
            "loss: 1.718966  [    0/60000]\n",
            "loss: 1.729624  [ 6400/60000]\n",
            "loss: 1.757736  [12800/60000]\n",
            "loss: 1.702089  [19200/60000]\n",
            "loss: 1.639529  [25600/60000]\n",
            "loss: 1.717876  [32000/60000]\n",
            "loss: 1.685500  [38400/60000]\n",
            "loss: 1.772881  [44800/60000]\n",
            "loss: 1.685310  [51200/60000]\n",
            "loss: 1.706618  [57600/60000]\n",
            "\n",
            "Epoch 76\n",
            "loss: 1.714271  [    0/60000]\n",
            "loss: 1.728887  [ 6400/60000]\n",
            "loss: 1.762182  [12800/60000]\n",
            "loss: 1.777285  [19200/60000]\n",
            "loss: 1.636140  [25600/60000]\n",
            "loss: 1.753671  [32000/60000]\n",
            "loss: 1.695413  [38400/60000]\n",
            "loss: 1.781734  [44800/60000]\n",
            "loss: 1.686482  [51200/60000]\n",
            "loss: 1.708137  [57600/60000]\n",
            "\n",
            "Epoch 77\n",
            "loss: 1.732252  [    0/60000]\n",
            "loss: 1.725602  [ 6400/60000]\n",
            "loss: 1.764489  [12800/60000]\n",
            "loss: 1.759693  [19200/60000]\n",
            "loss: 1.644601  [25600/60000]\n",
            "loss: 1.734010  [32000/60000]\n",
            "loss: 1.690163  [38400/60000]\n",
            "loss: 1.805054  [44800/60000]\n",
            "loss: 1.688407  [51200/60000]\n",
            "loss: 1.684416  [57600/60000]\n",
            "\n",
            "Epoch 78\n",
            "loss: 1.683781  [    0/60000]\n",
            "loss: 1.691195  [ 6400/60000]\n",
            "loss: 1.779026  [12800/60000]\n",
            "loss: 1.720485  [19200/60000]\n",
            "loss: 1.636992  [25600/60000]\n",
            "loss: 1.973943  [32000/60000]\n",
            "loss: 1.793128  [38400/60000]\n",
            "loss: 1.782932  [44800/60000]\n",
            "loss: 2.720929  [51200/60000]\n",
            "loss: 2.094842  [57600/60000]\n",
            "\n",
            "Epoch 79\n",
            "loss: 2.127494  [    0/60000]\n",
            "loss: 2.253168  [ 6400/60000]\n",
            "loss: 2.095206  [12800/60000]\n",
            "loss: 2.126331  [19200/60000]\n",
            "loss: 2.076003  [25600/60000]\n",
            "loss: 2.302112  [32000/60000]\n",
            "loss: 2.028420  [38400/60000]\n",
            "loss: 2.119848  [44800/60000]\n",
            "loss: 2.172130  [51200/60000]\n",
            "loss: 2.137044  [57600/60000]\n",
            "\n",
            "Epoch 80\n",
            "loss: 2.286576  [    0/60000]\n",
            "loss: 2.199969  [ 6400/60000]\n",
            "loss: 2.165027  [12800/60000]\n",
            "loss: 2.147843  [19200/60000]\n",
            "loss: 2.070521  [25600/60000]\n",
            "loss: 2.331602  [32000/60000]\n",
            "loss: 2.072562  [38400/60000]\n",
            "loss: 2.068331  [44800/60000]\n",
            "loss: 2.169215  [51200/60000]\n",
            "loss: 2.083316  [57600/60000]\n",
            "\n",
            "Epoch 81\n",
            "loss: 2.220151  [    0/60000]\n",
            "loss: 2.192573  [ 6400/60000]\n",
            "loss: 2.168447  [12800/60000]\n",
            "loss: 2.129968  [19200/60000]\n",
            "loss: 2.007299  [25600/60000]\n",
            "loss: 2.169338  [32000/60000]\n",
            "loss: 2.014208  [38400/60000]\n",
            "loss: 2.117962  [44800/60000]\n",
            "loss: 2.069625  [51200/60000]\n",
            "loss: 2.082407  [57600/60000]\n",
            "\n",
            "Epoch 82\n",
            "loss: 2.219143  [    0/60000]\n",
            "loss: 2.180660  [ 6400/60000]\n",
            "loss: 1.871700  [12800/60000]\n",
            "loss: 1.888808  [19200/60000]\n",
            "loss: 1.766618  [25600/60000]\n",
            "loss: 1.761997  [32000/60000]\n",
            "loss: 1.812189  [38400/60000]\n",
            "loss: 1.747221  [44800/60000]\n",
            "loss: 1.658404  [51200/60000]\n",
            "loss: 1.712555  [57600/60000]\n",
            "\n",
            "Epoch 83\n",
            "loss: 1.680563  [    0/60000]\n",
            "loss: 1.682877  [ 6400/60000]\n",
            "loss: 1.756109  [12800/60000]\n",
            "loss: 1.666484  [19200/60000]\n",
            "loss: 1.707158  [25600/60000]\n",
            "loss: 1.760339  [32000/60000]\n",
            "loss: 1.732454  [38400/60000]\n",
            "loss: 1.757699  [44800/60000]\n",
            "loss: 1.653753  [51200/60000]\n",
            "loss: 1.689817  [57600/60000]\n",
            "\n",
            "Epoch 84\n",
            "loss: 1.720448  [    0/60000]\n",
            "loss: 1.680203  [ 6400/60000]\n",
            "loss: 1.757468  [12800/60000]\n",
            "loss: 1.663375  [19200/60000]\n",
            "loss: 1.688476  [25600/60000]\n",
            "loss: 1.762562  [32000/60000]\n",
            "loss: 1.727181  [38400/60000]\n",
            "loss: 1.755870  [44800/60000]\n",
            "loss: 1.651634  [51200/60000]\n",
            "loss: 1.685158  [57600/60000]\n",
            "\n",
            "Epoch 85\n",
            "loss: 1.736878  [    0/60000]\n",
            "loss: 1.735925  [ 6400/60000]\n",
            "loss: 1.804629  [12800/60000]\n",
            "loss: 1.675809  [19200/60000]\n",
            "loss: 1.686729  [25600/60000]\n",
            "loss: 1.797363  [32000/60000]\n",
            "loss: 1.724127  [38400/60000]\n",
            "loss: 1.751028  [44800/60000]\n",
            "loss: 1.654857  [51200/60000]\n",
            "loss: 1.673846  [57600/60000]\n",
            "\n",
            "Epoch 86\n",
            "loss: 1.735790  [    0/60000]\n",
            "loss: 1.706586  [ 6400/60000]\n",
            "loss: 1.773925  [12800/60000]\n",
            "loss: 1.709893  [19200/60000]\n",
            "loss: 1.662730  [25600/60000]\n",
            "loss: 1.771699  [32000/60000]\n",
            "loss: 1.793940  [38400/60000]\n",
            "loss: 1.756936  [44800/60000]\n",
            "loss: 1.651664  [51200/60000]\n",
            "loss: 1.709067  [57600/60000]\n",
            "\n",
            "Epoch 87\n",
            "loss: 1.729924  [    0/60000]\n",
            "loss: 1.685287  [ 6400/60000]\n",
            "loss: 1.752800  [12800/60000]\n",
            "loss: 1.664594  [19200/60000]\n",
            "loss: 1.741423  [25600/60000]\n",
            "loss: 1.774907  [32000/60000]\n",
            "loss: 1.771046  [38400/60000]\n",
            "loss: 1.752876  [44800/60000]\n",
            "loss: 1.651111  [51200/60000]\n",
            "loss: 1.708780  [57600/60000]\n",
            "\n",
            "Epoch 88\n",
            "loss: 1.729057  [    0/60000]\n",
            "loss: 1.684551  [ 6400/60000]\n",
            "loss: 1.751913  [12800/60000]\n",
            "loss: 1.662996  [19200/60000]\n",
            "loss: 1.746039  [25600/60000]\n",
            "loss: 1.774749  [32000/60000]\n",
            "loss: 1.728678  [38400/60000]\n",
            "loss: 1.755444  [44800/60000]\n",
            "loss: 1.649778  [51200/60000]\n",
            "loss: 1.662309  [57600/60000]\n",
            "\n",
            "Epoch 89\n",
            "loss: 1.720335  [    0/60000]\n",
            "loss: 1.686934  [ 6400/60000]\n",
            "loss: 1.762425  [12800/60000]\n",
            "loss: 1.736289  [19200/60000]\n",
            "loss: 1.758507  [25600/60000]\n",
            "loss: 1.765877  [32000/60000]\n",
            "loss: 1.711915  [38400/60000]\n",
            "loss: 1.894854  [44800/60000]\n",
            "loss: 1.757713  [51200/60000]\n",
            "loss: 1.796817  [57600/60000]\n",
            "\n",
            "Epoch 90\n",
            "loss: 1.825805  [    0/60000]\n",
            "loss: 1.789212  [ 6400/60000]\n",
            "loss: 1.815097  [12800/60000]\n",
            "loss: 1.841961  [19200/60000]\n",
            "loss: 1.806578  [25600/60000]\n",
            "loss: 1.811753  [32000/60000]\n",
            "loss: 1.729447  [38400/60000]\n",
            "loss: 1.708425  [44800/60000]\n",
            "loss: 1.658286  [51200/60000]\n",
            "loss: 1.713226  [57600/60000]\n",
            "\n",
            "Epoch 91\n",
            "loss: 1.721500  [    0/60000]\n",
            "loss: 1.686085  [ 6400/60000]\n",
            "loss: 1.763517  [12800/60000]\n",
            "loss: 1.661430  [19200/60000]\n",
            "loss: 1.685817  [25600/60000]\n",
            "loss: 1.763195  [32000/60000]\n",
            "loss: 1.708230  [38400/60000]\n",
            "loss: 1.709744  [44800/60000]\n",
            "loss: 1.651832  [51200/60000]\n",
            "loss: 1.667752  [57600/60000]\n",
            "\n",
            "Epoch 92\n",
            "loss: 1.713430  [    0/60000]\n",
            "loss: 1.680802  [ 6400/60000]\n",
            "loss: 1.735165  [12800/60000]\n",
            "loss: 1.668795  [19200/60000]\n",
            "loss: 1.669390  [25600/60000]\n",
            "loss: 1.769515  [32000/60000]\n",
            "loss: 1.705925  [38400/60000]\n",
            "loss: 1.710948  [44800/60000]\n",
            "loss: 1.649446  [51200/60000]\n",
            "loss: 1.666848  [57600/60000]\n",
            "\n",
            "Epoch 93\n",
            "loss: 1.713300  [    0/60000]\n",
            "loss: 1.680562  [ 6400/60000]\n",
            "loss: 1.737971  [12800/60000]\n",
            "loss: 1.667705  [19200/60000]\n",
            "loss: 1.667596  [25600/60000]\n",
            "loss: 1.770566  [32000/60000]\n",
            "loss: 1.705654  [38400/60000]\n",
            "loss: 1.710868  [44800/60000]\n",
            "loss: 1.648875  [51200/60000]\n",
            "loss: 1.666677  [57600/60000]\n",
            "\n",
            "Epoch 94\n",
            "loss: 1.713412  [    0/60000]\n",
            "loss: 1.680675  [ 6400/60000]\n",
            "loss: 1.738817  [12800/60000]\n",
            "loss: 1.667305  [19200/60000]\n",
            "loss: 1.666967  [25600/60000]\n",
            "loss: 1.770835  [32000/60000]\n",
            "loss: 1.705568  [38400/60000]\n",
            "loss: 1.710758  [44800/60000]\n",
            "loss: 1.648661  [51200/60000]\n",
            "loss: 1.666623  [57600/60000]\n",
            "\n",
            "Epoch 95\n",
            "loss: 1.713482  [    0/60000]\n",
            "loss: 1.680762  [ 6400/60000]\n",
            "loss: 1.739162  [12800/60000]\n",
            "loss: 1.667121  [19200/60000]\n",
            "loss: 1.666714  [25600/60000]\n",
            "loss: 1.770923  [32000/60000]\n",
            "loss: 1.705582  [38400/60000]\n",
            "loss: 1.710662  [44800/60000]\n",
            "loss: 1.648672  [51200/60000]\n",
            "loss: 1.666615  [57600/60000]\n",
            "\n",
            "Epoch 96\n",
            "loss: 1.713501  [    0/60000]\n",
            "loss: 1.680766  [ 6400/60000]\n",
            "loss: 1.739200  [12800/60000]\n",
            "loss: 1.667107  [19200/60000]\n",
            "loss: 1.666675  [25600/60000]\n",
            "loss: 1.770940  [32000/60000]\n",
            "loss: 1.705521  [38400/60000]\n",
            "loss: 1.710666  [44800/60000]\n",
            "loss: 1.648560  [51200/60000]\n",
            "loss: 1.666584  [57600/60000]\n",
            "\n",
            "Epoch 97\n",
            "loss: 1.713534  [    0/60000]\n",
            "loss: 1.680820  [ 6400/60000]\n",
            "loss: 1.739382  [12800/60000]\n",
            "loss: 1.667004  [19200/60000]\n",
            "loss: 1.666597  [25600/60000]\n",
            "loss: 1.770993  [32000/60000]\n",
            "loss: 1.705494  [38400/60000]\n",
            "loss: 1.710662  [44800/60000]\n",
            "loss: 1.648508  [51200/60000]\n",
            "loss: 1.666564  [57600/60000]\n",
            "\n",
            "Epoch 98\n",
            "loss: 1.713554  [    0/60000]\n",
            "loss: 1.680851  [ 6400/60000]\n",
            "loss: 1.739483  [12800/60000]\n",
            "loss: 1.666949  [19200/60000]\n",
            "loss: 1.666573  [25600/60000]\n",
            "loss: 1.771021  [32000/60000]\n",
            "loss: 1.705477  [38400/60000]\n",
            "loss: 1.710659  [44800/60000]\n",
            "loss: 1.648482  [51200/60000]\n",
            "loss: 1.666550  [57600/60000]\n",
            "\n",
            "Epoch 99\n",
            "loss: 1.713566  [    0/60000]\n",
            "loss: 1.680869  [ 6400/60000]\n",
            "loss: 1.739548  [12800/60000]\n",
            "loss: 1.666917  [19200/60000]\n",
            "loss: 1.666571  [25600/60000]\n",
            "loss: 1.771039  [32000/60000]\n",
            "loss: 1.705465  [38400/60000]\n",
            "loss: 1.710657  [44800/60000]\n",
            "loss: 1.648468  [51200/60000]\n",
            "loss: 1.666538  [57600/60000]\n",
            "\n",
            "Epoch 100\n",
            "loss: 1.713574  [    0/60000]\n",
            "loss: 1.680880  [ 6400/60000]\n",
            "loss: 1.739595  [12800/60000]\n",
            "loss: 1.666898  [19200/60000]\n",
            "loss: 1.666578  [25600/60000]\n",
            "loss: 1.771052  [32000/60000]\n",
            "loss: 1.705456  [38400/60000]\n",
            "loss: 1.710655  [44800/60000]\n",
            "loss: 1.648460  [51200/60000]\n",
            "loss: 1.666527  [57600/60000]\n",
            "Final test:\n",
            "Test Error: \n",
            " Accuracy: 19.9%, Avg loss: 1.708759 \n",
            "\n",
            "\n",
            "Training with learning rate: 0.1\n",
            "\n",
            "\n",
            "Epoch 1\n",
            "loss: 2.306096  [    0/60000]\n",
            "loss: 0.898405  [ 6400/60000]\n",
            "loss: 0.579556  [12800/60000]\n",
            "loss: 0.698156  [19200/60000]\n",
            "loss: 0.605155  [25600/60000]\n",
            "loss: 0.517756  [32000/60000]\n",
            "loss: 0.537400  [38400/60000]\n",
            "loss: 0.597705  [44800/60000]\n",
            "loss: 0.595275  [51200/60000]\n",
            "loss: 0.455876  [57600/60000]\n",
            "\n",
            "Epoch 2\n",
            "loss: 0.437427  [    0/60000]\n",
            "loss: 0.442606  [ 6400/60000]\n",
            "loss: 0.377510  [12800/60000]\n",
            "loss: 0.424571  [19200/60000]\n",
            "loss: 0.416017  [25600/60000]\n",
            "loss: 0.450120  [32000/60000]\n",
            "loss: 0.412350  [38400/60000]\n",
            "loss: 0.514848  [44800/60000]\n",
            "loss: 0.495961  [51200/60000]\n",
            "loss: 0.431086  [57600/60000]\n",
            "\n",
            "Epoch 3\n",
            "loss: 0.326055  [    0/60000]\n",
            "loss: 0.368971  [ 6400/60000]\n",
            "loss: 0.313092  [12800/60000]\n",
            "loss: 0.356346  [19200/60000]\n",
            "loss: 0.345711  [25600/60000]\n",
            "loss: 0.430792  [32000/60000]\n",
            "loss: 0.353265  [38400/60000]\n",
            "loss: 0.461637  [44800/60000]\n",
            "loss: 0.444312  [51200/60000]\n",
            "loss: 0.409110  [57600/60000]\n",
            "\n",
            "Epoch 4\n",
            "loss: 0.268566  [    0/60000]\n",
            "loss: 0.340588  [ 6400/60000]\n",
            "loss: 0.271339  [12800/60000]\n",
            "loss: 0.311791  [19200/60000]\n",
            "loss: 0.321367  [25600/60000]\n",
            "loss: 0.408487  [32000/60000]\n",
            "loss: 0.317364  [38400/60000]\n",
            "loss: 0.434365  [44800/60000]\n",
            "loss: 0.404037  [51200/60000]\n",
            "loss: 0.391238  [57600/60000]\n",
            "\n",
            "Epoch 5\n",
            "loss: 0.228194  [    0/60000]\n",
            "loss: 0.327077  [ 6400/60000]\n",
            "loss: 0.239319  [12800/60000]\n",
            "loss: 0.283947  [19200/60000]\n",
            "loss: 0.312240  [25600/60000]\n",
            "loss: 0.382689  [32000/60000]\n",
            "loss: 0.302572  [38400/60000]\n",
            "loss: 0.409393  [44800/60000]\n",
            "loss: 0.371039  [51200/60000]\n",
            "loss: 0.371106  [57600/60000]\n",
            "\n",
            "Epoch 6\n",
            "loss: 0.228849  [    0/60000]\n",
            "loss: 0.320637  [ 6400/60000]\n",
            "loss: 0.217200  [12800/60000]\n",
            "loss: 0.265087  [19200/60000]\n",
            "loss: 0.301985  [25600/60000]\n",
            "loss: 0.363771  [32000/60000]\n",
            "loss: 0.283526  [38400/60000]\n",
            "loss: 0.368867  [44800/60000]\n",
            "loss: 0.355607  [51200/60000]\n",
            "loss: 0.359744  [57600/60000]\n",
            "\n",
            "Epoch 7\n",
            "loss: 0.210232  [    0/60000]\n",
            "loss: 0.305692  [ 6400/60000]\n",
            "loss: 0.197204  [12800/60000]\n",
            "loss: 0.248447  [19200/60000]\n",
            "loss: 0.306324  [25600/60000]\n",
            "loss: 0.349779  [32000/60000]\n",
            "loss: 0.265312  [38400/60000]\n",
            "loss: 0.345365  [44800/60000]\n",
            "loss: 0.347878  [51200/60000]\n",
            "loss: 0.351897  [57600/60000]\n",
            "\n",
            "Epoch 8\n",
            "loss: 0.198364  [    0/60000]\n",
            "loss: 0.297274  [ 6400/60000]\n",
            "loss: 0.182092  [12800/60000]\n",
            "loss: 0.233170  [19200/60000]\n",
            "loss: 0.292860  [25600/60000]\n",
            "loss: 0.331077  [32000/60000]\n",
            "loss: 0.256145  [38400/60000]\n",
            "loss: 0.321692  [44800/60000]\n",
            "loss: 0.330351  [51200/60000]\n",
            "loss: 0.323277  [57600/60000]\n",
            "\n",
            "Epoch 9\n",
            "loss: 0.184290  [    0/60000]\n",
            "loss: 0.283274  [ 6400/60000]\n",
            "loss: 0.177487  [12800/60000]\n",
            "loss: 0.221630  [19200/60000]\n",
            "loss: 0.294652  [25600/60000]\n",
            "loss: 0.318697  [32000/60000]\n",
            "loss: 0.246744  [38400/60000]\n",
            "loss: 0.298785  [44800/60000]\n",
            "loss: 0.304208  [51200/60000]\n",
            "loss: 0.305632  [57600/60000]\n",
            "\n",
            "Epoch 10\n",
            "loss: 0.183819  [    0/60000]\n",
            "loss: 0.271911  [ 6400/60000]\n",
            "loss: 0.162395  [12800/60000]\n",
            "loss: 0.210859  [19200/60000]\n",
            "loss: 0.296625  [25600/60000]\n",
            "loss: 0.297838  [32000/60000]\n",
            "loss: 0.240041  [38400/60000]\n",
            "loss: 0.287988  [44800/60000]\n",
            "loss: 0.297789  [51200/60000]\n",
            "loss: 0.285267  [57600/60000]\n",
            "\n",
            "Epoch 11\n",
            "loss: 0.181096  [    0/60000]\n",
            "loss: 0.251244  [ 6400/60000]\n",
            "loss: 0.156166  [12800/60000]\n",
            "loss: 0.193816  [19200/60000]\n",
            "loss: 0.297219  [25600/60000]\n",
            "loss: 0.293131  [32000/60000]\n",
            "loss: 0.232841  [38400/60000]\n",
            "loss: 0.266149  [44800/60000]\n",
            "loss: 0.283406  [51200/60000]\n",
            "loss: 0.278079  [57600/60000]\n",
            "\n",
            "Epoch 12\n",
            "loss: 0.177124  [    0/60000]\n",
            "loss: 0.244109  [ 6400/60000]\n",
            "loss: 0.149076  [12800/60000]\n",
            "loss: 0.187168  [19200/60000]\n",
            "loss: 0.280059  [25600/60000]\n",
            "loss: 0.274460  [32000/60000]\n",
            "loss: 0.221438  [38400/60000]\n",
            "loss: 0.258491  [44800/60000]\n",
            "loss: 0.260761  [51200/60000]\n",
            "loss: 0.272612  [57600/60000]\n",
            "\n",
            "Epoch 13\n",
            "loss: 0.172789  [    0/60000]\n",
            "loss: 0.231105  [ 6400/60000]\n",
            "loss: 0.150554  [12800/60000]\n",
            "loss: 0.171305  [19200/60000]\n",
            "loss: 0.269325  [25600/60000]\n",
            "loss: 0.269349  [32000/60000]\n",
            "loss: 0.215787  [38400/60000]\n",
            "loss: 0.245307  [44800/60000]\n",
            "loss: 0.255328  [51200/60000]\n",
            "loss: 0.266053  [57600/60000]\n",
            "\n",
            "Epoch 14\n",
            "loss: 0.170442  [    0/60000]\n",
            "loss: 0.221481  [ 6400/60000]\n",
            "loss: 0.146970  [12800/60000]\n",
            "loss: 0.154417  [19200/60000]\n",
            "loss: 0.262222  [25600/60000]\n",
            "loss: 0.264379  [32000/60000]\n",
            "loss: 0.203713  [38400/60000]\n",
            "loss: 0.240315  [44800/60000]\n",
            "loss: 0.247579  [51200/60000]\n",
            "loss: 0.259244  [57600/60000]\n",
            "\n",
            "Epoch 15\n",
            "loss: 0.159120  [    0/60000]\n",
            "loss: 0.210951  [ 6400/60000]\n",
            "loss: 0.140504  [12800/60000]\n",
            "loss: 0.144025  [19200/60000]\n",
            "loss: 0.239325  [25600/60000]\n",
            "loss: 0.250731  [32000/60000]\n",
            "loss: 0.195742  [38400/60000]\n",
            "loss: 0.222943  [44800/60000]\n",
            "loss: 0.242503  [51200/60000]\n",
            "loss: 0.245885  [57600/60000]\n",
            "\n",
            "Epoch 16\n",
            "loss: 0.159629  [    0/60000]\n",
            "loss: 0.206062  [ 6400/60000]\n",
            "loss: 0.136910  [12800/60000]\n",
            "loss: 0.140942  [19200/60000]\n",
            "loss: 0.244015  [25600/60000]\n",
            "loss: 0.244104  [32000/60000]\n",
            "loss: 0.174616  [38400/60000]\n",
            "loss: 0.216248  [44800/60000]\n",
            "loss: 0.239977  [51200/60000]\n",
            "loss: 0.232192  [57600/60000]\n",
            "\n",
            "Epoch 17\n",
            "loss: 0.165167  [    0/60000]\n",
            "loss: 0.190485  [ 6400/60000]\n",
            "loss: 0.124431  [12800/60000]\n",
            "loss: 0.137465  [19200/60000]\n",
            "loss: 0.239175  [25600/60000]\n",
            "loss: 0.233649  [32000/60000]\n",
            "loss: 0.160629  [38400/60000]\n",
            "loss: 0.184843  [44800/60000]\n",
            "loss: 0.223809  [51200/60000]\n",
            "loss: 0.208630  [57600/60000]\n",
            "\n",
            "Epoch 18\n",
            "loss: 0.162467  [    0/60000]\n",
            "loss: 0.179285  [ 6400/60000]\n",
            "loss: 0.121123  [12800/60000]\n",
            "loss: 0.129795  [19200/60000]\n",
            "loss: 0.226132  [25600/60000]\n",
            "loss: 0.222629  [32000/60000]\n",
            "loss: 0.157079  [38400/60000]\n",
            "loss: 0.196697  [44800/60000]\n",
            "loss: 0.206859  [51200/60000]\n",
            "loss: 0.212769  [57600/60000]\n",
            "\n",
            "Epoch 19\n",
            "loss: 0.150822  [    0/60000]\n",
            "loss: 0.172557  [ 6400/60000]\n",
            "loss: 0.116480  [12800/60000]\n",
            "loss: 0.125093  [19200/60000]\n",
            "loss: 0.213031  [25600/60000]\n",
            "loss: 0.217768  [32000/60000]\n",
            "loss: 0.149879  [38400/60000]\n",
            "loss: 0.186193  [44800/60000]\n",
            "loss: 0.214184  [51200/60000]\n",
            "loss: 0.224427  [57600/60000]\n",
            "\n",
            "Epoch 20\n",
            "loss: 0.148463  [    0/60000]\n",
            "loss: 0.168795  [ 6400/60000]\n",
            "loss: 0.108686  [12800/60000]\n",
            "loss: 0.106204  [19200/60000]\n",
            "loss: 0.198577  [25600/60000]\n",
            "loss: 0.218532  [32000/60000]\n",
            "loss: 0.148174  [38400/60000]\n",
            "loss: 0.189826  [44800/60000]\n",
            "loss: 0.182107  [51200/60000]\n",
            "loss: 0.185634  [57600/60000]\n",
            "\n",
            "Epoch 21\n",
            "loss: 0.141332  [    0/60000]\n",
            "loss: 0.165527  [ 6400/60000]\n",
            "loss: 0.096590  [12800/60000]\n",
            "loss: 0.109952  [19200/60000]\n",
            "loss: 0.186573  [25600/60000]\n",
            "loss: 0.216904  [32000/60000]\n",
            "loss: 0.134612  [38400/60000]\n",
            "loss: 0.213471  [44800/60000]\n",
            "loss: 0.180825  [51200/60000]\n",
            "loss: 0.189668  [57600/60000]\n",
            "\n",
            "Epoch 22\n",
            "loss: 0.132874  [    0/60000]\n",
            "loss: 0.166950  [ 6400/60000]\n",
            "loss: 0.095466  [12800/60000]\n",
            "loss: 0.097655  [19200/60000]\n",
            "loss: 0.173317  [25600/60000]\n",
            "loss: 0.212976  [32000/60000]\n",
            "loss: 0.130077  [38400/60000]\n",
            "loss: 0.170597  [44800/60000]\n",
            "loss: 0.163983  [51200/60000]\n",
            "loss: 0.195751  [57600/60000]\n",
            "\n",
            "Epoch 23\n",
            "loss: 0.133899  [    0/60000]\n",
            "loss: 0.160826  [ 6400/60000]\n",
            "loss: 0.098704  [12800/60000]\n",
            "loss: 0.103562  [19200/60000]\n",
            "loss: 0.165064  [25600/60000]\n",
            "loss: 0.198781  [32000/60000]\n",
            "loss: 0.129666  [38400/60000]\n",
            "loss: 0.161973  [44800/60000]\n",
            "loss: 0.143831  [51200/60000]\n",
            "loss: 0.176928  [57600/60000]\n",
            "\n",
            "Epoch 24\n",
            "loss: 0.126551  [    0/60000]\n",
            "loss: 0.149445  [ 6400/60000]\n",
            "loss: 0.084914  [12800/60000]\n",
            "loss: 0.095326  [19200/60000]\n",
            "loss: 0.143812  [25600/60000]\n",
            "loss: 0.184456  [32000/60000]\n",
            "loss: 0.126476  [38400/60000]\n",
            "loss: 0.161102  [44800/60000]\n",
            "loss: 0.130618  [51200/60000]\n",
            "loss: 0.183757  [57600/60000]\n",
            "\n",
            "Epoch 25\n",
            "loss: 0.121469  [    0/60000]\n",
            "loss: 0.154779  [ 6400/60000]\n",
            "loss: 0.094816  [12800/60000]\n",
            "loss: 0.087337  [19200/60000]\n",
            "loss: 0.147951  [25600/60000]\n",
            "loss: 0.187269  [32000/60000]\n",
            "loss: 0.122487  [38400/60000]\n",
            "loss: 0.146666  [44800/60000]\n",
            "loss: 0.122532  [51200/60000]\n",
            "loss: 0.165922  [57600/60000]\n",
            "\n",
            "Epoch 26\n",
            "loss: 0.119775  [    0/60000]\n",
            "loss: 0.144093  [ 6400/60000]\n",
            "loss: 0.080424  [12800/60000]\n",
            "loss: 0.087501  [19200/60000]\n",
            "loss: 0.132281  [25600/60000]\n",
            "loss: 0.179511  [32000/60000]\n",
            "loss: 0.121121  [38400/60000]\n",
            "loss: 0.150185  [44800/60000]\n",
            "loss: 0.141385  [51200/60000]\n",
            "loss: 0.219865  [57600/60000]\n",
            "\n",
            "Epoch 27\n",
            "loss: 0.139932  [    0/60000]\n",
            "loss: 0.130189  [ 6400/60000]\n",
            "loss: 0.076103  [12800/60000]\n",
            "loss: 0.091384  [19200/60000]\n",
            "loss: 0.137673  [25600/60000]\n",
            "loss: 0.170481  [32000/60000]\n",
            "loss: 0.118830  [38400/60000]\n",
            "loss: 0.129212  [44800/60000]\n",
            "loss: 0.117240  [51200/60000]\n",
            "loss: 0.161446  [57600/60000]\n",
            "\n",
            "Epoch 28\n",
            "loss: 0.100643  [    0/60000]\n",
            "loss: 0.101795  [ 6400/60000]\n",
            "loss: 0.061569  [12800/60000]\n",
            "loss: 0.087504  [19200/60000]\n",
            "loss: 0.148910  [25600/60000]\n",
            "loss: 0.182465  [32000/60000]\n",
            "loss: 0.099412  [38400/60000]\n",
            "loss: 0.110199  [44800/60000]\n",
            "loss: 0.132346  [51200/60000]\n",
            "loss: 0.149642  [57600/60000]\n",
            "\n",
            "Epoch 29\n",
            "loss: 0.120413  [    0/60000]\n",
            "loss: 0.103775  [ 6400/60000]\n",
            "loss: 0.065328  [12800/60000]\n",
            "loss: 0.066003  [19200/60000]\n",
            "loss: 0.112706  [25600/60000]\n",
            "loss: 0.163641  [32000/60000]\n",
            "loss: 0.105957  [38400/60000]\n",
            "loss: 0.108382  [44800/60000]\n",
            "loss: 0.130213  [51200/60000]\n",
            "loss: 0.171757  [57600/60000]\n",
            "\n",
            "Epoch 30\n",
            "loss: 0.159887  [    0/60000]\n",
            "loss: 0.095596  [ 6400/60000]\n",
            "loss: 0.061120  [12800/60000]\n",
            "loss: 0.083060  [19200/60000]\n",
            "loss: 0.104462  [25600/60000]\n",
            "loss: 0.170971  [32000/60000]\n",
            "loss: 0.106976  [38400/60000]\n",
            "loss: 0.097721  [44800/60000]\n",
            "loss: 0.132499  [51200/60000]\n",
            "loss: 0.144347  [57600/60000]\n",
            "\n",
            "Epoch 31\n",
            "loss: 0.109174  [    0/60000]\n",
            "loss: 0.095781  [ 6400/60000]\n",
            "loss: 0.049096  [12800/60000]\n",
            "loss: 0.059362  [19200/60000]\n",
            "loss: 0.118394  [25600/60000]\n",
            "loss: 0.146466  [32000/60000]\n",
            "loss: 0.110058  [38400/60000]\n",
            "loss: 0.100120  [44800/60000]\n",
            "loss: 0.141517  [51200/60000]\n",
            "loss: 0.135789  [57600/60000]\n",
            "\n",
            "Epoch 32\n",
            "loss: 0.101741  [    0/60000]\n",
            "loss: 0.071352  [ 6400/60000]\n",
            "loss: 0.057249  [12800/60000]\n",
            "loss: 0.056587  [19200/60000]\n",
            "loss: 0.098301  [25600/60000]\n",
            "loss: 0.148041  [32000/60000]\n",
            "loss: 0.117024  [38400/60000]\n",
            "loss: 0.104841  [44800/60000]\n",
            "loss: 0.111572  [51200/60000]\n",
            "loss: 0.140113  [57600/60000]\n",
            "\n",
            "Epoch 33\n",
            "loss: 0.117805  [    0/60000]\n",
            "loss: 0.058844  [ 6400/60000]\n",
            "loss: 0.045212  [12800/60000]\n",
            "loss: 0.046068  [19200/60000]\n",
            "loss: 0.105722  [25600/60000]\n",
            "loss: 0.169332  [32000/60000]\n",
            "loss: 0.093077  [38400/60000]\n",
            "loss: 0.062567  [44800/60000]\n",
            "loss: 0.094101  [51200/60000]\n",
            "loss: 0.114964  [57600/60000]\n",
            "\n",
            "Epoch 34\n",
            "loss: 0.092404  [    0/60000]\n",
            "loss: 0.069343  [ 6400/60000]\n",
            "loss: 0.039095  [12800/60000]\n",
            "loss: 0.059409  [19200/60000]\n",
            "loss: 0.120637  [25600/60000]\n",
            "loss: 0.164168  [32000/60000]\n",
            "loss: 0.063558  [38400/60000]\n",
            "loss: 0.072118  [44800/60000]\n",
            "loss: 0.080434  [51200/60000]\n",
            "loss: 0.107629  [57600/60000]\n",
            "\n",
            "Epoch 35\n",
            "loss: 0.077946  [    0/60000]\n",
            "loss: 0.053793  [ 6400/60000]\n",
            "loss: 0.066912  [12800/60000]\n",
            "loss: 0.059291  [19200/60000]\n",
            "loss: 0.131380  [25600/60000]\n",
            "loss: 0.160487  [32000/60000]\n",
            "loss: 0.072263  [38400/60000]\n",
            "loss: 0.074608  [44800/60000]\n",
            "loss: 0.118019  [51200/60000]\n",
            "loss: 0.083896  [57600/60000]\n",
            "\n",
            "Epoch 36\n",
            "loss: 0.094120  [    0/60000]\n",
            "loss: 0.063387  [ 6400/60000]\n",
            "loss: 0.061037  [12800/60000]\n",
            "loss: 0.044818  [19200/60000]\n",
            "loss: 0.136899  [25600/60000]\n",
            "loss: 0.130346  [32000/60000]\n",
            "loss: 0.085914  [38400/60000]\n",
            "loss: 0.077972  [44800/60000]\n",
            "loss: 0.081795  [51200/60000]\n",
            "loss: 0.080452  [57600/60000]\n",
            "\n",
            "Epoch 37\n",
            "loss: 0.073461  [    0/60000]\n",
            "loss: 0.054962  [ 6400/60000]\n",
            "loss: 0.046297  [12800/60000]\n",
            "loss: 0.048868  [19200/60000]\n",
            "loss: 0.079990  [25600/60000]\n",
            "loss: 0.151434  [32000/60000]\n",
            "loss: 0.092214  [38400/60000]\n",
            "loss: 0.064866  [44800/60000]\n",
            "loss: 0.068156  [51200/60000]\n",
            "loss: 0.111017  [57600/60000]\n",
            "\n",
            "Epoch 38\n",
            "loss: 0.084273  [    0/60000]\n",
            "loss: 0.155131  [ 6400/60000]\n",
            "loss: 0.024356  [12800/60000]\n",
            "loss: 0.035008  [19200/60000]\n",
            "loss: 0.069321  [25600/60000]\n",
            "loss: 0.114619  [32000/60000]\n",
            "loss: 0.051415  [38400/60000]\n",
            "loss: 0.115540  [44800/60000]\n",
            "loss: 0.093003  [51200/60000]\n",
            "loss: 0.098711  [57600/60000]\n",
            "\n",
            "Epoch 39\n",
            "loss: 0.155241  [    0/60000]\n",
            "loss: 0.055873  [ 6400/60000]\n",
            "loss: 0.035409  [12800/60000]\n",
            "loss: 0.048160  [19200/60000]\n",
            "loss: 0.095368  [25600/60000]\n",
            "loss: 0.133023  [32000/60000]\n",
            "loss: 0.073480  [38400/60000]\n",
            "loss: 0.048454  [44800/60000]\n",
            "loss: 0.049554  [51200/60000]\n",
            "loss: 0.103292  [57600/60000]\n",
            "\n",
            "Epoch 40\n",
            "loss: 0.051367  [    0/60000]\n",
            "loss: 0.058311  [ 6400/60000]\n",
            "loss: 0.054284  [12800/60000]\n",
            "loss: 0.029765  [19200/60000]\n",
            "loss: 0.071751  [25600/60000]\n",
            "loss: 0.159304  [32000/60000]\n",
            "loss: 0.064225  [38400/60000]\n",
            "loss: 0.036853  [44800/60000]\n",
            "loss: 0.057763  [51200/60000]\n",
            "loss: 0.085948  [57600/60000]\n",
            "\n",
            "Epoch 41\n",
            "loss: 0.125642  [    0/60000]\n",
            "loss: 0.034931  [ 6400/60000]\n",
            "loss: 0.040042  [12800/60000]\n",
            "loss: 0.054077  [19200/60000]\n",
            "loss: 0.072408  [25600/60000]\n",
            "loss: 0.095848  [32000/60000]\n",
            "loss: 0.034735  [38400/60000]\n",
            "loss: 0.049502  [44800/60000]\n",
            "loss: 0.079622  [51200/60000]\n",
            "loss: 0.072170  [57600/60000]\n",
            "\n",
            "Epoch 42\n",
            "loss: 0.064297  [    0/60000]\n",
            "loss: 0.060828  [ 6400/60000]\n",
            "loss: 0.049129  [12800/60000]\n",
            "loss: 0.047597  [19200/60000]\n",
            "loss: 0.038360  [25600/60000]\n",
            "loss: 0.099384  [32000/60000]\n",
            "loss: 0.049465  [38400/60000]\n",
            "loss: 0.042666  [44800/60000]\n",
            "loss: 0.067046  [51200/60000]\n",
            "loss: 0.060595  [57600/60000]\n",
            "\n",
            "Epoch 43\n",
            "loss: 0.088356  [    0/60000]\n",
            "loss: 0.081898  [ 6400/60000]\n",
            "loss: 0.053742  [12800/60000]\n",
            "loss: 0.032226  [19200/60000]\n",
            "loss: 0.076213  [25600/60000]\n",
            "loss: 0.130142  [32000/60000]\n",
            "loss: 0.059052  [38400/60000]\n",
            "loss: 0.038205  [44800/60000]\n",
            "loss: 0.055921  [51200/60000]\n",
            "loss: 0.094895  [57600/60000]\n",
            "\n",
            "Epoch 44\n",
            "loss: 0.077592  [    0/60000]\n",
            "loss: 0.067452  [ 6400/60000]\n",
            "loss: 0.023426  [12800/60000]\n",
            "loss: 0.028447  [19200/60000]\n",
            "loss: 0.105372  [25600/60000]\n",
            "loss: 0.102502  [32000/60000]\n",
            "loss: 0.029281  [38400/60000]\n",
            "loss: 0.263807  [44800/60000]\n",
            "loss: 0.070466  [51200/60000]\n",
            "loss: 0.131675  [57600/60000]\n",
            "\n",
            "Epoch 45\n",
            "loss: 0.089790  [    0/60000]\n",
            "loss: 0.050517  [ 6400/60000]\n",
            "loss: 0.033800  [12800/60000]\n",
            "loss: 0.031825  [19200/60000]\n",
            "loss: 0.094621  [25600/60000]\n",
            "loss: 0.118966  [32000/60000]\n",
            "loss: 0.046788  [38400/60000]\n",
            "loss: 0.042836  [44800/60000]\n",
            "loss: 0.040094  [51200/60000]\n",
            "loss: 0.060753  [57600/60000]\n",
            "\n",
            "Epoch 46\n",
            "loss: 0.091894  [    0/60000]\n",
            "loss: 0.059329  [ 6400/60000]\n",
            "loss: 0.032248  [12800/60000]\n",
            "loss: 0.028731  [19200/60000]\n",
            "loss: 0.057543  [25600/60000]\n",
            "loss: 0.111637  [32000/60000]\n",
            "loss: 0.048007  [38400/60000]\n",
            "loss: 0.053468  [44800/60000]\n",
            "loss: 0.037476  [51200/60000]\n",
            "loss: 0.062154  [57600/60000]\n",
            "\n",
            "Epoch 47\n",
            "loss: 0.094949  [    0/60000]\n",
            "loss: 0.043385  [ 6400/60000]\n",
            "loss: 0.074850  [12800/60000]\n",
            "loss: 0.024254  [19200/60000]\n",
            "loss: 0.086191  [25600/60000]\n",
            "loss: 0.149233  [32000/60000]\n",
            "loss: 0.031955  [38400/60000]\n",
            "loss: 0.028362  [44800/60000]\n",
            "loss: 0.033045  [51200/60000]\n",
            "loss: 0.037794  [57600/60000]\n",
            "\n",
            "Epoch 48\n",
            "loss: 0.095446  [    0/60000]\n",
            "loss: 0.045550  [ 6400/60000]\n",
            "loss: 0.035610  [12800/60000]\n",
            "loss: 0.034264  [19200/60000]\n",
            "loss: 0.072304  [25600/60000]\n",
            "loss: 0.057282  [32000/60000]\n",
            "loss: 0.020446  [38400/60000]\n",
            "loss: 0.035255  [44800/60000]\n",
            "loss: 0.021784  [51200/60000]\n",
            "loss: 0.081946  [57600/60000]\n",
            "\n",
            "Epoch 49\n",
            "loss: 0.055606  [    0/60000]\n",
            "loss: 0.028577  [ 6400/60000]\n",
            "loss: 0.049924  [12800/60000]\n",
            "loss: 0.035572  [19200/60000]\n",
            "loss: 0.051584  [25600/60000]\n",
            "loss: 0.076317  [32000/60000]\n",
            "loss: 0.100984  [38400/60000]\n",
            "loss: 0.023609  [44800/60000]\n",
            "loss: 0.030118  [51200/60000]\n",
            "loss: 0.045380  [57600/60000]\n",
            "\n",
            "Epoch 50\n",
            "loss: 0.130215  [    0/60000]\n",
            "loss: 0.063257  [ 6400/60000]\n",
            "loss: 0.032179  [12800/60000]\n",
            "loss: 0.018806  [19200/60000]\n",
            "loss: 0.081204  [25600/60000]\n",
            "loss: 0.040197  [32000/60000]\n",
            "loss: 0.044603  [38400/60000]\n",
            "loss: 0.037449  [44800/60000]\n",
            "loss: 0.075183  [51200/60000]\n",
            "loss: 0.059580  [57600/60000]\n",
            "\n",
            "Epoch 51\n",
            "loss: 0.061543  [    0/60000]\n",
            "loss: 0.034509  [ 6400/60000]\n",
            "loss: 0.035752  [12800/60000]\n",
            "loss: 0.012618  [19200/60000]\n",
            "loss: 0.056020  [25600/60000]\n",
            "loss: 0.085913  [32000/60000]\n",
            "loss: 0.056737  [38400/60000]\n",
            "loss: 0.028546  [44800/60000]\n",
            "loss: 0.019924  [51200/60000]\n",
            "loss: 0.103679  [57600/60000]\n",
            "\n",
            "Epoch 52\n",
            "loss: 0.088678  [    0/60000]\n",
            "loss: 0.084045  [ 6400/60000]\n",
            "loss: 0.168002  [12800/60000]\n",
            "loss: 0.033879  [19200/60000]\n",
            "loss: 0.050878  [25600/60000]\n",
            "loss: 0.059265  [32000/60000]\n",
            "loss: 0.025096  [38400/60000]\n",
            "loss: 0.019851  [44800/60000]\n",
            "loss: 0.033968  [51200/60000]\n",
            "loss: 0.090012  [57600/60000]\n",
            "\n",
            "Epoch 53\n",
            "loss: 0.093917  [    0/60000]\n",
            "loss: 0.067894  [ 6400/60000]\n",
            "loss: 0.020762  [12800/60000]\n",
            "loss: 0.012953  [19200/60000]\n",
            "loss: 0.041913  [25600/60000]\n",
            "loss: 0.089121  [32000/60000]\n",
            "loss: 0.014663  [38400/60000]\n",
            "loss: 0.045767  [44800/60000]\n",
            "loss: 0.028969  [51200/60000]\n",
            "loss: 0.052497  [57600/60000]\n",
            "\n",
            "Epoch 54\n",
            "loss: 0.063776  [    0/60000]\n",
            "loss: 0.043108  [ 6400/60000]\n",
            "loss: 0.054267  [12800/60000]\n",
            "loss: 0.043774  [19200/60000]\n",
            "loss: 0.059231  [25600/60000]\n",
            "loss: 0.062383  [32000/60000]\n",
            "loss: 0.047881  [38400/60000]\n",
            "loss: 0.019896  [44800/60000]\n",
            "loss: 0.058244  [51200/60000]\n",
            "loss: 0.043266  [57600/60000]\n",
            "\n",
            "Epoch 55\n",
            "loss: 0.052707  [    0/60000]\n",
            "loss: 0.042589  [ 6400/60000]\n",
            "loss: 0.014738  [12800/60000]\n",
            "loss: 0.033044  [19200/60000]\n",
            "loss: 0.102265  [25600/60000]\n",
            "loss: 0.041747  [32000/60000]\n",
            "loss: 0.022245  [38400/60000]\n",
            "loss: 0.030216  [44800/60000]\n",
            "loss: 0.007835  [51200/60000]\n",
            "loss: 0.034206  [57600/60000]\n",
            "\n",
            "Epoch 56\n",
            "loss: 0.041577  [    0/60000]\n",
            "loss: 0.020294  [ 6400/60000]\n",
            "loss: 0.044067  [12800/60000]\n",
            "loss: 0.009668  [19200/60000]\n",
            "loss: 0.044841  [25600/60000]\n",
            "loss: 0.066537  [32000/60000]\n",
            "loss: 0.026845  [38400/60000]\n",
            "loss: 0.013821  [44800/60000]\n",
            "loss: 0.012798  [51200/60000]\n",
            "loss: 0.033049  [57600/60000]\n",
            "\n",
            "Epoch 57\n",
            "loss: 0.019323  [    0/60000]\n",
            "loss: 0.067472  [ 6400/60000]\n",
            "loss: 0.122639  [12800/60000]\n",
            "loss: 0.019011  [19200/60000]\n",
            "loss: 0.036374  [25600/60000]\n",
            "loss: 0.044405  [32000/60000]\n",
            "loss: 0.034951  [38400/60000]\n",
            "loss: 0.011542  [44800/60000]\n",
            "loss: 0.019011  [51200/60000]\n",
            "loss: 0.110149  [57600/60000]\n",
            "\n",
            "Epoch 58\n",
            "loss: 0.075472  [    0/60000]\n",
            "loss: 0.029864  [ 6400/60000]\n",
            "loss: 0.023761  [12800/60000]\n",
            "loss: 0.010198  [19200/60000]\n",
            "loss: 0.140759  [25600/60000]\n",
            "loss: 0.027763  [32000/60000]\n",
            "loss: 0.016201  [38400/60000]\n",
            "loss: 0.026065  [44800/60000]\n",
            "loss: 0.028149  [51200/60000]\n",
            "loss: 0.056446  [57600/60000]\n",
            "\n",
            "Epoch 59\n",
            "loss: 0.036775  [    0/60000]\n",
            "loss: 0.043026  [ 6400/60000]\n",
            "loss: 0.009954  [12800/60000]\n",
            "loss: 0.018337  [19200/60000]\n",
            "loss: 0.038102  [25600/60000]\n",
            "loss: 0.060322  [32000/60000]\n",
            "loss: 0.038236  [38400/60000]\n",
            "loss: 0.011287  [44800/60000]\n",
            "loss: 0.015148  [51200/60000]\n",
            "loss: 0.073654  [57600/60000]\n",
            "\n",
            "Epoch 60\n",
            "loss: 0.042811  [    0/60000]\n",
            "loss: 0.080859  [ 6400/60000]\n",
            "loss: 0.057189  [12800/60000]\n",
            "loss: 0.015733  [19200/60000]\n",
            "loss: 0.026010  [25600/60000]\n",
            "loss: 0.089377  [32000/60000]\n",
            "loss: 0.026775  [38400/60000]\n",
            "loss: 0.032357  [44800/60000]\n",
            "loss: 0.015411  [51200/60000]\n",
            "loss: 0.070570  [57600/60000]\n",
            "\n",
            "Epoch 61\n",
            "loss: 0.035540  [    0/60000]\n",
            "loss: 0.042868  [ 6400/60000]\n",
            "loss: 0.019804  [12800/60000]\n",
            "loss: 0.027337  [19200/60000]\n",
            "loss: 0.034291  [25600/60000]\n",
            "loss: 0.019055  [32000/60000]\n",
            "loss: 0.030832  [38400/60000]\n",
            "loss: 0.027197  [44800/60000]\n",
            "loss: 0.015391  [51200/60000]\n",
            "loss: 0.077989  [57600/60000]\n",
            "\n",
            "Epoch 62\n",
            "loss: 0.029509  [    0/60000]\n",
            "loss: 0.045034  [ 6400/60000]\n",
            "loss: 0.021989  [12800/60000]\n",
            "loss: 0.011369  [19200/60000]\n",
            "loss: 0.036182  [25600/60000]\n",
            "loss: 0.029053  [32000/60000]\n",
            "loss: 0.048991  [38400/60000]\n",
            "loss: 0.027315  [44800/60000]\n",
            "loss: 0.015836  [51200/60000]\n",
            "loss: 0.048580  [57600/60000]\n",
            "\n",
            "Epoch 63\n",
            "loss: 0.135180  [    0/60000]\n",
            "loss: 0.035352  [ 6400/60000]\n",
            "loss: 0.035485  [12800/60000]\n",
            "loss: 0.020279  [19200/60000]\n",
            "loss: 0.029699  [25600/60000]\n",
            "loss: 0.040344  [32000/60000]\n",
            "loss: 0.034177  [38400/60000]\n",
            "loss: 0.015832  [44800/60000]\n",
            "loss: 0.027445  [51200/60000]\n",
            "loss: 0.059801  [57600/60000]\n",
            "\n",
            "Epoch 64\n",
            "loss: 0.035611  [    0/60000]\n",
            "loss: 0.011502  [ 6400/60000]\n",
            "loss: 0.015364  [12800/60000]\n",
            "loss: 0.013921  [19200/60000]\n",
            "loss: 0.061731  [25600/60000]\n",
            "loss: 0.024827  [32000/60000]\n",
            "loss: 0.010150  [38400/60000]\n",
            "loss: 0.021811  [44800/60000]\n",
            "loss: 0.040518  [51200/60000]\n",
            "loss: 0.030333  [57600/60000]\n",
            "\n",
            "Epoch 65\n",
            "loss: 0.022683  [    0/60000]\n",
            "loss: 0.026672  [ 6400/60000]\n",
            "loss: 0.013324  [12800/60000]\n",
            "loss: 0.008344  [19200/60000]\n",
            "loss: 0.022811  [25600/60000]\n",
            "loss: 0.160294  [32000/60000]\n",
            "loss: 0.013973  [38400/60000]\n",
            "loss: 0.083161  [44800/60000]\n",
            "loss: 0.034741  [51200/60000]\n",
            "loss: 0.019359  [57600/60000]\n",
            "\n",
            "Epoch 66\n",
            "loss: 0.064202  [    0/60000]\n",
            "loss: 0.064109  [ 6400/60000]\n",
            "loss: 0.025387  [12800/60000]\n",
            "loss: 0.016600  [19200/60000]\n",
            "loss: 0.049714  [25600/60000]\n",
            "loss: 0.026017  [32000/60000]\n",
            "loss: 0.019186  [38400/60000]\n",
            "loss: 0.007214  [44800/60000]\n",
            "loss: 0.018935  [51200/60000]\n",
            "loss: 0.016309  [57600/60000]\n",
            "\n",
            "Epoch 67\n",
            "loss: 0.025970  [    0/60000]\n",
            "loss: 0.046016  [ 6400/60000]\n",
            "loss: 0.023823  [12800/60000]\n",
            "loss: 0.017345  [19200/60000]\n",
            "loss: 0.026617  [25600/60000]\n",
            "loss: 0.046115  [32000/60000]\n",
            "loss: 0.050823  [38400/60000]\n",
            "loss: 0.019044  [44800/60000]\n",
            "loss: 0.017992  [51200/60000]\n",
            "loss: 0.037497  [57600/60000]\n",
            "\n",
            "Epoch 68\n",
            "loss: 0.043382  [    0/60000]\n",
            "loss: 0.052941  [ 6400/60000]\n",
            "loss: 0.017816  [12800/60000]\n",
            "loss: 0.026032  [19200/60000]\n",
            "loss: 0.013543  [25600/60000]\n",
            "loss: 0.040994  [32000/60000]\n",
            "loss: 0.024501  [38400/60000]\n",
            "loss: 0.023855  [44800/60000]\n",
            "loss: 0.006292  [51200/60000]\n",
            "loss: 0.020395  [57600/60000]\n",
            "\n",
            "Epoch 69\n",
            "loss: 0.019136  [    0/60000]\n",
            "loss: 0.021963  [ 6400/60000]\n",
            "loss: 0.004073  [12800/60000]\n",
            "loss: 0.013211  [19200/60000]\n",
            "loss: 0.016019  [25600/60000]\n",
            "loss: 0.052228  [32000/60000]\n",
            "loss: 0.009112  [38400/60000]\n",
            "loss: 0.031430  [44800/60000]\n",
            "loss: 0.006729  [51200/60000]\n",
            "loss: 0.034443  [57600/60000]\n",
            "\n",
            "Epoch 70\n",
            "loss: 0.047962  [    0/60000]\n",
            "loss: 0.018522  [ 6400/60000]\n",
            "loss: 0.009501  [12800/60000]\n",
            "loss: 0.006708  [19200/60000]\n",
            "loss: 0.042666  [25600/60000]\n",
            "loss: 0.035768  [32000/60000]\n",
            "loss: 0.049915  [38400/60000]\n",
            "loss: 0.015429  [44800/60000]\n",
            "loss: 0.005201  [51200/60000]\n",
            "loss: 0.020145  [57600/60000]\n",
            "\n",
            "Epoch 71\n",
            "loss: 0.026129  [    0/60000]\n",
            "loss: 0.034208  [ 6400/60000]\n",
            "loss: 0.038746  [12800/60000]\n",
            "loss: 0.014786  [19200/60000]\n",
            "loss: 0.065239  [25600/60000]\n",
            "loss: 0.040884  [32000/60000]\n",
            "loss: 0.032206  [38400/60000]\n",
            "loss: 0.004251  [44800/60000]\n",
            "loss: 0.026975  [51200/60000]\n",
            "loss: 0.015675  [57600/60000]\n",
            "\n",
            "Epoch 72\n",
            "loss: 0.093527  [    0/60000]\n",
            "loss: 0.006199  [ 6400/60000]\n",
            "loss: 0.039558  [12800/60000]\n",
            "loss: 0.016172  [19200/60000]\n",
            "loss: 0.030880  [25600/60000]\n",
            "loss: 0.025256  [32000/60000]\n",
            "loss: 0.019873  [38400/60000]\n",
            "loss: 0.030293  [44800/60000]\n",
            "loss: 0.018131  [51200/60000]\n",
            "loss: 0.019326  [57600/60000]\n",
            "\n",
            "Epoch 73\n",
            "loss: 0.046449  [    0/60000]\n",
            "loss: 0.016691  [ 6400/60000]\n",
            "loss: 0.015696  [12800/60000]\n",
            "loss: 0.008077  [19200/60000]\n",
            "loss: 0.051488  [25600/60000]\n",
            "loss: 0.024862  [32000/60000]\n",
            "loss: 0.016616  [38400/60000]\n",
            "loss: 0.016401  [44800/60000]\n",
            "loss: 0.086784  [51200/60000]\n",
            "loss: 0.017272  [57600/60000]\n",
            "\n",
            "Epoch 74\n",
            "loss: 0.025006  [    0/60000]\n",
            "loss: 0.064968  [ 6400/60000]\n",
            "loss: 0.006272  [12800/60000]\n",
            "loss: 0.004337  [19200/60000]\n",
            "loss: 0.039918  [25600/60000]\n",
            "loss: 0.020713  [32000/60000]\n",
            "loss: 0.018905  [38400/60000]\n",
            "loss: 0.006812  [44800/60000]\n",
            "loss: 0.004224  [51200/60000]\n",
            "loss: 0.047315  [57600/60000]\n",
            "\n",
            "Epoch 75\n",
            "loss: 0.023097  [    0/60000]\n",
            "loss: 0.044130  [ 6400/60000]\n",
            "loss: 0.021041  [12800/60000]\n",
            "loss: 0.016523  [19200/60000]\n",
            "loss: 0.013304  [25600/60000]\n",
            "loss: 0.020441  [32000/60000]\n",
            "loss: 0.007852  [38400/60000]\n",
            "loss: 0.009888  [44800/60000]\n",
            "loss: 0.013049  [51200/60000]\n",
            "loss: 0.030065  [57600/60000]\n",
            "\n",
            "Epoch 76\n",
            "loss: 0.029062  [    0/60000]\n",
            "loss: 0.017862  [ 6400/60000]\n",
            "loss: 0.001668  [12800/60000]\n",
            "loss: 0.014676  [19200/60000]\n",
            "loss: 0.024539  [25600/60000]\n",
            "loss: 0.018791  [32000/60000]\n",
            "loss: 0.010835  [38400/60000]\n",
            "loss: 0.010057  [44800/60000]\n",
            "loss: 0.019787  [51200/60000]\n",
            "loss: 0.018949  [57600/60000]\n",
            "\n",
            "Epoch 77\n",
            "loss: 0.024803  [    0/60000]\n",
            "loss: 0.035246  [ 6400/60000]\n",
            "loss: 0.014899  [12800/60000]\n",
            "loss: 0.028770  [19200/60000]\n",
            "loss: 0.026926  [25600/60000]\n",
            "loss: 0.030632  [32000/60000]\n",
            "loss: 0.019364  [38400/60000]\n",
            "loss: 0.007141  [44800/60000]\n",
            "loss: 0.024224  [51200/60000]\n",
            "loss: 0.033670  [57600/60000]\n",
            "\n",
            "Epoch 78\n",
            "loss: 0.020745  [    0/60000]\n",
            "loss: 0.039003  [ 6400/60000]\n",
            "loss: 0.004948  [12800/60000]\n",
            "loss: 0.014673  [19200/60000]\n",
            "loss: 0.012595  [25600/60000]\n",
            "loss: 0.026119  [32000/60000]\n",
            "loss: 0.027861  [38400/60000]\n",
            "loss: 0.026823  [44800/60000]\n",
            "loss: 0.010877  [51200/60000]\n",
            "loss: 0.018467  [57600/60000]\n",
            "\n",
            "Epoch 79\n",
            "loss: 0.018701  [    0/60000]\n",
            "loss: 0.006665  [ 6400/60000]\n",
            "loss: 0.010384  [12800/60000]\n",
            "loss: 0.014292  [19200/60000]\n",
            "loss: 0.040604  [25600/60000]\n",
            "loss: 0.021350  [32000/60000]\n",
            "loss: 0.018390  [38400/60000]\n",
            "loss: 0.009678  [44800/60000]\n",
            "loss: 0.007664  [51200/60000]\n",
            "loss: 0.147388  [57600/60000]\n",
            "\n",
            "Epoch 80\n",
            "loss: 0.043476  [    0/60000]\n",
            "loss: 0.031951  [ 6400/60000]\n",
            "loss: 0.006065  [12800/60000]\n",
            "loss: 0.023958  [19200/60000]\n",
            "loss: 0.008369  [25600/60000]\n",
            "loss: 0.024531  [32000/60000]\n",
            "loss: 0.027870  [38400/60000]\n",
            "loss: 0.027441  [44800/60000]\n",
            "loss: 0.040784  [51200/60000]\n",
            "loss: 0.050487  [57600/60000]\n",
            "\n",
            "Epoch 81\n",
            "loss: 0.041072  [    0/60000]\n",
            "loss: 0.022500  [ 6400/60000]\n",
            "loss: 0.007774  [12800/60000]\n",
            "loss: 0.020734  [19200/60000]\n",
            "loss: 0.025091  [25600/60000]\n",
            "loss: 0.170701  [32000/60000]\n",
            "loss: 0.011723  [38400/60000]\n",
            "loss: 0.011429  [44800/60000]\n",
            "loss: 0.007981  [51200/60000]\n",
            "loss: 0.040496  [57600/60000]\n",
            "\n",
            "Epoch 82\n",
            "loss: 0.028839  [    0/60000]\n",
            "loss: 0.033785  [ 6400/60000]\n",
            "loss: 0.014301  [12800/60000]\n",
            "loss: 0.006358  [19200/60000]\n",
            "loss: 0.009827  [25600/60000]\n",
            "loss: 0.023661  [32000/60000]\n",
            "loss: 0.005605  [38400/60000]\n",
            "loss: 0.017763  [44800/60000]\n",
            "loss: 0.009148  [51200/60000]\n",
            "loss: 0.023476  [57600/60000]\n",
            "\n",
            "Epoch 83\n",
            "loss: 0.011930  [    0/60000]\n",
            "loss: 0.033021  [ 6400/60000]\n",
            "loss: 0.002297  [12800/60000]\n",
            "loss: 0.013158  [19200/60000]\n",
            "loss: 0.016893  [25600/60000]\n",
            "loss: 0.012930  [32000/60000]\n",
            "loss: 0.007665  [38400/60000]\n",
            "loss: 0.016115  [44800/60000]\n",
            "loss: 0.018623  [51200/60000]\n",
            "loss: 0.038098  [57600/60000]\n",
            "\n",
            "Epoch 84\n",
            "loss: 0.009905  [    0/60000]\n",
            "loss: 0.014020  [ 6400/60000]\n",
            "loss: 0.028467  [12800/60000]\n",
            "loss: 0.015883  [19200/60000]\n",
            "loss: 0.026851  [25600/60000]\n",
            "loss: 0.037407  [32000/60000]\n",
            "loss: 0.004907  [38400/60000]\n",
            "loss: 0.005557  [44800/60000]\n",
            "loss: 0.004607  [51200/60000]\n",
            "loss: 0.022816  [57600/60000]\n",
            "\n",
            "Epoch 85\n",
            "loss: 0.006849  [    0/60000]\n",
            "loss: 0.011426  [ 6400/60000]\n",
            "loss: 0.011562  [12800/60000]\n",
            "loss: 0.003979  [19200/60000]\n",
            "loss: 0.030879  [25600/60000]\n",
            "loss: 0.013832  [32000/60000]\n",
            "loss: 0.006531  [38400/60000]\n",
            "loss: 0.021531  [44800/60000]\n",
            "loss: 0.024403  [51200/60000]\n",
            "loss: 0.015774  [57600/60000]\n",
            "\n",
            "Epoch 86\n",
            "loss: 0.037336  [    0/60000]\n",
            "loss: 0.018704  [ 6400/60000]\n",
            "loss: 0.004006  [12800/60000]\n",
            "loss: 0.028569  [19200/60000]\n",
            "loss: 0.046743  [25600/60000]\n",
            "loss: 0.056528  [32000/60000]\n",
            "loss: 0.022336  [38400/60000]\n",
            "loss: 0.014668  [44800/60000]\n",
            "loss: 0.004259  [51200/60000]\n",
            "loss: 0.015374  [57600/60000]\n",
            "\n",
            "Epoch 87\n",
            "loss: 0.094297  [    0/60000]\n",
            "loss: 0.026124  [ 6400/60000]\n",
            "loss: 0.011209  [12800/60000]\n",
            "loss: 0.007611  [19200/60000]\n",
            "loss: 0.020559  [25600/60000]\n",
            "loss: 0.013556  [32000/60000]\n",
            "loss: 0.010968  [38400/60000]\n",
            "loss: 0.003264  [44800/60000]\n",
            "loss: 0.053941  [51200/60000]\n",
            "loss: 0.022265  [57600/60000]\n",
            "\n",
            "Epoch 88\n",
            "loss: 0.016500  [    0/60000]\n",
            "loss: 0.013861  [ 6400/60000]\n",
            "loss: 0.007064  [12800/60000]\n",
            "loss: 0.096976  [19200/60000]\n",
            "loss: 0.008599  [25600/60000]\n",
            "loss: 0.004486  [32000/60000]\n",
            "loss: 0.004942  [38400/60000]\n",
            "loss: 0.004839  [44800/60000]\n",
            "loss: 0.009990  [51200/60000]\n",
            "loss: 0.008317  [57600/60000]\n",
            "\n",
            "Epoch 89\n",
            "loss: 0.102972  [    0/60000]\n",
            "loss: 0.081472  [ 6400/60000]\n",
            "loss: 0.004240  [12800/60000]\n",
            "loss: 0.030555  [19200/60000]\n",
            "loss: 0.010604  [25600/60000]\n",
            "loss: 0.005094  [32000/60000]\n",
            "loss: 0.006065  [38400/60000]\n",
            "loss: 0.013506  [44800/60000]\n",
            "loss: 0.009443  [51200/60000]\n",
            "loss: 0.025782  [57600/60000]\n",
            "\n",
            "Epoch 90\n",
            "loss: 0.028451  [    0/60000]\n",
            "loss: 0.004969  [ 6400/60000]\n",
            "loss: 0.017782  [12800/60000]\n",
            "loss: 0.018079  [19200/60000]\n",
            "loss: 0.011792  [25600/60000]\n",
            "loss: 0.002672  [32000/60000]\n",
            "loss: 0.008148  [38400/60000]\n",
            "loss: 0.009190  [44800/60000]\n",
            "loss: 0.007442  [51200/60000]\n",
            "loss: 0.014362  [57600/60000]\n",
            "\n",
            "Epoch 91\n",
            "loss: 0.025371  [    0/60000]\n",
            "loss: 0.008113  [ 6400/60000]\n",
            "loss: 0.004805  [12800/60000]\n",
            "loss: 0.026626  [19200/60000]\n",
            "loss: 0.067173  [25600/60000]\n",
            "loss: 0.009822  [32000/60000]\n",
            "loss: 0.007201  [38400/60000]\n",
            "loss: 0.026576  [44800/60000]\n",
            "loss: 0.039436  [51200/60000]\n",
            "loss: 0.029098  [57600/60000]\n",
            "\n",
            "Epoch 92\n",
            "loss: 0.041109  [    0/60000]\n",
            "loss: 0.044363  [ 6400/60000]\n",
            "loss: 0.003095  [12800/60000]\n",
            "loss: 0.005868  [19200/60000]\n",
            "loss: 0.011701  [25600/60000]\n",
            "loss: 0.035343  [32000/60000]\n",
            "loss: 0.006313  [38400/60000]\n",
            "loss: 0.006037  [44800/60000]\n",
            "loss: 0.006366  [51200/60000]\n",
            "loss: 0.014070  [57600/60000]\n",
            "\n",
            "Epoch 93\n",
            "loss: 0.042154  [    0/60000]\n",
            "loss: 0.010317  [ 6400/60000]\n",
            "loss: 0.009956  [12800/60000]\n",
            "loss: 0.027924  [19200/60000]\n",
            "loss: 0.002918  [25600/60000]\n",
            "loss: 0.054693  [32000/60000]\n",
            "loss: 0.005464  [38400/60000]\n",
            "loss: 0.003149  [44800/60000]\n",
            "loss: 0.002818  [51200/60000]\n",
            "loss: 0.081289  [57600/60000]\n",
            "\n",
            "Epoch 94\n",
            "loss: 0.172496  [    0/60000]\n",
            "loss: 0.053969  [ 6400/60000]\n",
            "loss: 0.008815  [12800/60000]\n",
            "loss: 0.028601  [19200/60000]\n",
            "loss: 0.021962  [25600/60000]\n",
            "loss: 0.006851  [32000/60000]\n",
            "loss: 0.003645  [38400/60000]\n",
            "loss: 0.003506  [44800/60000]\n",
            "loss: 0.011313  [51200/60000]\n",
            "loss: 0.017024  [57600/60000]\n",
            "\n",
            "Epoch 95\n",
            "loss: 0.017689  [    0/60000]\n",
            "loss: 0.007692  [ 6400/60000]\n",
            "loss: 0.007788  [12800/60000]\n",
            "loss: 0.012269  [19200/60000]\n",
            "loss: 0.009187  [25600/60000]\n",
            "loss: 0.056664  [32000/60000]\n",
            "loss: 0.023673  [38400/60000]\n",
            "loss: 0.003040  [44800/60000]\n",
            "loss: 0.008826  [51200/60000]\n",
            "loss: 0.007235  [57600/60000]\n",
            "\n",
            "Epoch 96\n",
            "loss: 0.026236  [    0/60000]\n",
            "loss: 0.004644  [ 6400/60000]\n",
            "loss: 0.019116  [12800/60000]\n",
            "loss: 0.005003  [19200/60000]\n",
            "loss: 0.004071  [25600/60000]\n",
            "loss: 0.012259  [32000/60000]\n",
            "loss: 0.021189  [38400/60000]\n",
            "loss: 0.005922  [44800/60000]\n",
            "loss: 0.005820  [51200/60000]\n",
            "loss: 0.013545  [57600/60000]\n",
            "\n",
            "Epoch 97\n",
            "loss: 0.018821  [    0/60000]\n",
            "loss: 0.003760  [ 6400/60000]\n",
            "loss: 0.003502  [12800/60000]\n",
            "loss: 0.014419  [19200/60000]\n",
            "loss: 0.021294  [25600/60000]\n",
            "loss: 0.040671  [32000/60000]\n",
            "loss: 0.005191  [38400/60000]\n",
            "loss: 0.003864  [44800/60000]\n",
            "loss: 0.022128  [51200/60000]\n",
            "loss: 0.028558  [57600/60000]\n",
            "\n",
            "Epoch 98\n",
            "loss: 0.035014  [    0/60000]\n",
            "loss: 0.010132  [ 6400/60000]\n",
            "loss: 0.008844  [12800/60000]\n",
            "loss: 0.006368  [19200/60000]\n",
            "loss: 0.002714  [25600/60000]\n",
            "loss: 0.022413  [32000/60000]\n",
            "loss: 0.013459  [38400/60000]\n",
            "loss: 0.012427  [44800/60000]\n",
            "loss: 0.016829  [51200/60000]\n",
            "loss: 0.008665  [57600/60000]\n",
            "\n",
            "Epoch 99\n",
            "loss: 0.014361  [    0/60000]\n",
            "loss: 0.065293  [ 6400/60000]\n",
            "loss: 0.003202  [12800/60000]\n",
            "loss: 0.012299  [19200/60000]\n",
            "loss: 0.008788  [25600/60000]\n",
            "loss: 0.013529  [32000/60000]\n",
            "loss: 0.007481  [38400/60000]\n",
            "loss: 0.011443  [44800/60000]\n",
            "loss: 0.006811  [51200/60000]\n",
            "loss: 0.009416  [57600/60000]\n",
            "\n",
            "Epoch 100\n",
            "loss: 0.025778  [    0/60000]\n",
            "loss: 0.075159  [ 6400/60000]\n",
            "loss: 0.064521  [12800/60000]\n",
            "loss: 0.004573  [19200/60000]\n",
            "loss: 0.008735  [25600/60000]\n",
            "loss: 0.002859  [32000/60000]\n",
            "loss: 0.032288  [38400/60000]\n",
            "loss: 0.001963  [44800/60000]\n",
            "loss: 0.010848  [51200/60000]\n",
            "loss: 0.036870  [57600/60000]\n",
            "Final test:\n",
            "Test Error: \n",
            " Accuracy: 89.2%, Avg loss: 0.769737 \n",
            "\n",
            "\n",
            "Training with learning rate: 0.01\n",
            "\n",
            "\n",
            "Epoch 1\n",
            "loss: 2.314913  [    0/60000]\n",
            "loss: 2.182650  [ 6400/60000]\n",
            "loss: 1.837376  [12800/60000]\n",
            "loss: 1.549077  [19200/60000]\n",
            "loss: 1.183164  [25600/60000]\n",
            "loss: 1.075147  [32000/60000]\n",
            "loss: 1.031737  [38400/60000]\n",
            "loss: 0.878747  [44800/60000]\n",
            "loss: 0.891185  [51200/60000]\n",
            "loss: 0.828335  [57600/60000]\n",
            "\n",
            "Epoch 2\n",
            "loss: 0.818203  [    0/60000]\n",
            "loss: 0.865005  [ 6400/60000]\n",
            "loss: 0.595858  [12800/60000]\n",
            "loss: 0.792915  [19200/60000]\n",
            "loss: 0.686005  [25600/60000]\n",
            "loss: 0.650691  [32000/60000]\n",
            "loss: 0.729858  [38400/60000]\n",
            "loss: 0.684485  [44800/60000]\n",
            "loss: 0.717266  [51200/60000]\n",
            "loss: 0.648593  [57600/60000]\n",
            "\n",
            "Epoch 3\n",
            "loss: 0.578747  [    0/60000]\n",
            "loss: 0.659360  [ 6400/60000]\n",
            "loss: 0.441110  [12800/60000]\n",
            "loss: 0.671448  [19200/60000]\n",
            "loss: 0.597918  [25600/60000]\n",
            "loss: 0.571212  [32000/60000]\n",
            "loss: 0.596482  [38400/60000]\n",
            "loss: 0.640231  [44800/60000]\n",
            "loss: 0.676405  [51200/60000]\n",
            "loss: 0.556774  [57600/60000]\n",
            "\n",
            "Epoch 4\n",
            "loss: 0.478028  [    0/60000]\n",
            "loss: 0.568700  [ 6400/60000]\n",
            "loss: 0.378633  [12800/60000]\n",
            "loss: 0.608286  [19200/60000]\n",
            "loss: 0.541722  [25600/60000]\n",
            "loss: 0.532611  [32000/60000]\n",
            "loss: 0.535507  [38400/60000]\n",
            "loss: 0.639433  [44800/60000]\n",
            "loss: 0.660856  [51200/60000]\n",
            "loss: 0.491977  [57600/60000]\n",
            "\n",
            "Epoch 5\n",
            "loss: 0.416650  [    0/60000]\n",
            "loss: 0.522086  [ 6400/60000]\n",
            "loss: 0.344926  [12800/60000]\n",
            "loss: 0.568096  [19200/60000]\n",
            "loss: 0.494508  [25600/60000]\n",
            "loss: 0.502229  [32000/60000]\n",
            "loss: 0.502664  [38400/60000]\n",
            "loss: 0.635858  [44800/60000]\n",
            "loss: 0.641143  [51200/60000]\n",
            "loss: 0.451813  [57600/60000]\n",
            "\n",
            "Epoch 6\n",
            "loss: 0.372566  [    0/60000]\n",
            "loss: 0.494737  [ 6400/60000]\n",
            "loss: 0.322727  [12800/60000]\n",
            "loss: 0.540836  [19200/60000]\n",
            "loss: 0.460910  [25600/60000]\n",
            "loss: 0.480462  [32000/60000]\n",
            "loss: 0.480386  [38400/60000]\n",
            "loss: 0.621868  [44800/60000]\n",
            "loss: 0.620555  [51200/60000]\n",
            "loss: 0.427678  [57600/60000]\n",
            "\n",
            "Epoch 7\n",
            "loss: 0.341170  [    0/60000]\n",
            "loss: 0.475364  [ 6400/60000]\n",
            "loss: 0.305766  [12800/60000]\n",
            "loss: 0.522158  [19200/60000]\n",
            "loss: 0.436742  [25600/60000]\n",
            "loss: 0.465671  [32000/60000]\n",
            "loss: 0.462767  [38400/60000]\n",
            "loss: 0.605013  [44800/60000]\n",
            "loss: 0.600930  [51200/60000]\n",
            "loss: 0.414359  [57600/60000]\n",
            "\n",
            "Epoch 8\n",
            "loss: 0.318652  [    0/60000]\n",
            "loss: 0.459491  [ 6400/60000]\n",
            "loss: 0.292214  [12800/60000]\n",
            "loss: 0.507402  [19200/60000]\n",
            "loss: 0.417142  [25600/60000]\n",
            "loss: 0.454750  [32000/60000]\n",
            "loss: 0.447707  [38400/60000]\n",
            "loss: 0.588754  [44800/60000]\n",
            "loss: 0.584937  [51200/60000]\n",
            "loss: 0.406473  [57600/60000]\n",
            "\n",
            "Epoch 9\n",
            "loss: 0.302518  [    0/60000]\n",
            "loss: 0.445666  [ 6400/60000]\n",
            "loss: 0.281313  [12800/60000]\n",
            "loss: 0.495070  [19200/60000]\n",
            "loss: 0.399027  [25600/60000]\n",
            "loss: 0.444823  [32000/60000]\n",
            "loss: 0.433705  [38400/60000]\n",
            "loss: 0.572897  [44800/60000]\n",
            "loss: 0.571600  [51200/60000]\n",
            "loss: 0.400500  [57600/60000]\n",
            "\n",
            "Epoch 10\n",
            "loss: 0.289200  [    0/60000]\n",
            "loss: 0.432498  [ 6400/60000]\n",
            "loss: 0.271409  [12800/60000]\n",
            "loss: 0.483595  [19200/60000]\n",
            "loss: 0.383129  [25600/60000]\n",
            "loss: 0.436195  [32000/60000]\n",
            "loss: 0.421149  [38400/60000]\n",
            "loss: 0.559413  [44800/60000]\n",
            "loss: 0.559227  [51200/60000]\n",
            "loss: 0.395835  [57600/60000]\n",
            "\n",
            "Epoch 11\n",
            "loss: 0.278876  [    0/60000]\n",
            "loss: 0.420802  [ 6400/60000]\n",
            "loss: 0.263193  [12800/60000]\n",
            "loss: 0.472380  [19200/60000]\n",
            "loss: 0.369807  [25600/60000]\n",
            "loss: 0.428616  [32000/60000]\n",
            "loss: 0.410146  [38400/60000]\n",
            "loss: 0.547546  [44800/60000]\n",
            "loss: 0.546437  [51200/60000]\n",
            "loss: 0.391187  [57600/60000]\n",
            "\n",
            "Epoch 12\n",
            "loss: 0.270172  [    0/60000]\n",
            "loss: 0.409164  [ 6400/60000]\n",
            "loss: 0.257055  [12800/60000]\n",
            "loss: 0.461347  [19200/60000]\n",
            "loss: 0.359393  [25600/60000]\n",
            "loss: 0.421282  [32000/60000]\n",
            "loss: 0.400633  [38400/60000]\n",
            "loss: 0.536919  [44800/60000]\n",
            "loss: 0.535098  [51200/60000]\n",
            "loss: 0.386674  [57600/60000]\n",
            "\n",
            "Epoch 13\n",
            "loss: 0.263407  [    0/60000]\n",
            "loss: 0.398166  [ 6400/60000]\n",
            "loss: 0.252027  [12800/60000]\n",
            "loss: 0.451483  [19200/60000]\n",
            "loss: 0.350167  [25600/60000]\n",
            "loss: 0.415342  [32000/60000]\n",
            "loss: 0.392412  [38400/60000]\n",
            "loss: 0.526626  [44800/60000]\n",
            "loss: 0.524768  [51200/60000]\n",
            "loss: 0.381798  [57600/60000]\n",
            "\n",
            "Epoch 14\n",
            "loss: 0.255602  [    0/60000]\n",
            "loss: 0.390051  [ 6400/60000]\n",
            "loss: 0.247040  [12800/60000]\n",
            "loss: 0.441866  [19200/60000]\n",
            "loss: 0.342531  [25600/60000]\n",
            "loss: 0.408931  [32000/60000]\n",
            "loss: 0.384931  [38400/60000]\n",
            "loss: 0.517463  [44800/60000]\n",
            "loss: 0.515235  [51200/60000]\n",
            "loss: 0.378389  [57600/60000]\n",
            "\n",
            "Epoch 15\n",
            "loss: 0.249595  [    0/60000]\n",
            "loss: 0.381918  [ 6400/60000]\n",
            "loss: 0.242640  [12800/60000]\n",
            "loss: 0.432893  [19200/60000]\n",
            "loss: 0.336063  [25600/60000]\n",
            "loss: 0.402800  [32000/60000]\n",
            "loss: 0.377434  [38400/60000]\n",
            "loss: 0.509674  [44800/60000]\n",
            "loss: 0.505925  [51200/60000]\n",
            "loss: 0.375285  [57600/60000]\n",
            "\n",
            "Epoch 16\n",
            "loss: 0.245250  [    0/60000]\n",
            "loss: 0.375256  [ 6400/60000]\n",
            "loss: 0.238267  [12800/60000]\n",
            "loss: 0.424752  [19200/60000]\n",
            "loss: 0.330865  [25600/60000]\n",
            "loss: 0.396578  [32000/60000]\n",
            "loss: 0.371423  [38400/60000]\n",
            "loss: 0.502333  [44800/60000]\n",
            "loss: 0.497771  [51200/60000]\n",
            "loss: 0.373430  [57600/60000]\n",
            "\n",
            "Epoch 17\n",
            "loss: 0.240659  [    0/60000]\n",
            "loss: 0.367871  [ 6400/60000]\n",
            "loss: 0.234284  [12800/60000]\n",
            "loss: 0.416740  [19200/60000]\n",
            "loss: 0.325845  [25600/60000]\n",
            "loss: 0.389704  [32000/60000]\n",
            "loss: 0.364915  [38400/60000]\n",
            "loss: 0.495074  [44800/60000]\n",
            "loss: 0.490213  [51200/60000]\n",
            "loss: 0.371305  [57600/60000]\n",
            "\n",
            "Epoch 18\n",
            "loss: 0.235360  [    0/60000]\n",
            "loss: 0.362593  [ 6400/60000]\n",
            "loss: 0.230209  [12800/60000]\n",
            "loss: 0.408087  [19200/60000]\n",
            "loss: 0.321870  [25600/60000]\n",
            "loss: 0.382677  [32000/60000]\n",
            "loss: 0.358701  [38400/60000]\n",
            "loss: 0.489204  [44800/60000]\n",
            "loss: 0.483687  [51200/60000]\n",
            "loss: 0.368477  [57600/60000]\n",
            "\n",
            "Epoch 19\n",
            "loss: 0.230753  [    0/60000]\n",
            "loss: 0.356703  [ 6400/60000]\n",
            "loss: 0.227377  [12800/60000]\n",
            "loss: 0.400711  [19200/60000]\n",
            "loss: 0.318150  [25600/60000]\n",
            "loss: 0.376162  [32000/60000]\n",
            "loss: 0.352802  [38400/60000]\n",
            "loss: 0.482552  [44800/60000]\n",
            "loss: 0.477640  [51200/60000]\n",
            "loss: 0.365470  [57600/60000]\n",
            "\n",
            "Epoch 20\n",
            "loss: 0.226587  [    0/60000]\n",
            "loss: 0.351262  [ 6400/60000]\n",
            "loss: 0.224549  [12800/60000]\n",
            "loss: 0.392806  [19200/60000]\n",
            "loss: 0.314005  [25600/60000]\n",
            "loss: 0.370471  [32000/60000]\n",
            "loss: 0.347485  [38400/60000]\n",
            "loss: 0.476916  [44800/60000]\n",
            "loss: 0.471684  [51200/60000]\n",
            "loss: 0.362462  [57600/60000]\n",
            "\n",
            "Epoch 21\n",
            "loss: 0.222541  [    0/60000]\n",
            "loss: 0.346540  [ 6400/60000]\n",
            "loss: 0.222275  [12800/60000]\n",
            "loss: 0.386349  [19200/60000]\n",
            "loss: 0.310508  [25600/60000]\n",
            "loss: 0.365515  [32000/60000]\n",
            "loss: 0.342680  [38400/60000]\n",
            "loss: 0.469511  [44800/60000]\n",
            "loss: 0.464935  [51200/60000]\n",
            "loss: 0.359236  [57600/60000]\n",
            "\n",
            "Epoch 22\n",
            "loss: 0.219893  [    0/60000]\n",
            "loss: 0.341234  [ 6400/60000]\n",
            "loss: 0.218951  [12800/60000]\n",
            "loss: 0.380337  [19200/60000]\n",
            "loss: 0.305920  [25600/60000]\n",
            "loss: 0.360873  [32000/60000]\n",
            "loss: 0.337450  [38400/60000]\n",
            "loss: 0.463643  [44800/60000]\n",
            "loss: 0.458706  [51200/60000]\n",
            "loss: 0.357690  [57600/60000]\n",
            "\n",
            "Epoch 23\n",
            "loss: 0.217577  [    0/60000]\n",
            "loss: 0.335622  [ 6400/60000]\n",
            "loss: 0.215525  [12800/60000]\n",
            "loss: 0.373289  [19200/60000]\n",
            "loss: 0.304440  [25600/60000]\n",
            "loss: 0.355024  [32000/60000]\n",
            "loss: 0.333245  [38400/60000]\n",
            "loss: 0.458361  [44800/60000]\n",
            "loss: 0.450366  [51200/60000]\n",
            "loss: 0.355117  [57600/60000]\n",
            "\n",
            "Epoch 24\n",
            "loss: 0.214365  [    0/60000]\n",
            "loss: 0.330388  [ 6400/60000]\n",
            "loss: 0.212591  [12800/60000]\n",
            "loss: 0.367148  [19200/60000]\n",
            "loss: 0.302677  [25600/60000]\n",
            "loss: 0.350441  [32000/60000]\n",
            "loss: 0.329458  [38400/60000]\n",
            "loss: 0.452770  [44800/60000]\n",
            "loss: 0.444691  [51200/60000]\n",
            "loss: 0.352872  [57600/60000]\n",
            "\n",
            "Epoch 25\n",
            "loss: 0.211126  [    0/60000]\n",
            "loss: 0.326062  [ 6400/60000]\n",
            "loss: 0.210304  [12800/60000]\n",
            "loss: 0.360344  [19200/60000]\n",
            "loss: 0.299440  [25600/60000]\n",
            "loss: 0.346188  [32000/60000]\n",
            "loss: 0.326679  [38400/60000]\n",
            "loss: 0.446206  [44800/60000]\n",
            "loss: 0.437674  [51200/60000]\n",
            "loss: 0.350341  [57600/60000]\n",
            "\n",
            "Epoch 26\n",
            "loss: 0.210337  [    0/60000]\n",
            "loss: 0.320820  [ 6400/60000]\n",
            "loss: 0.207527  [12800/60000]\n",
            "loss: 0.355285  [19200/60000]\n",
            "loss: 0.297611  [25600/60000]\n",
            "loss: 0.340431  [32000/60000]\n",
            "loss: 0.325022  [38400/60000]\n",
            "loss: 0.440776  [44800/60000]\n",
            "loss: 0.430699  [51200/60000]\n",
            "loss: 0.346735  [57600/60000]\n",
            "\n",
            "Epoch 27\n",
            "loss: 0.206332  [    0/60000]\n",
            "loss: 0.316784  [ 6400/60000]\n",
            "loss: 0.204724  [12800/60000]\n",
            "loss: 0.349779  [19200/60000]\n",
            "loss: 0.295545  [25600/60000]\n",
            "loss: 0.335580  [32000/60000]\n",
            "loss: 0.321665  [38400/60000]\n",
            "loss: 0.434204  [44800/60000]\n",
            "loss: 0.423987  [51200/60000]\n",
            "loss: 0.345754  [57600/60000]\n",
            "\n",
            "Epoch 28\n",
            "loss: 0.204729  [    0/60000]\n",
            "loss: 0.312649  [ 6400/60000]\n",
            "loss: 0.202750  [12800/60000]\n",
            "loss: 0.345551  [19200/60000]\n",
            "loss: 0.293942  [25600/60000]\n",
            "loss: 0.331279  [32000/60000]\n",
            "loss: 0.319540  [38400/60000]\n",
            "loss: 0.428007  [44800/60000]\n",
            "loss: 0.418863  [51200/60000]\n",
            "loss: 0.343170  [57600/60000]\n",
            "\n",
            "Epoch 29\n",
            "loss: 0.202245  [    0/60000]\n",
            "loss: 0.308724  [ 6400/60000]\n",
            "loss: 0.200941  [12800/60000]\n",
            "loss: 0.340001  [19200/60000]\n",
            "loss: 0.292706  [25600/60000]\n",
            "loss: 0.326862  [32000/60000]\n",
            "loss: 0.317086  [38400/60000]\n",
            "loss: 0.422575  [44800/60000]\n",
            "loss: 0.412155  [51200/60000]\n",
            "loss: 0.338705  [57600/60000]\n",
            "\n",
            "Epoch 30\n",
            "loss: 0.199406  [    0/60000]\n",
            "loss: 0.304901  [ 6400/60000]\n",
            "loss: 0.200028  [12800/60000]\n",
            "loss: 0.334826  [19200/60000]\n",
            "loss: 0.291439  [25600/60000]\n",
            "loss: 0.323106  [32000/60000]\n",
            "loss: 0.315297  [38400/60000]\n",
            "loss: 0.417442  [44800/60000]\n",
            "loss: 0.406130  [51200/60000]\n",
            "loss: 0.337267  [57600/60000]\n",
            "\n",
            "Epoch 31\n",
            "loss: 0.195815  [    0/60000]\n",
            "loss: 0.302485  [ 6400/60000]\n",
            "loss: 0.197494  [12800/60000]\n",
            "loss: 0.329127  [19200/60000]\n",
            "loss: 0.289960  [25600/60000]\n",
            "loss: 0.320447  [32000/60000]\n",
            "loss: 0.311351  [38400/60000]\n",
            "loss: 0.412252  [44800/60000]\n",
            "loss: 0.399685  [51200/60000]\n",
            "loss: 0.334920  [57600/60000]\n",
            "\n",
            "Epoch 32\n",
            "loss: 0.194803  [    0/60000]\n",
            "loss: 0.299322  [ 6400/60000]\n",
            "loss: 0.196679  [12800/60000]\n",
            "loss: 0.322823  [19200/60000]\n",
            "loss: 0.288042  [25600/60000]\n",
            "loss: 0.316445  [32000/60000]\n",
            "loss: 0.309371  [38400/60000]\n",
            "loss: 0.407732  [44800/60000]\n",
            "loss: 0.394834  [51200/60000]\n",
            "loss: 0.332045  [57600/60000]\n",
            "\n",
            "Epoch 33\n",
            "loss: 0.191153  [    0/60000]\n",
            "loss: 0.295976  [ 6400/60000]\n",
            "loss: 0.193007  [12800/60000]\n",
            "loss: 0.317157  [19200/60000]\n",
            "loss: 0.288847  [25600/60000]\n",
            "loss: 0.313106  [32000/60000]\n",
            "loss: 0.305824  [38400/60000]\n",
            "loss: 0.401746  [44800/60000]\n",
            "loss: 0.389647  [51200/60000]\n",
            "loss: 0.330771  [57600/60000]\n",
            "\n",
            "Epoch 34\n",
            "loss: 0.190171  [    0/60000]\n",
            "loss: 0.291632  [ 6400/60000]\n",
            "loss: 0.190901  [12800/60000]\n",
            "loss: 0.312335  [19200/60000]\n",
            "loss: 0.288005  [25600/60000]\n",
            "loss: 0.309287  [32000/60000]\n",
            "loss: 0.304338  [38400/60000]\n",
            "loss: 0.397697  [44800/60000]\n",
            "loss: 0.385021  [51200/60000]\n",
            "loss: 0.328105  [57600/60000]\n",
            "\n",
            "Epoch 35\n",
            "loss: 0.188979  [    0/60000]\n",
            "loss: 0.289353  [ 6400/60000]\n",
            "loss: 0.188872  [12800/60000]\n",
            "loss: 0.306975  [19200/60000]\n",
            "loss: 0.287378  [25600/60000]\n",
            "loss: 0.306004  [32000/60000]\n",
            "loss: 0.301208  [38400/60000]\n",
            "loss: 0.392251  [44800/60000]\n",
            "loss: 0.378700  [51200/60000]\n",
            "loss: 0.325484  [57600/60000]\n",
            "\n",
            "Epoch 36\n",
            "loss: 0.185843  [    0/60000]\n",
            "loss: 0.287252  [ 6400/60000]\n",
            "loss: 0.186616  [12800/60000]\n",
            "loss: 0.302097  [19200/60000]\n",
            "loss: 0.286050  [25600/60000]\n",
            "loss: 0.302022  [32000/60000]\n",
            "loss: 0.296091  [38400/60000]\n",
            "loss: 0.386000  [44800/60000]\n",
            "loss: 0.373734  [51200/60000]\n",
            "loss: 0.321575  [57600/60000]\n",
            "\n",
            "Epoch 37\n",
            "loss: 0.183072  [    0/60000]\n",
            "loss: 0.284031  [ 6400/60000]\n",
            "loss: 0.184555  [12800/60000]\n",
            "loss: 0.298168  [19200/60000]\n",
            "loss: 0.286194  [25600/60000]\n",
            "loss: 0.296939  [32000/60000]\n",
            "loss: 0.293524  [38400/60000]\n",
            "loss: 0.382563  [44800/60000]\n",
            "loss: 0.367272  [51200/60000]\n",
            "loss: 0.320329  [57600/60000]\n",
            "\n",
            "Epoch 38\n",
            "loss: 0.181131  [    0/60000]\n",
            "loss: 0.280862  [ 6400/60000]\n",
            "loss: 0.183354  [12800/60000]\n",
            "loss: 0.293248  [19200/60000]\n",
            "loss: 0.285542  [25600/60000]\n",
            "loss: 0.293089  [32000/60000]\n",
            "loss: 0.291412  [38400/60000]\n",
            "loss: 0.378626  [44800/60000]\n",
            "loss: 0.362961  [51200/60000]\n",
            "loss: 0.318608  [57600/60000]\n",
            "\n",
            "Epoch 39\n",
            "loss: 0.179435  [    0/60000]\n",
            "loss: 0.278673  [ 6400/60000]\n",
            "loss: 0.181921  [12800/60000]\n",
            "loss: 0.288410  [19200/60000]\n",
            "loss: 0.284631  [25600/60000]\n",
            "loss: 0.289519  [32000/60000]\n",
            "loss: 0.286334  [38400/60000]\n",
            "loss: 0.374477  [44800/60000]\n",
            "loss: 0.358987  [51200/60000]\n",
            "loss: 0.314823  [57600/60000]\n",
            "\n",
            "Epoch 40\n",
            "loss: 0.178903  [    0/60000]\n",
            "loss: 0.275527  [ 6400/60000]\n",
            "loss: 0.178791  [12800/60000]\n",
            "loss: 0.283662  [19200/60000]\n",
            "loss: 0.283706  [25600/60000]\n",
            "loss: 0.288022  [32000/60000]\n",
            "loss: 0.282743  [38400/60000]\n",
            "loss: 0.368222  [44800/60000]\n",
            "loss: 0.354509  [51200/60000]\n",
            "loss: 0.313654  [57600/60000]\n",
            "\n",
            "Epoch 41\n",
            "loss: 0.177552  [    0/60000]\n",
            "loss: 0.273567  [ 6400/60000]\n",
            "loss: 0.176425  [12800/60000]\n",
            "loss: 0.278983  [19200/60000]\n",
            "loss: 0.281194  [25600/60000]\n",
            "loss: 0.284952  [32000/60000]\n",
            "loss: 0.280871  [38400/60000]\n",
            "loss: 0.363710  [44800/60000]\n",
            "loss: 0.348479  [51200/60000]\n",
            "loss: 0.311363  [57600/60000]\n",
            "\n",
            "Epoch 42\n",
            "loss: 0.177461  [    0/60000]\n",
            "loss: 0.269964  [ 6400/60000]\n",
            "loss: 0.174460  [12800/60000]\n",
            "loss: 0.274480  [19200/60000]\n",
            "loss: 0.279293  [25600/60000]\n",
            "loss: 0.281857  [32000/60000]\n",
            "loss: 0.279441  [38400/60000]\n",
            "loss: 0.357253  [44800/60000]\n",
            "loss: 0.344811  [51200/60000]\n",
            "loss: 0.309401  [57600/60000]\n",
            "\n",
            "Epoch 43\n",
            "loss: 0.177320  [    0/60000]\n",
            "loss: 0.268090  [ 6400/60000]\n",
            "loss: 0.171449  [12800/60000]\n",
            "loss: 0.270664  [19200/60000]\n",
            "loss: 0.279180  [25600/60000]\n",
            "loss: 0.279720  [32000/60000]\n",
            "loss: 0.275261  [38400/60000]\n",
            "loss: 0.350982  [44800/60000]\n",
            "loss: 0.340341  [51200/60000]\n",
            "loss: 0.305611  [57600/60000]\n",
            "\n",
            "Epoch 44\n",
            "loss: 0.173951  [    0/60000]\n",
            "loss: 0.264752  [ 6400/60000]\n",
            "loss: 0.169156  [12800/60000]\n",
            "loss: 0.267852  [19200/60000]\n",
            "loss: 0.278760  [25600/60000]\n",
            "loss: 0.276088  [32000/60000]\n",
            "loss: 0.272434  [38400/60000]\n",
            "loss: 0.345660  [44800/60000]\n",
            "loss: 0.338240  [51200/60000]\n",
            "loss: 0.305361  [57600/60000]\n",
            "\n",
            "Epoch 45\n",
            "loss: 0.171991  [    0/60000]\n",
            "loss: 0.261672  [ 6400/60000]\n",
            "loss: 0.167370  [12800/60000]\n",
            "loss: 0.263365  [19200/60000]\n",
            "loss: 0.276908  [25600/60000]\n",
            "loss: 0.274364  [32000/60000]\n",
            "loss: 0.271434  [38400/60000]\n",
            "loss: 0.341671  [44800/60000]\n",
            "loss: 0.336057  [51200/60000]\n",
            "loss: 0.302377  [57600/60000]\n",
            "\n",
            "Epoch 46\n",
            "loss: 0.171375  [    0/60000]\n",
            "loss: 0.259684  [ 6400/60000]\n",
            "loss: 0.165043  [12800/60000]\n",
            "loss: 0.258981  [19200/60000]\n",
            "loss: 0.275866  [25600/60000]\n",
            "loss: 0.271424  [32000/60000]\n",
            "loss: 0.266924  [38400/60000]\n",
            "loss: 0.337570  [44800/60000]\n",
            "loss: 0.329800  [51200/60000]\n",
            "loss: 0.300828  [57600/60000]\n",
            "\n",
            "Epoch 47\n",
            "loss: 0.172518  [    0/60000]\n",
            "loss: 0.258863  [ 6400/60000]\n",
            "loss: 0.163194  [12800/60000]\n",
            "loss: 0.255352  [19200/60000]\n",
            "loss: 0.276487  [25600/60000]\n",
            "loss: 0.269350  [32000/60000]\n",
            "loss: 0.264555  [38400/60000]\n",
            "loss: 0.331982  [44800/60000]\n",
            "loss: 0.328681  [51200/60000]\n",
            "loss: 0.297583  [57600/60000]\n",
            "\n",
            "Epoch 48\n",
            "loss: 0.171546  [    0/60000]\n",
            "loss: 0.255548  [ 6400/60000]\n",
            "loss: 0.161364  [12800/60000]\n",
            "loss: 0.250714  [19200/60000]\n",
            "loss: 0.273384  [25600/60000]\n",
            "loss: 0.268969  [32000/60000]\n",
            "loss: 0.262391  [38400/60000]\n",
            "loss: 0.327811  [44800/60000]\n",
            "loss: 0.325376  [51200/60000]\n",
            "loss: 0.296865  [57600/60000]\n",
            "\n",
            "Epoch 49\n",
            "loss: 0.170094  [    0/60000]\n",
            "loss: 0.252546  [ 6400/60000]\n",
            "loss: 0.159626  [12800/60000]\n",
            "loss: 0.247633  [19200/60000]\n",
            "loss: 0.273122  [25600/60000]\n",
            "loss: 0.264873  [32000/60000]\n",
            "loss: 0.259409  [38400/60000]\n",
            "loss: 0.322203  [44800/60000]\n",
            "loss: 0.321322  [51200/60000]\n",
            "loss: 0.294600  [57600/60000]\n",
            "\n",
            "Epoch 50\n",
            "loss: 0.167878  [    0/60000]\n",
            "loss: 0.251149  [ 6400/60000]\n",
            "loss: 0.158677  [12800/60000]\n",
            "loss: 0.242932  [19200/60000]\n",
            "loss: 0.270893  [25600/60000]\n",
            "loss: 0.263845  [32000/60000]\n",
            "loss: 0.254901  [38400/60000]\n",
            "loss: 0.320493  [44800/60000]\n",
            "loss: 0.315826  [51200/60000]\n",
            "loss: 0.292846  [57600/60000]\n",
            "\n",
            "Epoch 51\n",
            "loss: 0.166380  [    0/60000]\n",
            "loss: 0.247971  [ 6400/60000]\n",
            "loss: 0.156026  [12800/60000]\n",
            "loss: 0.240442  [19200/60000]\n",
            "loss: 0.268760  [25600/60000]\n",
            "loss: 0.262253  [32000/60000]\n",
            "loss: 0.252789  [38400/60000]\n",
            "loss: 0.316550  [44800/60000]\n",
            "loss: 0.312391  [51200/60000]\n",
            "loss: 0.293480  [57600/60000]\n",
            "\n",
            "Epoch 52\n",
            "loss: 0.166223  [    0/60000]\n",
            "loss: 0.245710  [ 6400/60000]\n",
            "loss: 0.154220  [12800/60000]\n",
            "loss: 0.236029  [19200/60000]\n",
            "loss: 0.267208  [25600/60000]\n",
            "loss: 0.258702  [32000/60000]\n",
            "loss: 0.248475  [38400/60000]\n",
            "loss: 0.313087  [44800/60000]\n",
            "loss: 0.308700  [51200/60000]\n",
            "loss: 0.288628  [57600/60000]\n",
            "\n",
            "Epoch 53\n",
            "loss: 0.165482  [    0/60000]\n",
            "loss: 0.245039  [ 6400/60000]\n",
            "loss: 0.152073  [12800/60000]\n",
            "loss: 0.231657  [19200/60000]\n",
            "loss: 0.267645  [25600/60000]\n",
            "loss: 0.257541  [32000/60000]\n",
            "loss: 0.245704  [38400/60000]\n",
            "loss: 0.311500  [44800/60000]\n",
            "loss: 0.300902  [51200/60000]\n",
            "loss: 0.285390  [57600/60000]\n",
            "\n",
            "Epoch 54\n",
            "loss: 0.165531  [    0/60000]\n",
            "loss: 0.243194  [ 6400/60000]\n",
            "loss: 0.150165  [12800/60000]\n",
            "loss: 0.227409  [19200/60000]\n",
            "loss: 0.266406  [25600/60000]\n",
            "loss: 0.254362  [32000/60000]\n",
            "loss: 0.242828  [38400/60000]\n",
            "loss: 0.309739  [44800/60000]\n",
            "loss: 0.298903  [51200/60000]\n",
            "loss: 0.285933  [57600/60000]\n",
            "\n",
            "Epoch 55\n",
            "loss: 0.164671  [    0/60000]\n",
            "loss: 0.239917  [ 6400/60000]\n",
            "loss: 0.147835  [12800/60000]\n",
            "loss: 0.223108  [19200/60000]\n",
            "loss: 0.263831  [25600/60000]\n",
            "loss: 0.252656  [32000/60000]\n",
            "loss: 0.241160  [38400/60000]\n",
            "loss: 0.305719  [44800/60000]\n",
            "loss: 0.296133  [51200/60000]\n",
            "loss: 0.281667  [57600/60000]\n",
            "\n",
            "Epoch 56\n",
            "loss: 0.166977  [    0/60000]\n",
            "loss: 0.239341  [ 6400/60000]\n",
            "loss: 0.146434  [12800/60000]\n",
            "loss: 0.218317  [19200/60000]\n",
            "loss: 0.262997  [25600/60000]\n",
            "loss: 0.249518  [32000/60000]\n",
            "loss: 0.238212  [38400/60000]\n",
            "loss: 0.300754  [44800/60000]\n",
            "loss: 0.292109  [51200/60000]\n",
            "loss: 0.281505  [57600/60000]\n",
            "\n",
            "Epoch 57\n",
            "loss: 0.165986  [    0/60000]\n",
            "loss: 0.236826  [ 6400/60000]\n",
            "loss: 0.143423  [12800/60000]\n",
            "loss: 0.214522  [19200/60000]\n",
            "loss: 0.261277  [25600/60000]\n",
            "loss: 0.248905  [32000/60000]\n",
            "loss: 0.235862  [38400/60000]\n",
            "loss: 0.297227  [44800/60000]\n",
            "loss: 0.289360  [51200/60000]\n",
            "loss: 0.277197  [57600/60000]\n",
            "\n",
            "Epoch 58\n",
            "loss: 0.164731  [    0/60000]\n",
            "loss: 0.235471  [ 6400/60000]\n",
            "loss: 0.141434  [12800/60000]\n",
            "loss: 0.210389  [19200/60000]\n",
            "loss: 0.260285  [25600/60000]\n",
            "loss: 0.247330  [32000/60000]\n",
            "loss: 0.232206  [38400/60000]\n",
            "loss: 0.292541  [44800/60000]\n",
            "loss: 0.286021  [51200/60000]\n",
            "loss: 0.275533  [57600/60000]\n",
            "\n",
            "Epoch 59\n",
            "loss: 0.164949  [    0/60000]\n",
            "loss: 0.232643  [ 6400/60000]\n",
            "loss: 0.141187  [12800/60000]\n",
            "loss: 0.206423  [19200/60000]\n",
            "loss: 0.259131  [25600/60000]\n",
            "loss: 0.246043  [32000/60000]\n",
            "loss: 0.228906  [38400/60000]\n",
            "loss: 0.288722  [44800/60000]\n",
            "loss: 0.280354  [51200/60000]\n",
            "loss: 0.276366  [57600/60000]\n",
            "\n",
            "Epoch 60\n",
            "loss: 0.160622  [    0/60000]\n",
            "loss: 0.231298  [ 6400/60000]\n",
            "loss: 0.140642  [12800/60000]\n",
            "loss: 0.203686  [19200/60000]\n",
            "loss: 0.256894  [25600/60000]\n",
            "loss: 0.242384  [32000/60000]\n",
            "loss: 0.226813  [38400/60000]\n",
            "loss: 0.283091  [44800/60000]\n",
            "loss: 0.277236  [51200/60000]\n",
            "loss: 0.270527  [57600/60000]\n",
            "\n",
            "Epoch 61\n",
            "loss: 0.161160  [    0/60000]\n",
            "loss: 0.228556  [ 6400/60000]\n",
            "loss: 0.137863  [12800/60000]\n",
            "loss: 0.199220  [19200/60000]\n",
            "loss: 0.255044  [25600/60000]\n",
            "loss: 0.243035  [32000/60000]\n",
            "loss: 0.222080  [38400/60000]\n",
            "loss: 0.279971  [44800/60000]\n",
            "loss: 0.274264  [51200/60000]\n",
            "loss: 0.270614  [57600/60000]\n",
            "\n",
            "Epoch 62\n",
            "loss: 0.159552  [    0/60000]\n",
            "loss: 0.225637  [ 6400/60000]\n",
            "loss: 0.136036  [12800/60000]\n",
            "loss: 0.195920  [19200/60000]\n",
            "loss: 0.253920  [25600/60000]\n",
            "loss: 0.238826  [32000/60000]\n",
            "loss: 0.221144  [38400/60000]\n",
            "loss: 0.276945  [44800/60000]\n",
            "loss: 0.270872  [51200/60000]\n",
            "loss: 0.269240  [57600/60000]\n",
            "\n",
            "Epoch 63\n",
            "loss: 0.160385  [    0/60000]\n",
            "loss: 0.223774  [ 6400/60000]\n",
            "loss: 0.135968  [12800/60000]\n",
            "loss: 0.192275  [19200/60000]\n",
            "loss: 0.251125  [25600/60000]\n",
            "loss: 0.237065  [32000/60000]\n",
            "loss: 0.220239  [38400/60000]\n",
            "loss: 0.274985  [44800/60000]\n",
            "loss: 0.266195  [51200/60000]\n",
            "loss: 0.268826  [57600/60000]\n",
            "\n",
            "Epoch 64\n",
            "loss: 0.159791  [    0/60000]\n",
            "loss: 0.219813  [ 6400/60000]\n",
            "loss: 0.131081  [12800/60000]\n",
            "loss: 0.190253  [19200/60000]\n",
            "loss: 0.246467  [25600/60000]\n",
            "loss: 0.238948  [32000/60000]\n",
            "loss: 0.218341  [38400/60000]\n",
            "loss: 0.269207  [44800/60000]\n",
            "loss: 0.264153  [51200/60000]\n",
            "loss: 0.266410  [57600/60000]\n",
            "\n",
            "Epoch 65\n",
            "loss: 0.159369  [    0/60000]\n",
            "loss: 0.219194  [ 6400/60000]\n",
            "loss: 0.129148  [12800/60000]\n",
            "loss: 0.186229  [19200/60000]\n",
            "loss: 0.245777  [25600/60000]\n",
            "loss: 0.237720  [32000/60000]\n",
            "loss: 0.214623  [38400/60000]\n",
            "loss: 0.265272  [44800/60000]\n",
            "loss: 0.259759  [51200/60000]\n",
            "loss: 0.263216  [57600/60000]\n",
            "\n",
            "Epoch 66\n",
            "loss: 0.157225  [    0/60000]\n",
            "loss: 0.216688  [ 6400/60000]\n",
            "loss: 0.127257  [12800/60000]\n",
            "loss: 0.184684  [19200/60000]\n",
            "loss: 0.243089  [25600/60000]\n",
            "loss: 0.235230  [32000/60000]\n",
            "loss: 0.211887  [38400/60000]\n",
            "loss: 0.261781  [44800/60000]\n",
            "loss: 0.255182  [51200/60000]\n",
            "loss: 0.261204  [57600/60000]\n",
            "\n",
            "Epoch 67\n",
            "loss: 0.158180  [    0/60000]\n",
            "loss: 0.214775  [ 6400/60000]\n",
            "loss: 0.125294  [12800/60000]\n",
            "loss: 0.179938  [19200/60000]\n",
            "loss: 0.243305  [25600/60000]\n",
            "loss: 0.235077  [32000/60000]\n",
            "loss: 0.209158  [38400/60000]\n",
            "loss: 0.259476  [44800/60000]\n",
            "loss: 0.250263  [51200/60000]\n",
            "loss: 0.257713  [57600/60000]\n",
            "\n",
            "Epoch 68\n",
            "loss: 0.158315  [    0/60000]\n",
            "loss: 0.214049  [ 6400/60000]\n",
            "loss: 0.124350  [12800/60000]\n",
            "loss: 0.176681  [19200/60000]\n",
            "loss: 0.242139  [25600/60000]\n",
            "loss: 0.232782  [32000/60000]\n",
            "loss: 0.207207  [38400/60000]\n",
            "loss: 0.255139  [44800/60000]\n",
            "loss: 0.245455  [51200/60000]\n",
            "loss: 0.257491  [57600/60000]\n",
            "\n",
            "Epoch 69\n",
            "loss: 0.158445  [    0/60000]\n",
            "loss: 0.212976  [ 6400/60000]\n",
            "loss: 0.122680  [12800/60000]\n",
            "loss: 0.174980  [19200/60000]\n",
            "loss: 0.238695  [25600/60000]\n",
            "loss: 0.231270  [32000/60000]\n",
            "loss: 0.203980  [38400/60000]\n",
            "loss: 0.253449  [44800/60000]\n",
            "loss: 0.240091  [51200/60000]\n",
            "loss: 0.255862  [57600/60000]\n",
            "\n",
            "Epoch 70\n",
            "loss: 0.158475  [    0/60000]\n",
            "loss: 0.210121  [ 6400/60000]\n",
            "loss: 0.120346  [12800/60000]\n",
            "loss: 0.172202  [19200/60000]\n",
            "loss: 0.238206  [25600/60000]\n",
            "loss: 0.226274  [32000/60000]\n",
            "loss: 0.200636  [38400/60000]\n",
            "loss: 0.249069  [44800/60000]\n",
            "loss: 0.235204  [51200/60000]\n",
            "loss: 0.253120  [57600/60000]\n",
            "\n",
            "Epoch 71\n",
            "loss: 0.160155  [    0/60000]\n",
            "loss: 0.206654  [ 6400/60000]\n",
            "loss: 0.120627  [12800/60000]\n",
            "loss: 0.169705  [19200/60000]\n",
            "loss: 0.236293  [25600/60000]\n",
            "loss: 0.225269  [32000/60000]\n",
            "loss: 0.199352  [38400/60000]\n",
            "loss: 0.244268  [44800/60000]\n",
            "loss: 0.234959  [51200/60000]\n",
            "loss: 0.249439  [57600/60000]\n",
            "\n",
            "Epoch 72\n",
            "loss: 0.155326  [    0/60000]\n",
            "loss: 0.204436  [ 6400/60000]\n",
            "loss: 0.119847  [12800/60000]\n",
            "loss: 0.169784  [19200/60000]\n",
            "loss: 0.234133  [25600/60000]\n",
            "loss: 0.224061  [32000/60000]\n",
            "loss: 0.196844  [38400/60000]\n",
            "loss: 0.242454  [44800/60000]\n",
            "loss: 0.231289  [51200/60000]\n",
            "loss: 0.251808  [57600/60000]\n",
            "\n",
            "Epoch 73\n",
            "loss: 0.153849  [    0/60000]\n",
            "loss: 0.202213  [ 6400/60000]\n",
            "loss: 0.117936  [12800/60000]\n",
            "loss: 0.165413  [19200/60000]\n",
            "loss: 0.233734  [25600/60000]\n",
            "loss: 0.220853  [32000/60000]\n",
            "loss: 0.193986  [38400/60000]\n",
            "loss: 0.239524  [44800/60000]\n",
            "loss: 0.227363  [51200/60000]\n",
            "loss: 0.247645  [57600/60000]\n",
            "\n",
            "Epoch 74\n",
            "loss: 0.158501  [    0/60000]\n",
            "loss: 0.200120  [ 6400/60000]\n",
            "loss: 0.115185  [12800/60000]\n",
            "loss: 0.162080  [19200/60000]\n",
            "loss: 0.232397  [25600/60000]\n",
            "loss: 0.218648  [32000/60000]\n",
            "loss: 0.192095  [38400/60000]\n",
            "loss: 0.231717  [44800/60000]\n",
            "loss: 0.221514  [51200/60000]\n",
            "loss: 0.244647  [57600/60000]\n",
            "\n",
            "Epoch 75\n",
            "loss: 0.160771  [    0/60000]\n",
            "loss: 0.196251  [ 6400/60000]\n",
            "loss: 0.114252  [12800/60000]\n",
            "loss: 0.157619  [19200/60000]\n",
            "loss: 0.229211  [25600/60000]\n",
            "loss: 0.216523  [32000/60000]\n",
            "loss: 0.188637  [38400/60000]\n",
            "loss: 0.229871  [44800/60000]\n",
            "loss: 0.219387  [51200/60000]\n",
            "loss: 0.243194  [57600/60000]\n",
            "\n",
            "Epoch 76\n",
            "loss: 0.162483  [    0/60000]\n",
            "loss: 0.193965  [ 6400/60000]\n",
            "loss: 0.113326  [12800/60000]\n",
            "loss: 0.156837  [19200/60000]\n",
            "loss: 0.229589  [25600/60000]\n",
            "loss: 0.212845  [32000/60000]\n",
            "loss: 0.184347  [38400/60000]\n",
            "loss: 0.224797  [44800/60000]\n",
            "loss: 0.213886  [51200/60000]\n",
            "loss: 0.242179  [57600/60000]\n",
            "\n",
            "Epoch 77\n",
            "loss: 0.158277  [    0/60000]\n",
            "loss: 0.192799  [ 6400/60000]\n",
            "loss: 0.109781  [12800/60000]\n",
            "loss: 0.156440  [19200/60000]\n",
            "loss: 0.224933  [25600/60000]\n",
            "loss: 0.208783  [32000/60000]\n",
            "loss: 0.185207  [38400/60000]\n",
            "loss: 0.223808  [44800/60000]\n",
            "loss: 0.211091  [51200/60000]\n",
            "loss: 0.239673  [57600/60000]\n",
            "\n",
            "Epoch 78\n",
            "loss: 0.157762  [    0/60000]\n",
            "loss: 0.189200  [ 6400/60000]\n",
            "loss: 0.110174  [12800/60000]\n",
            "loss: 0.152862  [19200/60000]\n",
            "loss: 0.222586  [25600/60000]\n",
            "loss: 0.207870  [32000/60000]\n",
            "loss: 0.179435  [38400/60000]\n",
            "loss: 0.221776  [44800/60000]\n",
            "loss: 0.208394  [51200/60000]\n",
            "loss: 0.236863  [57600/60000]\n",
            "\n",
            "Epoch 79\n",
            "loss: 0.159250  [    0/60000]\n",
            "loss: 0.185813  [ 6400/60000]\n",
            "loss: 0.110127  [12800/60000]\n",
            "loss: 0.150538  [19200/60000]\n",
            "loss: 0.220173  [25600/60000]\n",
            "loss: 0.206073  [32000/60000]\n",
            "loss: 0.176509  [38400/60000]\n",
            "loss: 0.214991  [44800/60000]\n",
            "loss: 0.201860  [51200/60000]\n",
            "loss: 0.236508  [57600/60000]\n",
            "\n",
            "Epoch 80\n",
            "loss: 0.163944  [    0/60000]\n",
            "loss: 0.184316  [ 6400/60000]\n",
            "loss: 0.107138  [12800/60000]\n",
            "loss: 0.150776  [19200/60000]\n",
            "loss: 0.219332  [25600/60000]\n",
            "loss: 0.201986  [32000/60000]\n",
            "loss: 0.176397  [38400/60000]\n",
            "loss: 0.214313  [44800/60000]\n",
            "loss: 0.199924  [51200/60000]\n",
            "loss: 0.233314  [57600/60000]\n",
            "\n",
            "Epoch 81\n",
            "loss: 0.152994  [    0/60000]\n",
            "loss: 0.181016  [ 6400/60000]\n",
            "loss: 0.107359  [12800/60000]\n",
            "loss: 0.146249  [19200/60000]\n",
            "loss: 0.215981  [25600/60000]\n",
            "loss: 0.200208  [32000/60000]\n",
            "loss: 0.177656  [38400/60000]\n",
            "loss: 0.209388  [44800/60000]\n",
            "loss: 0.196378  [51200/60000]\n",
            "loss: 0.231948  [57600/60000]\n",
            "\n",
            "Epoch 82\n",
            "loss: 0.153621  [    0/60000]\n",
            "loss: 0.177980  [ 6400/60000]\n",
            "loss: 0.105716  [12800/60000]\n",
            "loss: 0.145151  [19200/60000]\n",
            "loss: 0.214614  [25600/60000]\n",
            "loss: 0.197144  [32000/60000]\n",
            "loss: 0.172860  [38400/60000]\n",
            "loss: 0.205861  [44800/60000]\n",
            "loss: 0.193451  [51200/60000]\n",
            "loss: 0.230275  [57600/60000]\n",
            "\n",
            "Epoch 83\n",
            "loss: 0.154752  [    0/60000]\n",
            "loss: 0.176986  [ 6400/60000]\n",
            "loss: 0.104841  [12800/60000]\n",
            "loss: 0.143010  [19200/60000]\n",
            "loss: 0.211504  [25600/60000]\n",
            "loss: 0.196755  [32000/60000]\n",
            "loss: 0.170509  [38400/60000]\n",
            "loss: 0.203723  [44800/60000]\n",
            "loss: 0.192632  [51200/60000]\n",
            "loss: 0.231214  [57600/60000]\n",
            "\n",
            "Epoch 84\n",
            "loss: 0.156666  [    0/60000]\n",
            "loss: 0.172815  [ 6400/60000]\n",
            "loss: 0.102811  [12800/60000]\n",
            "loss: 0.139711  [19200/60000]\n",
            "loss: 0.207989  [25600/60000]\n",
            "loss: 0.192816  [32000/60000]\n",
            "loss: 0.171053  [38400/60000]\n",
            "loss: 0.198318  [44800/60000]\n",
            "loss: 0.186208  [51200/60000]\n",
            "loss: 0.228601  [57600/60000]\n",
            "\n",
            "Epoch 85\n",
            "loss: 0.154738  [    0/60000]\n",
            "loss: 0.168054  [ 6400/60000]\n",
            "loss: 0.101558  [12800/60000]\n",
            "loss: 0.139831  [19200/60000]\n",
            "loss: 0.207308  [25600/60000]\n",
            "loss: 0.189355  [32000/60000]\n",
            "loss: 0.169730  [38400/60000]\n",
            "loss: 0.191522  [44800/60000]\n",
            "loss: 0.185023  [51200/60000]\n",
            "loss: 0.223585  [57600/60000]\n",
            "\n",
            "Epoch 86\n",
            "loss: 0.153010  [    0/60000]\n",
            "loss: 0.166799  [ 6400/60000]\n",
            "loss: 0.099959  [12800/60000]\n",
            "loss: 0.136761  [19200/60000]\n",
            "loss: 0.204441  [25600/60000]\n",
            "loss: 0.188461  [32000/60000]\n",
            "loss: 0.168645  [38400/60000]\n",
            "loss: 0.189354  [44800/60000]\n",
            "loss: 0.183141  [51200/60000]\n",
            "loss: 0.224419  [57600/60000]\n",
            "\n",
            "Epoch 87\n",
            "loss: 0.150296  [    0/60000]\n",
            "loss: 0.165661  [ 6400/60000]\n",
            "loss: 0.097287  [12800/60000]\n",
            "loss: 0.135345  [19200/60000]\n",
            "loss: 0.198075  [25600/60000]\n",
            "loss: 0.188228  [32000/60000]\n",
            "loss: 0.168129  [38400/60000]\n",
            "loss: 0.187402  [44800/60000]\n",
            "loss: 0.180486  [51200/60000]\n",
            "loss: 0.220318  [57600/60000]\n",
            "\n",
            "Epoch 88\n",
            "loss: 0.150550  [    0/60000]\n",
            "loss: 0.161054  [ 6400/60000]\n",
            "loss: 0.096301  [12800/60000]\n",
            "loss: 0.134835  [19200/60000]\n",
            "loss: 0.197326  [25600/60000]\n",
            "loss: 0.186642  [32000/60000]\n",
            "loss: 0.163523  [38400/60000]\n",
            "loss: 0.185406  [44800/60000]\n",
            "loss: 0.176262  [51200/60000]\n",
            "loss: 0.216867  [57600/60000]\n",
            "\n",
            "Epoch 89\n",
            "loss: 0.149092  [    0/60000]\n",
            "loss: 0.157841  [ 6400/60000]\n",
            "loss: 0.095344  [12800/60000]\n",
            "loss: 0.131125  [19200/60000]\n",
            "loss: 0.195650  [25600/60000]\n",
            "loss: 0.185885  [32000/60000]\n",
            "loss: 0.165115  [38400/60000]\n",
            "loss: 0.185816  [44800/60000]\n",
            "loss: 0.174489  [51200/60000]\n",
            "loss: 0.214224  [57600/60000]\n",
            "\n",
            "Epoch 90\n",
            "loss: 0.144600  [    0/60000]\n",
            "loss: 0.156725  [ 6400/60000]\n",
            "loss: 0.093004  [12800/60000]\n",
            "loss: 0.131623  [19200/60000]\n",
            "loss: 0.192235  [25600/60000]\n",
            "loss: 0.183624  [32000/60000]\n",
            "loss: 0.163377  [38400/60000]\n",
            "loss: 0.180258  [44800/60000]\n",
            "loss: 0.170938  [51200/60000]\n",
            "loss: 0.212361  [57600/60000]\n",
            "\n",
            "Epoch 91\n",
            "loss: 0.146685  [    0/60000]\n",
            "loss: 0.155152  [ 6400/60000]\n",
            "loss: 0.093341  [12800/60000]\n",
            "loss: 0.129265  [19200/60000]\n",
            "loss: 0.188192  [25600/60000]\n",
            "loss: 0.182091  [32000/60000]\n",
            "loss: 0.160673  [38400/60000]\n",
            "loss: 0.175699  [44800/60000]\n",
            "loss: 0.166213  [51200/60000]\n",
            "loss: 0.210612  [57600/60000]\n",
            "\n",
            "Epoch 92\n",
            "loss: 0.141300  [    0/60000]\n",
            "loss: 0.152002  [ 6400/60000]\n",
            "loss: 0.090030  [12800/60000]\n",
            "loss: 0.127797  [19200/60000]\n",
            "loss: 0.184910  [25600/60000]\n",
            "loss: 0.177608  [32000/60000]\n",
            "loss: 0.159037  [38400/60000]\n",
            "loss: 0.172828  [44800/60000]\n",
            "loss: 0.165169  [51200/60000]\n",
            "loss: 0.204826  [57600/60000]\n",
            "\n",
            "Epoch 93\n",
            "loss: 0.139640  [    0/60000]\n",
            "loss: 0.148878  [ 6400/60000]\n",
            "loss: 0.088493  [12800/60000]\n",
            "loss: 0.125894  [19200/60000]\n",
            "loss: 0.184848  [25600/60000]\n",
            "loss: 0.175261  [32000/60000]\n",
            "loss: 0.155668  [38400/60000]\n",
            "loss: 0.169932  [44800/60000]\n",
            "loss: 0.165817  [51200/60000]\n",
            "loss: 0.203144  [57600/60000]\n",
            "\n",
            "Epoch 94\n",
            "loss: 0.135529  [    0/60000]\n",
            "loss: 0.146852  [ 6400/60000]\n",
            "loss: 0.086911  [12800/60000]\n",
            "loss: 0.124318  [19200/60000]\n",
            "loss: 0.179123  [25600/60000]\n",
            "loss: 0.171027  [32000/60000]\n",
            "loss: 0.153330  [38400/60000]\n",
            "loss: 0.168007  [44800/60000]\n",
            "loss: 0.162264  [51200/60000]\n",
            "loss: 0.201918  [57600/60000]\n",
            "\n",
            "Epoch 95\n",
            "loss: 0.137979  [    0/60000]\n",
            "loss: 0.143979  [ 6400/60000]\n",
            "loss: 0.084525  [12800/60000]\n",
            "loss: 0.121451  [19200/60000]\n",
            "loss: 0.179269  [25600/60000]\n",
            "loss: 0.171483  [32000/60000]\n",
            "loss: 0.151075  [38400/60000]\n",
            "loss: 0.167026  [44800/60000]\n",
            "loss: 0.159136  [51200/60000]\n",
            "loss: 0.197997  [57600/60000]\n",
            "\n",
            "Epoch 96\n",
            "loss: 0.126898  [    0/60000]\n",
            "loss: 0.142661  [ 6400/60000]\n",
            "loss: 0.086215  [12800/60000]\n",
            "loss: 0.120640  [19200/60000]\n",
            "loss: 0.174380  [25600/60000]\n",
            "loss: 0.167284  [32000/60000]\n",
            "loss: 0.149956  [38400/60000]\n",
            "loss: 0.164290  [44800/60000]\n",
            "loss: 0.155798  [51200/60000]\n",
            "loss: 0.198176  [57600/60000]\n",
            "\n",
            "Epoch 97\n",
            "loss: 0.127663  [    0/60000]\n",
            "loss: 0.139869  [ 6400/60000]\n",
            "loss: 0.086092  [12800/60000]\n",
            "loss: 0.119927  [19200/60000]\n",
            "loss: 0.172719  [25600/60000]\n",
            "loss: 0.167019  [32000/60000]\n",
            "loss: 0.149913  [38400/60000]\n",
            "loss: 0.161544  [44800/60000]\n",
            "loss: 0.155907  [51200/60000]\n",
            "loss: 0.196529  [57600/60000]\n",
            "\n",
            "Epoch 98\n",
            "loss: 0.129365  [    0/60000]\n",
            "loss: 0.134601  [ 6400/60000]\n",
            "loss: 0.082553  [12800/60000]\n",
            "loss: 0.119043  [19200/60000]\n",
            "loss: 0.169571  [25600/60000]\n",
            "loss: 0.165880  [32000/60000]\n",
            "loss: 0.150615  [38400/60000]\n",
            "loss: 0.155796  [44800/60000]\n",
            "loss: 0.154989  [51200/60000]\n",
            "loss: 0.192648  [57600/60000]\n",
            "\n",
            "Epoch 99\n",
            "loss: 0.124888  [    0/60000]\n",
            "loss: 0.133009  [ 6400/60000]\n",
            "loss: 0.081734  [12800/60000]\n",
            "loss: 0.115860  [19200/60000]\n",
            "loss: 0.162738  [25600/60000]\n",
            "loss: 0.163013  [32000/60000]\n",
            "loss: 0.147700  [38400/60000]\n",
            "loss: 0.155501  [44800/60000]\n",
            "loss: 0.149915  [51200/60000]\n",
            "loss: 0.186389  [57600/60000]\n",
            "\n",
            "Epoch 100\n",
            "loss: 0.129441  [    0/60000]\n",
            "loss: 0.131053  [ 6400/60000]\n",
            "loss: 0.082116  [12800/60000]\n",
            "loss: 0.115250  [19200/60000]\n",
            "loss: 0.162401  [25600/60000]\n",
            "loss: 0.162865  [32000/60000]\n",
            "loss: 0.144399  [38400/60000]\n",
            "loss: 0.153024  [44800/60000]\n",
            "loss: 0.146776  [51200/60000]\n",
            "loss: 0.183468  [57600/60000]\n",
            "Final test:\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 0.351810 \n",
            "\n",
            "\n",
            "Training with learning rate: 0.001\n",
            "\n",
            "\n",
            "Epoch 1\n",
            "loss: 2.296007  [    0/60000]\n",
            "loss: 2.284187  [ 6400/60000]\n",
            "loss: 2.263155  [12800/60000]\n",
            "loss: 2.260654  [19200/60000]\n",
            "loss: 2.241191  [25600/60000]\n",
            "loss: 2.208610  [32000/60000]\n",
            "loss: 2.217145  [38400/60000]\n",
            "loss: 2.181418  [44800/60000]\n",
            "loss: 2.177150  [51200/60000]\n",
            "loss: 2.147264  [57600/60000]\n",
            "\n",
            "Epoch 2\n",
            "loss: 2.141351  [    0/60000]\n",
            "loss: 2.130416  [ 6400/60000]\n",
            "loss: 2.070842  [12800/60000]\n",
            "loss: 2.088980  [19200/60000]\n",
            "loss: 2.029329  [25600/60000]\n",
            "loss: 1.968107  [32000/60000]\n",
            "loss: 1.994248  [38400/60000]\n",
            "loss: 1.910831  [44800/60000]\n",
            "loss: 1.922796  [51200/60000]\n",
            "loss: 1.839828  [57600/60000]\n",
            "\n",
            "Epoch 3\n",
            "loss: 1.872379  [    0/60000]\n",
            "loss: 1.842035  [ 6400/60000]\n",
            "loss: 1.723041  [12800/60000]\n",
            "loss: 1.763021  [19200/60000]\n",
            "loss: 1.653514  [25600/60000]\n",
            "loss: 1.610314  [32000/60000]\n",
            "loss: 1.628486  [38400/60000]\n",
            "loss: 1.534392  [44800/60000]\n",
            "loss: 1.570917  [51200/60000]\n",
            "loss: 1.453797  [57600/60000]\n",
            "\n",
            "Epoch 4\n",
            "loss: 1.545123  [    0/60000]\n",
            "loss: 1.516004  [ 6400/60000]\n",
            "loss: 1.368943  [12800/60000]\n",
            "loss: 1.436201  [19200/60000]\n",
            "loss: 1.326808  [25600/60000]\n",
            "loss: 1.324468  [32000/60000]\n",
            "loss: 1.337538  [38400/60000]\n",
            "loss: 1.264691  [44800/60000]\n",
            "loss: 1.309537  [51200/60000]\n",
            "loss: 1.200821  [57600/60000]\n",
            "\n",
            "Epoch 5\n",
            "loss: 1.303328  [    0/60000]\n",
            "loss: 1.290313  [ 6400/60000]\n",
            "loss: 1.127743  [12800/60000]\n",
            "loss: 1.228948  [19200/60000]\n",
            "loss: 1.110889  [25600/60000]\n",
            "loss: 1.136571  [32000/60000]\n",
            "loss: 1.160387  [38400/60000]\n",
            "loss: 1.095830  [44800/60000]\n",
            "loss: 1.145583  [51200/60000]\n",
            "loss: 1.051902  [57600/60000]\n",
            "\n",
            "Epoch 6\n",
            "loss: 1.141029  [    0/60000]\n",
            "loss: 1.146702  [ 6400/60000]\n",
            "loss: 0.968274  [12800/60000]\n",
            "loss: 1.097327  [19200/60000]\n",
            "loss: 0.975959  [25600/60000]\n",
            "loss: 1.009878  [32000/60000]\n",
            "loss: 1.049886  [38400/60000]\n",
            "loss: 0.987792  [44800/60000]\n",
            "loss: 1.037744  [51200/60000]\n",
            "loss: 0.958043  [57600/60000]\n",
            "\n",
            "Epoch 7\n",
            "loss: 1.027646  [    0/60000]\n",
            "loss: 1.053198  [ 6400/60000]\n",
            "loss: 0.859400  [12800/60000]\n",
            "loss: 1.008953  [19200/60000]\n",
            "loss: 0.890263  [25600/60000]\n",
            "loss: 0.920958  [32000/60000]\n",
            "loss: 0.977079  [38400/60000]\n",
            "loss: 0.917760  [44800/60000]\n",
            "loss: 0.962627  [51200/60000]\n",
            "loss: 0.895094  [57600/60000]\n",
            "\n",
            "Epoch 8\n",
            "loss: 0.944853  [    0/60000]\n",
            "loss: 0.988116  [ 6400/60000]\n",
            "loss: 0.781937  [12800/60000]\n",
            "loss: 0.946207  [19200/60000]\n",
            "loss: 0.832926  [25600/60000]\n",
            "loss: 0.855916  [32000/60000]\n",
            "loss: 0.925208  [38400/60000]\n",
            "loss: 0.870817  [44800/60000]\n",
            "loss: 0.908180  [51200/60000]\n",
            "loss: 0.849748  [57600/60000]\n",
            "\n",
            "Epoch 9\n",
            "loss: 0.881292  [    0/60000]\n",
            "loss: 0.939152  [ 6400/60000]\n",
            "loss: 0.723980  [12800/60000]\n",
            "loss: 0.899406  [19200/60000]\n",
            "loss: 0.792408  [25600/60000]\n",
            "loss: 0.806856  [32000/60000]\n",
            "loss: 0.885398  [38400/60000]\n",
            "loss: 0.837794  [44800/60000]\n",
            "loss: 0.867086  [51200/60000]\n",
            "loss: 0.814910  [57600/60000]\n",
            "\n",
            "Epoch 10\n",
            "loss: 0.830306  [    0/60000]\n",
            "loss: 0.899618  [ 6400/60000]\n",
            "loss: 0.678640  [12800/60000]\n",
            "loss: 0.863212  [19200/60000]\n",
            "loss: 0.761641  [25600/60000]\n",
            "loss: 0.768731  [32000/60000]\n",
            "loss: 0.852930  [38400/60000]\n",
            "loss: 0.813135  [44800/60000]\n",
            "loss: 0.834814  [51200/60000]\n",
            "loss: 0.786794  [57600/60000]\n",
            "\n",
            "Epoch 11\n",
            "loss: 0.787704  [    0/60000]\n",
            "loss: 0.866285  [ 6400/60000]\n",
            "loss: 0.641505  [12800/60000]\n",
            "loss: 0.834328  [19200/60000]\n",
            "loss: 0.737041  [25600/60000]\n",
            "loss: 0.738536  [32000/60000]\n",
            "loss: 0.825154  [38400/60000]\n",
            "loss: 0.793233  [44800/60000]\n",
            "loss: 0.808618  [51200/60000]\n",
            "loss: 0.763152  [57600/60000]\n",
            "\n",
            "Epoch 12\n",
            "loss: 0.751381  [    0/60000]\n",
            "loss: 0.836969  [ 6400/60000]\n",
            "loss: 0.610072  [12800/60000]\n",
            "loss: 0.810435  [19200/60000]\n",
            "loss: 0.716308  [25600/60000]\n",
            "loss: 0.713792  [32000/60000]\n",
            "loss: 0.800349  [38400/60000]\n",
            "loss: 0.776173  [44800/60000]\n",
            "loss: 0.786460  [51200/60000]\n",
            "loss: 0.742391  [57600/60000]\n",
            "\n",
            "Epoch 13\n",
            "loss: 0.719688  [    0/60000]\n",
            "loss: 0.810385  [ 6400/60000]\n",
            "loss: 0.582856  [12800/60000]\n",
            "loss: 0.790143  [19200/60000]\n",
            "loss: 0.698468  [25600/60000]\n",
            "loss: 0.693102  [32000/60000]\n",
            "loss: 0.777746  [38400/60000]\n",
            "loss: 0.760982  [44800/60000]\n",
            "loss: 0.767372  [51200/60000]\n",
            "loss: 0.723645  [57600/60000]\n",
            "\n",
            "Epoch 14\n",
            "loss: 0.691657  [    0/60000]\n",
            "loss: 0.786184  [ 6400/60000]\n",
            "loss: 0.559007  [12800/60000]\n",
            "loss: 0.772620  [19200/60000]\n",
            "loss: 0.682683  [25600/60000]\n",
            "loss: 0.675652  [32000/60000]\n",
            "loss: 0.756718  [38400/60000]\n",
            "loss: 0.747171  [44800/60000]\n",
            "loss: 0.750637  [51200/60000]\n",
            "loss: 0.706586  [57600/60000]\n",
            "\n",
            "Epoch 15\n",
            "loss: 0.666857  [    0/60000]\n",
            "loss: 0.763920  [ 6400/60000]\n",
            "loss: 0.537984  [12800/60000]\n",
            "loss: 0.757109  [19200/60000]\n",
            "loss: 0.668900  [25600/60000]\n",
            "loss: 0.660599  [32000/60000]\n",
            "loss: 0.737291  [38400/60000]\n",
            "loss: 0.734637  [44800/60000]\n",
            "loss: 0.735694  [51200/60000]\n",
            "loss: 0.690922  [57600/60000]\n",
            "\n",
            "Epoch 16\n",
            "loss: 0.644732  [    0/60000]\n",
            "loss: 0.743294  [ 6400/60000]\n",
            "loss: 0.519398  [12800/60000]\n",
            "loss: 0.742965  [19200/60000]\n",
            "loss: 0.656580  [25600/60000]\n",
            "loss: 0.647445  [32000/60000]\n",
            "loss: 0.719269  [38400/60000]\n",
            "loss: 0.723144  [44800/60000]\n",
            "loss: 0.722338  [51200/60000]\n",
            "loss: 0.676497  [57600/60000]\n",
            "\n",
            "Epoch 17\n",
            "loss: 0.625017  [    0/60000]\n",
            "loss: 0.724223  [ 6400/60000]\n",
            "loss: 0.502738  [12800/60000]\n",
            "loss: 0.729866  [19200/60000]\n",
            "loss: 0.645626  [25600/60000]\n",
            "loss: 0.635823  [32000/60000]\n",
            "loss: 0.702527  [38400/60000]\n",
            "loss: 0.712691  [44800/60000]\n",
            "loss: 0.710525  [51200/60000]\n",
            "loss: 0.663157  [57600/60000]\n",
            "\n",
            "Epoch 18\n",
            "loss: 0.607461  [    0/60000]\n",
            "loss: 0.706672  [ 6400/60000]\n",
            "loss: 0.487715  [12800/60000]\n",
            "loss: 0.717717  [19200/60000]\n",
            "loss: 0.635888  [25600/60000]\n",
            "loss: 0.625462  [32000/60000]\n",
            "loss: 0.686973  [38400/60000]\n",
            "loss: 0.703338  [44800/60000]\n",
            "loss: 0.699997  [51200/60000]\n",
            "loss: 0.650687  [57600/60000]\n",
            "\n",
            "Epoch 19\n",
            "loss: 0.591691  [    0/60000]\n",
            "loss: 0.690565  [ 6400/60000]\n",
            "loss: 0.474124  [12800/60000]\n",
            "loss: 0.706383  [19200/60000]\n",
            "loss: 0.627031  [25600/60000]\n",
            "loss: 0.616192  [32000/60000]\n",
            "loss: 0.672523  [38400/60000]\n",
            "loss: 0.695085  [44800/60000]\n",
            "loss: 0.690675  [51200/60000]\n",
            "loss: 0.638989  [57600/60000]\n",
            "\n",
            "Epoch 20\n",
            "loss: 0.577429  [    0/60000]\n",
            "loss: 0.675737  [ 6400/60000]\n",
            "loss: 0.461734  [12800/60000]\n",
            "loss: 0.695692  [19200/60000]\n",
            "loss: 0.619017  [25600/60000]\n",
            "loss: 0.607841  [32000/60000]\n",
            "loss: 0.659169  [38400/60000]\n",
            "loss: 0.687927  [44800/60000]\n",
            "loss: 0.682523  [51200/60000]\n",
            "loss: 0.627968  [57600/60000]\n",
            "\n",
            "Epoch 21\n",
            "loss: 0.564434  [    0/60000]\n",
            "loss: 0.662086  [ 6400/60000]\n",
            "loss: 0.450463  [12800/60000]\n",
            "loss: 0.685550  [19200/60000]\n",
            "loss: 0.611628  [25600/60000]\n",
            "loss: 0.600206  [32000/60000]\n",
            "loss: 0.646897  [38400/60000]\n",
            "loss: 0.681793  [44800/60000]\n",
            "loss: 0.675373  [51200/60000]\n",
            "loss: 0.617399  [57600/60000]\n",
            "\n",
            "Epoch 22\n",
            "loss: 0.552593  [    0/60000]\n",
            "loss: 0.649508  [ 6400/60000]\n",
            "loss: 0.440102  [12800/60000]\n",
            "loss: 0.675996  [19200/60000]\n",
            "loss: 0.604714  [25600/60000]\n",
            "loss: 0.593148  [32000/60000]\n",
            "loss: 0.635514  [38400/60000]\n",
            "loss: 0.676589  [44800/60000]\n",
            "loss: 0.669075  [51200/60000]\n",
            "loss: 0.607354  [57600/60000]\n",
            "\n",
            "Epoch 23\n",
            "loss: 0.541687  [    0/60000]\n",
            "loss: 0.637908  [ 6400/60000]\n",
            "loss: 0.430489  [12800/60000]\n",
            "loss: 0.666900  [19200/60000]\n",
            "loss: 0.598120  [25600/60000]\n",
            "loss: 0.586575  [32000/60000]\n",
            "loss: 0.624945  [38400/60000]\n",
            "loss: 0.672330  [44800/60000]\n",
            "loss: 0.663528  [51200/60000]\n",
            "loss: 0.597694  [57600/60000]\n",
            "\n",
            "Epoch 24\n",
            "loss: 0.531570  [    0/60000]\n",
            "loss: 0.627167  [ 6400/60000]\n",
            "loss: 0.421634  [12800/60000]\n",
            "loss: 0.658171  [19200/60000]\n",
            "loss: 0.591744  [25600/60000]\n",
            "loss: 0.580421  [32000/60000]\n",
            "loss: 0.615185  [38400/60000]\n",
            "loss: 0.668887  [44800/60000]\n",
            "loss: 0.658661  [51200/60000]\n",
            "loss: 0.588321  [57600/60000]\n",
            "\n",
            "Epoch 25\n",
            "loss: 0.522097  [    0/60000]\n",
            "loss: 0.617268  [ 6400/60000]\n",
            "loss: 0.413448  [12800/60000]\n",
            "loss: 0.649775  [19200/60000]\n",
            "loss: 0.585496  [25600/60000]\n",
            "loss: 0.574579  [32000/60000]\n",
            "loss: 0.606141  [38400/60000]\n",
            "loss: 0.666162  [44800/60000]\n",
            "loss: 0.654323  [51200/60000]\n",
            "loss: 0.579235  [57600/60000]\n",
            "\n",
            "Epoch 26\n",
            "loss: 0.513250  [    0/60000]\n",
            "loss: 0.608143  [ 6400/60000]\n",
            "loss: 0.405777  [12800/60000]\n",
            "loss: 0.641772  [19200/60000]\n",
            "loss: 0.579380  [25600/60000]\n",
            "loss: 0.569039  [32000/60000]\n",
            "loss: 0.597859  [38400/60000]\n",
            "loss: 0.664159  [44800/60000]\n",
            "loss: 0.650582  [51200/60000]\n",
            "loss: 0.570523  [57600/60000]\n",
            "\n",
            "Epoch 27\n",
            "loss: 0.504868  [    0/60000]\n",
            "loss: 0.599639  [ 6400/60000]\n",
            "loss: 0.398597  [12800/60000]\n",
            "loss: 0.634081  [19200/60000]\n",
            "loss: 0.573340  [25600/60000]\n",
            "loss: 0.563786  [32000/60000]\n",
            "loss: 0.590119  [38400/60000]\n",
            "loss: 0.662653  [44800/60000]\n",
            "loss: 0.647242  [51200/60000]\n",
            "loss: 0.561980  [57600/60000]\n",
            "\n",
            "Epoch 28\n",
            "loss: 0.496978  [    0/60000]\n",
            "loss: 0.591639  [ 6400/60000]\n",
            "loss: 0.391844  [12800/60000]\n",
            "loss: 0.626630  [19200/60000]\n",
            "loss: 0.567359  [25600/60000]\n",
            "loss: 0.558649  [32000/60000]\n",
            "loss: 0.582938  [38400/60000]\n",
            "loss: 0.661617  [44800/60000]\n",
            "loss: 0.644198  [51200/60000]\n",
            "loss: 0.553624  [57600/60000]\n",
            "\n",
            "Epoch 29\n",
            "loss: 0.489506  [    0/60000]\n",
            "loss: 0.584182  [ 6400/60000]\n",
            "loss: 0.385506  [12800/60000]\n",
            "loss: 0.619467  [19200/60000]\n",
            "loss: 0.561466  [25600/60000]\n",
            "loss: 0.553689  [32000/60000]\n",
            "loss: 0.576286  [38400/60000]\n",
            "loss: 0.660989  [44800/60000]\n",
            "loss: 0.641429  [51200/60000]\n",
            "loss: 0.545467  [57600/60000]\n",
            "\n",
            "Epoch 30\n",
            "loss: 0.482421  [    0/60000]\n",
            "loss: 0.577241  [ 6400/60000]\n",
            "loss: 0.379539  [12800/60000]\n",
            "loss: 0.612590  [19200/60000]\n",
            "loss: 0.555683  [25600/60000]\n",
            "loss: 0.548816  [32000/60000]\n",
            "loss: 0.570039  [38400/60000]\n",
            "loss: 0.660693  [44800/60000]\n",
            "loss: 0.638906  [51200/60000]\n",
            "loss: 0.537520  [57600/60000]\n",
            "\n",
            "Epoch 31\n",
            "loss: 0.475640  [    0/60000]\n",
            "loss: 0.570810  [ 6400/60000]\n",
            "loss: 0.373927  [12800/60000]\n",
            "loss: 0.605931  [19200/60000]\n",
            "loss: 0.550025  [25600/60000]\n",
            "loss: 0.543991  [32000/60000]\n",
            "loss: 0.564179  [38400/60000]\n",
            "loss: 0.660647  [44800/60000]\n",
            "loss: 0.636536  [51200/60000]\n",
            "loss: 0.529836  [57600/60000]\n",
            "\n",
            "Epoch 32\n",
            "loss: 0.469138  [    0/60000]\n",
            "loss: 0.564851  [ 6400/60000]\n",
            "loss: 0.368665  [12800/60000]\n",
            "loss: 0.599535  [19200/60000]\n",
            "loss: 0.544450  [25600/60000]\n",
            "loss: 0.539298  [32000/60000]\n",
            "loss: 0.558687  [38400/60000]\n",
            "loss: 0.660834  [44800/60000]\n",
            "loss: 0.634241  [51200/60000]\n",
            "loss: 0.522367  [57600/60000]\n",
            "\n",
            "Epoch 33\n",
            "loss: 0.462910  [    0/60000]\n",
            "loss: 0.559346  [ 6400/60000]\n",
            "loss: 0.363694  [12800/60000]\n",
            "loss: 0.593383  [19200/60000]\n",
            "loss: 0.538969  [25600/60000]\n",
            "loss: 0.534683  [32000/60000]\n",
            "loss: 0.553499  [38400/60000]\n",
            "loss: 0.661181  [44800/60000]\n",
            "loss: 0.632036  [51200/60000]\n",
            "loss: 0.515148  [57600/60000]\n",
            "\n",
            "Epoch 34\n",
            "loss: 0.456951  [    0/60000]\n",
            "loss: 0.554221  [ 6400/60000]\n",
            "loss: 0.358950  [12800/60000]\n",
            "loss: 0.587501  [19200/60000]\n",
            "loss: 0.533639  [25600/60000]\n",
            "loss: 0.530137  [32000/60000]\n",
            "loss: 0.548670  [38400/60000]\n",
            "loss: 0.661615  [44800/60000]\n",
            "loss: 0.629900  [51200/60000]\n",
            "loss: 0.508232  [57600/60000]\n",
            "\n",
            "Epoch 35\n",
            "loss: 0.451216  [    0/60000]\n",
            "loss: 0.549440  [ 6400/60000]\n",
            "loss: 0.354470  [12800/60000]\n",
            "loss: 0.581829  [19200/60000]\n",
            "loss: 0.528358  [25600/60000]\n",
            "loss: 0.525668  [32000/60000]\n",
            "loss: 0.544131  [38400/60000]\n",
            "loss: 0.662069  [44800/60000]\n",
            "loss: 0.627764  [51200/60000]\n",
            "loss: 0.501542  [57600/60000]\n",
            "\n",
            "Epoch 36\n",
            "loss: 0.445684  [    0/60000]\n",
            "loss: 0.545023  [ 6400/60000]\n",
            "loss: 0.350223  [12800/60000]\n",
            "loss: 0.576376  [19200/60000]\n",
            "loss: 0.523275  [25600/60000]\n",
            "loss: 0.521340  [32000/60000]\n",
            "loss: 0.539819  [38400/60000]\n",
            "loss: 0.662516  [44800/60000]\n",
            "loss: 0.625687  [51200/60000]\n",
            "loss: 0.495130  [57600/60000]\n",
            "\n",
            "Epoch 37\n",
            "loss: 0.440365  [    0/60000]\n",
            "loss: 0.540949  [ 6400/60000]\n",
            "loss: 0.346210  [12800/60000]\n",
            "loss: 0.571146  [19200/60000]\n",
            "loss: 0.518273  [25600/60000]\n",
            "loss: 0.517136  [32000/60000]\n",
            "loss: 0.535803  [38400/60000]\n",
            "loss: 0.662907  [44800/60000]\n",
            "loss: 0.623674  [51200/60000]\n",
            "loss: 0.489004  [57600/60000]\n",
            "\n",
            "Epoch 38\n",
            "loss: 0.435241  [    0/60000]\n",
            "loss: 0.537159  [ 6400/60000]\n",
            "loss: 0.342387  [12800/60000]\n",
            "loss: 0.566151  [19200/60000]\n",
            "loss: 0.513428  [25600/60000]\n",
            "loss: 0.512999  [32000/60000]\n",
            "loss: 0.531961  [38400/60000]\n",
            "loss: 0.663192  [44800/60000]\n",
            "loss: 0.621623  [51200/60000]\n",
            "loss: 0.483182  [57600/60000]\n",
            "\n",
            "Epoch 39\n",
            "loss: 0.430277  [    0/60000]\n",
            "loss: 0.533655  [ 6400/60000]\n",
            "loss: 0.338784  [12800/60000]\n",
            "loss: 0.561349  [19200/60000]\n",
            "loss: 0.508688  [25600/60000]\n",
            "loss: 0.508990  [32000/60000]\n",
            "loss: 0.528347  [38400/60000]\n",
            "loss: 0.663344  [44800/60000]\n",
            "loss: 0.619537  [51200/60000]\n",
            "loss: 0.477703  [57600/60000]\n",
            "\n",
            "Epoch 40\n",
            "loss: 0.425454  [    0/60000]\n",
            "loss: 0.530392  [ 6400/60000]\n",
            "loss: 0.335344  [12800/60000]\n",
            "loss: 0.556787  [19200/60000]\n",
            "loss: 0.504095  [25600/60000]\n",
            "loss: 0.505065  [32000/60000]\n",
            "loss: 0.524906  [38400/60000]\n",
            "loss: 0.663339  [44800/60000]\n",
            "loss: 0.617401  [51200/60000]\n",
            "loss: 0.472565  [57600/60000]\n",
            "\n",
            "Epoch 41\n",
            "loss: 0.420701  [    0/60000]\n",
            "loss: 0.527349  [ 6400/60000]\n",
            "loss: 0.332125  [12800/60000]\n",
            "loss: 0.552433  [19200/60000]\n",
            "loss: 0.499716  [25600/60000]\n",
            "loss: 0.501235  [32000/60000]\n",
            "loss: 0.521600  [38400/60000]\n",
            "loss: 0.663238  [44800/60000]\n",
            "loss: 0.615280  [51200/60000]\n",
            "loss: 0.467571  [57600/60000]\n",
            "\n",
            "Epoch 42\n",
            "loss: 0.416062  [    0/60000]\n",
            "loss: 0.524556  [ 6400/60000]\n",
            "loss: 0.329068  [12800/60000]\n",
            "loss: 0.548237  [19200/60000]\n",
            "loss: 0.495551  [25600/60000]\n",
            "loss: 0.497598  [32000/60000]\n",
            "loss: 0.518471  [38400/60000]\n",
            "loss: 0.662995  [44800/60000]\n",
            "loss: 0.613198  [51200/60000]\n",
            "loss: 0.462843  [57600/60000]\n",
            "\n",
            "Epoch 43\n",
            "loss: 0.411558  [    0/60000]\n",
            "loss: 0.521949  [ 6400/60000]\n",
            "loss: 0.326123  [12800/60000]\n",
            "loss: 0.544247  [19200/60000]\n",
            "loss: 0.491512  [25600/60000]\n",
            "loss: 0.494098  [32000/60000]\n",
            "loss: 0.515434  [38400/60000]\n",
            "loss: 0.662611  [44800/60000]\n",
            "loss: 0.611145  [51200/60000]\n",
            "loss: 0.458416  [57600/60000]\n",
            "\n",
            "Epoch 44\n",
            "loss: 0.407172  [    0/60000]\n",
            "loss: 0.519465  [ 6400/60000]\n",
            "loss: 0.323280  [12800/60000]\n",
            "loss: 0.540340  [19200/60000]\n",
            "loss: 0.487589  [25600/60000]\n",
            "loss: 0.490796  [32000/60000]\n",
            "loss: 0.512490  [38400/60000]\n",
            "loss: 0.662027  [44800/60000]\n",
            "loss: 0.609037  [51200/60000]\n",
            "loss: 0.454227  [57600/60000]\n",
            "\n",
            "Epoch 45\n",
            "loss: 0.402933  [    0/60000]\n",
            "loss: 0.517079  [ 6400/60000]\n",
            "loss: 0.320577  [12800/60000]\n",
            "loss: 0.536657  [19200/60000]\n",
            "loss: 0.483735  [25600/60000]\n",
            "loss: 0.487616  [32000/60000]\n",
            "loss: 0.509656  [38400/60000]\n",
            "loss: 0.661303  [44800/60000]\n",
            "loss: 0.606926  [51200/60000]\n",
            "loss: 0.450294  [57600/60000]\n",
            "\n",
            "Epoch 46\n",
            "loss: 0.398811  [    0/60000]\n",
            "loss: 0.514800  [ 6400/60000]\n",
            "loss: 0.317959  [12800/60000]\n",
            "loss: 0.533146  [19200/60000]\n",
            "loss: 0.479961  [25600/60000]\n",
            "loss: 0.484593  [32000/60000]\n",
            "loss: 0.506894  [38400/60000]\n",
            "loss: 0.660426  [44800/60000]\n",
            "loss: 0.604926  [51200/60000]\n",
            "loss: 0.446621  [57600/60000]\n",
            "\n",
            "Epoch 47\n",
            "loss: 0.394808  [    0/60000]\n",
            "loss: 0.512618  [ 6400/60000]\n",
            "loss: 0.315434  [12800/60000]\n",
            "loss: 0.529749  [19200/60000]\n",
            "loss: 0.476273  [25600/60000]\n",
            "loss: 0.481677  [32000/60000]\n",
            "loss: 0.504201  [38400/60000]\n",
            "loss: 0.659413  [44800/60000]\n",
            "loss: 0.602947  [51200/60000]\n",
            "loss: 0.443123  [57600/60000]\n",
            "\n",
            "Epoch 48\n",
            "loss: 0.390901  [    0/60000]\n",
            "loss: 0.510522  [ 6400/60000]\n",
            "loss: 0.312946  [12800/60000]\n",
            "loss: 0.526470  [19200/60000]\n",
            "loss: 0.472689  [25600/60000]\n",
            "loss: 0.478921  [32000/60000]\n",
            "loss: 0.501567  [38400/60000]\n",
            "loss: 0.658300  [44800/60000]\n",
            "loss: 0.600974  [51200/60000]\n",
            "loss: 0.439774  [57600/60000]\n",
            "\n",
            "Epoch 49\n",
            "loss: 0.387133  [    0/60000]\n",
            "loss: 0.508456  [ 6400/60000]\n",
            "loss: 0.310576  [12800/60000]\n",
            "loss: 0.523307  [19200/60000]\n",
            "loss: 0.469230  [25600/60000]\n",
            "loss: 0.476212  [32000/60000]\n",
            "loss: 0.499038  [38400/60000]\n",
            "loss: 0.657082  [44800/60000]\n",
            "loss: 0.599034  [51200/60000]\n",
            "loss: 0.436646  [57600/60000]\n",
            "\n",
            "Epoch 50\n",
            "loss: 0.383501  [    0/60000]\n",
            "loss: 0.506466  [ 6400/60000]\n",
            "loss: 0.308332  [12800/60000]\n",
            "loss: 0.520256  [19200/60000]\n",
            "loss: 0.465842  [25600/60000]\n",
            "loss: 0.473593  [32000/60000]\n",
            "loss: 0.496648  [38400/60000]\n",
            "loss: 0.655741  [44800/60000]\n",
            "loss: 0.597115  [51200/60000]\n",
            "loss: 0.433648  [57600/60000]\n",
            "\n",
            "Epoch 51\n",
            "loss: 0.379968  [    0/60000]\n",
            "loss: 0.504529  [ 6400/60000]\n",
            "loss: 0.306163  [12800/60000]\n",
            "loss: 0.517386  [19200/60000]\n",
            "loss: 0.462619  [25600/60000]\n",
            "loss: 0.471110  [32000/60000]\n",
            "loss: 0.494293  [38400/60000]\n",
            "loss: 0.654307  [44800/60000]\n",
            "loss: 0.595259  [51200/60000]\n",
            "loss: 0.430834  [57600/60000]\n",
            "\n",
            "Epoch 52\n",
            "loss: 0.376530  [    0/60000]\n",
            "loss: 0.502681  [ 6400/60000]\n",
            "loss: 0.304041  [12800/60000]\n",
            "loss: 0.514629  [19200/60000]\n",
            "loss: 0.459493  [25600/60000]\n",
            "loss: 0.468645  [32000/60000]\n",
            "loss: 0.491970  [38400/60000]\n",
            "loss: 0.652877  [44800/60000]\n",
            "loss: 0.593507  [51200/60000]\n",
            "loss: 0.428230  [57600/60000]\n",
            "\n",
            "Epoch 53\n",
            "loss: 0.373142  [    0/60000]\n",
            "loss: 0.500946  [ 6400/60000]\n",
            "loss: 0.301995  [12800/60000]\n",
            "loss: 0.512026  [19200/60000]\n",
            "loss: 0.456476  [25600/60000]\n",
            "loss: 0.466281  [32000/60000]\n",
            "loss: 0.489677  [38400/60000]\n",
            "loss: 0.651399  [44800/60000]\n",
            "loss: 0.591757  [51200/60000]\n",
            "loss: 0.425777  [57600/60000]\n",
            "\n",
            "Epoch 54\n",
            "loss: 0.369820  [    0/60000]\n",
            "loss: 0.499254  [ 6400/60000]\n",
            "loss: 0.300036  [12800/60000]\n",
            "loss: 0.509538  [19200/60000]\n",
            "loss: 0.453506  [25600/60000]\n",
            "loss: 0.463956  [32000/60000]\n",
            "loss: 0.487459  [38400/60000]\n",
            "loss: 0.649874  [44800/60000]\n",
            "loss: 0.590024  [51200/60000]\n",
            "loss: 0.423500  [57600/60000]\n",
            "\n",
            "Epoch 55\n",
            "loss: 0.366586  [    0/60000]\n",
            "loss: 0.497582  [ 6400/60000]\n",
            "loss: 0.298136  [12800/60000]\n",
            "loss: 0.507197  [19200/60000]\n",
            "loss: 0.450680  [25600/60000]\n",
            "loss: 0.461740  [32000/60000]\n",
            "loss: 0.485279  [38400/60000]\n",
            "loss: 0.648333  [44800/60000]\n",
            "loss: 0.588290  [51200/60000]\n",
            "loss: 0.421354  [57600/60000]\n",
            "\n",
            "Epoch 56\n",
            "loss: 0.363464  [    0/60000]\n",
            "loss: 0.495953  [ 6400/60000]\n",
            "loss: 0.296302  [12800/60000]\n",
            "loss: 0.504940  [19200/60000]\n",
            "loss: 0.447913  [25600/60000]\n",
            "loss: 0.459577  [32000/60000]\n",
            "loss: 0.483218  [38400/60000]\n",
            "loss: 0.646743  [44800/60000]\n",
            "loss: 0.586571  [51200/60000]\n",
            "loss: 0.419274  [57600/60000]\n",
            "\n",
            "Epoch 57\n",
            "loss: 0.360385  [    0/60000]\n",
            "loss: 0.494329  [ 6400/60000]\n",
            "loss: 0.294542  [12800/60000]\n",
            "loss: 0.502800  [19200/60000]\n",
            "loss: 0.445216  [25600/60000]\n",
            "loss: 0.457521  [32000/60000]\n",
            "loss: 0.481218  [38400/60000]\n",
            "loss: 0.645119  [44800/60000]\n",
            "loss: 0.584844  [51200/60000]\n",
            "loss: 0.417328  [57600/60000]\n",
            "\n",
            "Epoch 58\n",
            "loss: 0.357356  [    0/60000]\n",
            "loss: 0.492761  [ 6400/60000]\n",
            "loss: 0.292810  [12800/60000]\n",
            "loss: 0.500745  [19200/60000]\n",
            "loss: 0.442570  [25600/60000]\n",
            "loss: 0.455540  [32000/60000]\n",
            "loss: 0.479258  [38400/60000]\n",
            "loss: 0.643487  [44800/60000]\n",
            "loss: 0.583203  [51200/60000]\n",
            "loss: 0.415478  [57600/60000]\n",
            "\n",
            "Epoch 59\n",
            "loss: 0.354401  [    0/60000]\n",
            "loss: 0.491185  [ 6400/60000]\n",
            "loss: 0.291145  [12800/60000]\n",
            "loss: 0.498786  [19200/60000]\n",
            "loss: 0.439992  [25600/60000]\n",
            "loss: 0.453647  [32000/60000]\n",
            "loss: 0.477341  [38400/60000]\n",
            "loss: 0.641850  [44800/60000]\n",
            "loss: 0.581584  [51200/60000]\n",
            "loss: 0.413724  [57600/60000]\n",
            "\n",
            "Epoch 60\n",
            "loss: 0.351471  [    0/60000]\n",
            "loss: 0.489629  [ 6400/60000]\n",
            "loss: 0.289512  [12800/60000]\n",
            "loss: 0.496885  [19200/60000]\n",
            "loss: 0.437431  [25600/60000]\n",
            "loss: 0.451894  [32000/60000]\n",
            "loss: 0.475460  [38400/60000]\n",
            "loss: 0.640227  [44800/60000]\n",
            "loss: 0.580028  [51200/60000]\n",
            "loss: 0.412021  [57600/60000]\n",
            "\n",
            "Epoch 61\n",
            "loss: 0.348611  [    0/60000]\n",
            "loss: 0.488069  [ 6400/60000]\n",
            "loss: 0.287884  [12800/60000]\n",
            "loss: 0.495040  [19200/60000]\n",
            "loss: 0.434945  [25600/60000]\n",
            "loss: 0.450173  [32000/60000]\n",
            "loss: 0.473600  [38400/60000]\n",
            "loss: 0.638593  [44800/60000]\n",
            "loss: 0.578444  [51200/60000]\n",
            "loss: 0.410391  [57600/60000]\n",
            "\n",
            "Epoch 62\n",
            "loss: 0.345842  [    0/60000]\n",
            "loss: 0.486543  [ 6400/60000]\n",
            "loss: 0.286329  [12800/60000]\n",
            "loss: 0.493255  [19200/60000]\n",
            "loss: 0.432520  [25600/60000]\n",
            "loss: 0.448527  [32000/60000]\n",
            "loss: 0.471757  [38400/60000]\n",
            "loss: 0.636922  [44800/60000]\n",
            "loss: 0.576917  [51200/60000]\n",
            "loss: 0.408908  [57600/60000]\n",
            "\n",
            "Epoch 63\n",
            "loss: 0.343123  [    0/60000]\n",
            "loss: 0.485032  [ 6400/60000]\n",
            "loss: 0.284831  [12800/60000]\n",
            "loss: 0.491479  [19200/60000]\n",
            "loss: 0.430127  [25600/60000]\n",
            "loss: 0.446976  [32000/60000]\n",
            "loss: 0.469989  [38400/60000]\n",
            "loss: 0.635266  [44800/60000]\n",
            "loss: 0.575355  [51200/60000]\n",
            "loss: 0.407462  [57600/60000]\n",
            "\n",
            "Epoch 64\n",
            "loss: 0.340486  [    0/60000]\n",
            "loss: 0.483571  [ 6400/60000]\n",
            "loss: 0.283343  [12800/60000]\n",
            "loss: 0.489730  [19200/60000]\n",
            "loss: 0.427734  [25600/60000]\n",
            "loss: 0.445502  [32000/60000]\n",
            "loss: 0.468266  [38400/60000]\n",
            "loss: 0.633543  [44800/60000]\n",
            "loss: 0.573775  [51200/60000]\n",
            "loss: 0.406169  [57600/60000]\n",
            "\n",
            "Epoch 65\n",
            "loss: 0.337908  [    0/60000]\n",
            "loss: 0.482158  [ 6400/60000]\n",
            "loss: 0.281894  [12800/60000]\n",
            "loss: 0.488013  [19200/60000]\n",
            "loss: 0.425409  [25600/60000]\n",
            "loss: 0.444121  [32000/60000]\n",
            "loss: 0.466564  [38400/60000]\n",
            "loss: 0.631840  [44800/60000]\n",
            "loss: 0.572223  [51200/60000]\n",
            "loss: 0.404912  [57600/60000]\n",
            "\n",
            "Epoch 66\n",
            "loss: 0.335463  [    0/60000]\n",
            "loss: 0.480751  [ 6400/60000]\n",
            "loss: 0.280499  [12800/60000]\n",
            "loss: 0.486344  [19200/60000]\n",
            "loss: 0.423072  [25600/60000]\n",
            "loss: 0.442694  [32000/60000]\n",
            "loss: 0.464904  [38400/60000]\n",
            "loss: 0.630273  [44800/60000]\n",
            "loss: 0.570798  [51200/60000]\n",
            "loss: 0.403635  [57600/60000]\n",
            "\n",
            "Epoch 67\n",
            "loss: 0.333041  [    0/60000]\n",
            "loss: 0.479317  [ 6400/60000]\n",
            "loss: 0.279159  [12800/60000]\n",
            "loss: 0.484788  [19200/60000]\n",
            "loss: 0.420772  [25600/60000]\n",
            "loss: 0.441238  [32000/60000]\n",
            "loss: 0.463299  [38400/60000]\n",
            "loss: 0.628717  [44800/60000]\n",
            "loss: 0.569424  [51200/60000]\n",
            "loss: 0.402380  [57600/60000]\n",
            "\n",
            "Epoch 68\n",
            "loss: 0.330686  [    0/60000]\n",
            "loss: 0.477848  [ 6400/60000]\n",
            "loss: 0.277889  [12800/60000]\n",
            "loss: 0.483318  [19200/60000]\n",
            "loss: 0.418543  [25600/60000]\n",
            "loss: 0.439811  [32000/60000]\n",
            "loss: 0.461761  [38400/60000]\n",
            "loss: 0.627158  [44800/60000]\n",
            "loss: 0.568075  [51200/60000]\n",
            "loss: 0.401140  [57600/60000]\n",
            "\n",
            "Epoch 69\n",
            "loss: 0.328405  [    0/60000]\n",
            "loss: 0.476349  [ 6400/60000]\n",
            "loss: 0.276666  [12800/60000]\n",
            "loss: 0.481874  [19200/60000]\n",
            "loss: 0.416357  [25600/60000]\n",
            "loss: 0.438379  [32000/60000]\n",
            "loss: 0.460249  [38400/60000]\n",
            "loss: 0.625558  [44800/60000]\n",
            "loss: 0.566705  [51200/60000]\n",
            "loss: 0.399970  [57600/60000]\n",
            "\n",
            "Epoch 70\n",
            "loss: 0.326176  [    0/60000]\n",
            "loss: 0.474890  [ 6400/60000]\n",
            "loss: 0.275499  [12800/60000]\n",
            "loss: 0.480453  [19200/60000]\n",
            "loss: 0.414221  [25600/60000]\n",
            "loss: 0.436997  [32000/60000]\n",
            "loss: 0.458765  [38400/60000]\n",
            "loss: 0.623935  [44800/60000]\n",
            "loss: 0.565359  [51200/60000]\n",
            "loss: 0.398877  [57600/60000]\n",
            "\n",
            "Epoch 71\n",
            "loss: 0.324021  [    0/60000]\n",
            "loss: 0.473405  [ 6400/60000]\n",
            "loss: 0.274365  [12800/60000]\n",
            "loss: 0.479068  [19200/60000]\n",
            "loss: 0.412138  [25600/60000]\n",
            "loss: 0.435657  [32000/60000]\n",
            "loss: 0.457277  [38400/60000]\n",
            "loss: 0.622331  [44800/60000]\n",
            "loss: 0.563980  [51200/60000]\n",
            "loss: 0.397857  [57600/60000]\n",
            "\n",
            "Epoch 72\n",
            "loss: 0.321893  [    0/60000]\n",
            "loss: 0.471942  [ 6400/60000]\n",
            "loss: 0.273240  [12800/60000]\n",
            "loss: 0.477716  [19200/60000]\n",
            "loss: 0.410126  [25600/60000]\n",
            "loss: 0.434374  [32000/60000]\n",
            "loss: 0.455774  [38400/60000]\n",
            "loss: 0.620763  [44800/60000]\n",
            "loss: 0.562604  [51200/60000]\n",
            "loss: 0.396809  [57600/60000]\n",
            "\n",
            "Epoch 73\n",
            "loss: 0.319820  [    0/60000]\n",
            "loss: 0.470488  [ 6400/60000]\n",
            "loss: 0.272160  [12800/60000]\n",
            "loss: 0.476402  [19200/60000]\n",
            "loss: 0.408058  [25600/60000]\n",
            "loss: 0.433132  [32000/60000]\n",
            "loss: 0.454293  [38400/60000]\n",
            "loss: 0.619206  [44800/60000]\n",
            "loss: 0.561322  [51200/60000]\n",
            "loss: 0.395748  [57600/60000]\n",
            "\n",
            "Epoch 74\n",
            "loss: 0.317827  [    0/60000]\n",
            "loss: 0.469071  [ 6400/60000]\n",
            "loss: 0.271058  [12800/60000]\n",
            "loss: 0.475085  [19200/60000]\n",
            "loss: 0.405892  [25600/60000]\n",
            "loss: 0.431962  [32000/60000]\n",
            "loss: 0.452899  [38400/60000]\n",
            "loss: 0.617615  [44800/60000]\n",
            "loss: 0.559985  [51200/60000]\n",
            "loss: 0.394731  [57600/60000]\n",
            "\n",
            "Epoch 75\n",
            "loss: 0.315884  [    0/60000]\n",
            "loss: 0.467682  [ 6400/60000]\n",
            "loss: 0.270014  [12800/60000]\n",
            "loss: 0.473789  [19200/60000]\n",
            "loss: 0.403774  [25600/60000]\n",
            "loss: 0.430775  [32000/60000]\n",
            "loss: 0.451518  [38400/60000]\n",
            "loss: 0.616067  [44800/60000]\n",
            "loss: 0.558734  [51200/60000]\n",
            "loss: 0.393734  [57600/60000]\n",
            "\n",
            "Epoch 76\n",
            "loss: 0.313982  [    0/60000]\n",
            "loss: 0.466235  [ 6400/60000]\n",
            "loss: 0.268990  [12800/60000]\n",
            "loss: 0.472526  [19200/60000]\n",
            "loss: 0.401744  [25600/60000]\n",
            "loss: 0.429689  [32000/60000]\n",
            "loss: 0.450134  [38400/60000]\n",
            "loss: 0.614578  [44800/60000]\n",
            "loss: 0.557612  [51200/60000]\n",
            "loss: 0.392801  [57600/60000]\n",
            "\n",
            "Epoch 77\n",
            "loss: 0.312090  [    0/60000]\n",
            "loss: 0.464739  [ 6400/60000]\n",
            "loss: 0.267991  [12800/60000]\n",
            "loss: 0.471293  [19200/60000]\n",
            "loss: 0.399796  [25600/60000]\n",
            "loss: 0.428638  [32000/60000]\n",
            "loss: 0.448770  [38400/60000]\n",
            "loss: 0.613141  [44800/60000]\n",
            "loss: 0.556409  [51200/60000]\n",
            "loss: 0.391947  [57600/60000]\n",
            "\n",
            "Epoch 78\n",
            "loss: 0.310280  [    0/60000]\n",
            "loss: 0.463258  [ 6400/60000]\n",
            "loss: 0.267044  [12800/60000]\n",
            "loss: 0.470039  [19200/60000]\n",
            "loss: 0.397910  [25600/60000]\n",
            "loss: 0.427523  [32000/60000]\n",
            "loss: 0.447548  [38400/60000]\n",
            "loss: 0.611689  [44800/60000]\n",
            "loss: 0.555209  [51200/60000]\n",
            "loss: 0.391078  [57600/60000]\n",
            "\n",
            "Epoch 79\n",
            "loss: 0.308553  [    0/60000]\n",
            "loss: 0.461762  [ 6400/60000]\n",
            "loss: 0.266053  [12800/60000]\n",
            "loss: 0.468811  [19200/60000]\n",
            "loss: 0.396032  [25600/60000]\n",
            "loss: 0.426427  [32000/60000]\n",
            "loss: 0.446206  [38400/60000]\n",
            "loss: 0.610270  [44800/60000]\n",
            "loss: 0.553942  [51200/60000]\n",
            "loss: 0.390277  [57600/60000]\n",
            "\n",
            "Epoch 80\n",
            "loss: 0.306829  [    0/60000]\n",
            "loss: 0.460327  [ 6400/60000]\n",
            "loss: 0.265120  [12800/60000]\n",
            "loss: 0.467587  [19200/60000]\n",
            "loss: 0.394242  [25600/60000]\n",
            "loss: 0.425284  [32000/60000]\n",
            "loss: 0.444867  [38400/60000]\n",
            "loss: 0.608815  [44800/60000]\n",
            "loss: 0.552713  [51200/60000]\n",
            "loss: 0.389562  [57600/60000]\n",
            "\n",
            "Epoch 81\n",
            "loss: 0.305137  [    0/60000]\n",
            "loss: 0.458945  [ 6400/60000]\n",
            "loss: 0.264217  [12800/60000]\n",
            "loss: 0.466379  [19200/60000]\n",
            "loss: 0.392484  [25600/60000]\n",
            "loss: 0.424143  [32000/60000]\n",
            "loss: 0.443475  [38400/60000]\n",
            "loss: 0.607381  [44800/60000]\n",
            "loss: 0.551498  [51200/60000]\n",
            "loss: 0.388840  [57600/60000]\n",
            "\n",
            "Epoch 82\n",
            "loss: 0.303469  [    0/60000]\n",
            "loss: 0.457571  [ 6400/60000]\n",
            "loss: 0.263341  [12800/60000]\n",
            "loss: 0.465202  [19200/60000]\n",
            "loss: 0.390716  [25600/60000]\n",
            "loss: 0.422969  [32000/60000]\n",
            "loss: 0.442124  [38400/60000]\n",
            "loss: 0.605952  [44800/60000]\n",
            "loss: 0.550288  [51200/60000]\n",
            "loss: 0.388186  [57600/60000]\n",
            "\n",
            "Epoch 83\n",
            "loss: 0.301902  [    0/60000]\n",
            "loss: 0.456208  [ 6400/60000]\n",
            "loss: 0.262501  [12800/60000]\n",
            "loss: 0.464009  [19200/60000]\n",
            "loss: 0.388936  [25600/60000]\n",
            "loss: 0.421742  [32000/60000]\n",
            "loss: 0.440815  [38400/60000]\n",
            "loss: 0.604560  [44800/60000]\n",
            "loss: 0.549126  [51200/60000]\n",
            "loss: 0.387555  [57600/60000]\n",
            "\n",
            "Epoch 84\n",
            "loss: 0.300323  [    0/60000]\n",
            "loss: 0.454861  [ 6400/60000]\n",
            "loss: 0.261676  [12800/60000]\n",
            "loss: 0.462802  [19200/60000]\n",
            "loss: 0.387200  [25600/60000]\n",
            "loss: 0.420635  [32000/60000]\n",
            "loss: 0.439488  [38400/60000]\n",
            "loss: 0.603064  [44800/60000]\n",
            "loss: 0.547962  [51200/60000]\n",
            "loss: 0.386946  [57600/60000]\n",
            "\n",
            "Epoch 85\n",
            "loss: 0.298782  [    0/60000]\n",
            "loss: 0.453508  [ 6400/60000]\n",
            "loss: 0.260909  [12800/60000]\n",
            "loss: 0.461601  [19200/60000]\n",
            "loss: 0.385510  [25600/60000]\n",
            "loss: 0.419497  [32000/60000]\n",
            "loss: 0.438196  [38400/60000]\n",
            "loss: 0.601610  [44800/60000]\n",
            "loss: 0.546766  [51200/60000]\n",
            "loss: 0.386331  [57600/60000]\n",
            "\n",
            "Epoch 86\n",
            "loss: 0.297303  [    0/60000]\n",
            "loss: 0.452131  [ 6400/60000]\n",
            "loss: 0.260159  [12800/60000]\n",
            "loss: 0.460409  [19200/60000]\n",
            "loss: 0.383821  [25600/60000]\n",
            "loss: 0.418346  [32000/60000]\n",
            "loss: 0.436943  [38400/60000]\n",
            "loss: 0.600215  [44800/60000]\n",
            "loss: 0.545615  [51200/60000]\n",
            "loss: 0.385729  [57600/60000]\n",
            "\n",
            "Epoch 87\n",
            "loss: 0.295873  [    0/60000]\n",
            "loss: 0.450783  [ 6400/60000]\n",
            "loss: 0.259397  [12800/60000]\n",
            "loss: 0.459190  [19200/60000]\n",
            "loss: 0.382221  [25600/60000]\n",
            "loss: 0.417277  [32000/60000]\n",
            "loss: 0.435709  [38400/60000]\n",
            "loss: 0.598784  [44800/60000]\n",
            "loss: 0.544470  [51200/60000]\n",
            "loss: 0.385138  [57600/60000]\n",
            "\n",
            "Epoch 88\n",
            "loss: 0.294517  [    0/60000]\n",
            "loss: 0.449410  [ 6400/60000]\n",
            "loss: 0.258732  [12800/60000]\n",
            "loss: 0.457912  [19200/60000]\n",
            "loss: 0.380587  [25600/60000]\n",
            "loss: 0.416198  [32000/60000]\n",
            "loss: 0.434516  [38400/60000]\n",
            "loss: 0.597320  [44800/60000]\n",
            "loss: 0.543255  [51200/60000]\n",
            "loss: 0.384580  [57600/60000]\n",
            "\n",
            "Epoch 89\n",
            "loss: 0.293208  [    0/60000]\n",
            "loss: 0.448079  [ 6400/60000]\n",
            "loss: 0.258125  [12800/60000]\n",
            "loss: 0.456645  [19200/60000]\n",
            "loss: 0.378906  [25600/60000]\n",
            "loss: 0.415076  [32000/60000]\n",
            "loss: 0.433343  [38400/60000]\n",
            "loss: 0.595948  [44800/60000]\n",
            "loss: 0.542059  [51200/60000]\n",
            "loss: 0.384037  [57600/60000]\n",
            "\n",
            "Epoch 90\n",
            "loss: 0.291966  [    0/60000]\n",
            "loss: 0.446619  [ 6400/60000]\n",
            "loss: 0.257500  [12800/60000]\n",
            "loss: 0.455403  [19200/60000]\n",
            "loss: 0.377290  [25600/60000]\n",
            "loss: 0.413945  [32000/60000]\n",
            "loss: 0.432165  [38400/60000]\n",
            "loss: 0.594573  [44800/60000]\n",
            "loss: 0.540885  [51200/60000]\n",
            "loss: 0.383466  [57600/60000]\n",
            "\n",
            "Epoch 91\n",
            "loss: 0.290727  [    0/60000]\n",
            "loss: 0.445198  [ 6400/60000]\n",
            "loss: 0.256903  [12800/60000]\n",
            "loss: 0.454216  [19200/60000]\n",
            "loss: 0.375753  [25600/60000]\n",
            "loss: 0.412775  [32000/60000]\n",
            "loss: 0.431006  [38400/60000]\n",
            "loss: 0.593242  [44800/60000]\n",
            "loss: 0.539737  [51200/60000]\n",
            "loss: 0.382868  [57600/60000]\n",
            "\n",
            "Epoch 92\n",
            "loss: 0.289602  [    0/60000]\n",
            "loss: 0.443835  [ 6400/60000]\n",
            "loss: 0.256342  [12800/60000]\n",
            "loss: 0.453032  [19200/60000]\n",
            "loss: 0.374241  [25600/60000]\n",
            "loss: 0.411633  [32000/60000]\n",
            "loss: 0.429844  [38400/60000]\n",
            "loss: 0.591917  [44800/60000]\n",
            "loss: 0.538646  [51200/60000]\n",
            "loss: 0.382254  [57600/60000]\n",
            "\n",
            "Epoch 93\n",
            "loss: 0.288536  [    0/60000]\n",
            "loss: 0.442472  [ 6400/60000]\n",
            "loss: 0.255816  [12800/60000]\n",
            "loss: 0.451813  [19200/60000]\n",
            "loss: 0.372734  [25600/60000]\n",
            "loss: 0.410497  [32000/60000]\n",
            "loss: 0.428701  [38400/60000]\n",
            "loss: 0.590591  [44800/60000]\n",
            "loss: 0.537611  [51200/60000]\n",
            "loss: 0.381681  [57600/60000]\n",
            "\n",
            "Epoch 94\n",
            "loss: 0.287427  [    0/60000]\n",
            "loss: 0.441156  [ 6400/60000]\n",
            "loss: 0.255246  [12800/60000]\n",
            "loss: 0.450656  [19200/60000]\n",
            "loss: 0.371210  [25600/60000]\n",
            "loss: 0.409369  [32000/60000]\n",
            "loss: 0.427603  [38400/60000]\n",
            "loss: 0.589313  [44800/60000]\n",
            "loss: 0.536532  [51200/60000]\n",
            "loss: 0.381129  [57600/60000]\n",
            "\n",
            "Epoch 95\n",
            "loss: 0.286340  [    0/60000]\n",
            "loss: 0.439854  [ 6400/60000]\n",
            "loss: 0.254617  [12800/60000]\n",
            "loss: 0.449515  [19200/60000]\n",
            "loss: 0.369697  [25600/60000]\n",
            "loss: 0.408309  [32000/60000]\n",
            "loss: 0.426511  [38400/60000]\n",
            "loss: 0.588056  [44800/60000]\n",
            "loss: 0.535429  [51200/60000]\n",
            "loss: 0.380593  [57600/60000]\n",
            "\n",
            "Epoch 96\n",
            "loss: 0.285285  [    0/60000]\n",
            "loss: 0.438553  [ 6400/60000]\n",
            "loss: 0.254036  [12800/60000]\n",
            "loss: 0.448372  [19200/60000]\n",
            "loss: 0.368247  [25600/60000]\n",
            "loss: 0.407173  [32000/60000]\n",
            "loss: 0.425346  [38400/60000]\n",
            "loss: 0.586809  [44800/60000]\n",
            "loss: 0.534320  [51200/60000]\n",
            "loss: 0.380051  [57600/60000]\n",
            "\n",
            "Epoch 97\n",
            "loss: 0.284211  [    0/60000]\n",
            "loss: 0.437305  [ 6400/60000]\n",
            "loss: 0.253434  [12800/60000]\n",
            "loss: 0.447187  [19200/60000]\n",
            "loss: 0.366818  [25600/60000]\n",
            "loss: 0.406055  [32000/60000]\n",
            "loss: 0.424160  [38400/60000]\n",
            "loss: 0.585606  [44800/60000]\n",
            "loss: 0.533194  [51200/60000]\n",
            "loss: 0.379502  [57600/60000]\n",
            "\n",
            "Epoch 98\n",
            "loss: 0.283103  [    0/60000]\n",
            "loss: 0.436076  [ 6400/60000]\n",
            "loss: 0.252847  [12800/60000]\n",
            "loss: 0.446008  [19200/60000]\n",
            "loss: 0.365399  [25600/60000]\n",
            "loss: 0.404999  [32000/60000]\n",
            "loss: 0.423023  [38400/60000]\n",
            "loss: 0.584401  [44800/60000]\n",
            "loss: 0.532054  [51200/60000]\n",
            "loss: 0.378952  [57600/60000]\n",
            "\n",
            "Epoch 99\n",
            "loss: 0.282026  [    0/60000]\n",
            "loss: 0.434856  [ 6400/60000]\n",
            "loss: 0.252334  [12800/60000]\n",
            "loss: 0.444862  [19200/60000]\n",
            "loss: 0.364067  [25600/60000]\n",
            "loss: 0.403955  [32000/60000]\n",
            "loss: 0.421872  [38400/60000]\n",
            "loss: 0.583187  [44800/60000]\n",
            "loss: 0.530918  [51200/60000]\n",
            "loss: 0.378455  [57600/60000]\n",
            "\n",
            "Epoch 100\n",
            "loss: 0.281005  [    0/60000]\n",
            "loss: 0.433625  [ 6400/60000]\n",
            "loss: 0.251841  [12800/60000]\n",
            "loss: 0.443702  [19200/60000]\n",
            "loss: 0.362768  [25600/60000]\n",
            "loss: 0.402883  [32000/60000]\n",
            "loss: 0.420732  [38400/60000]\n",
            "loss: 0.582043  [44800/60000]\n",
            "loss: 0.529774  [51200/60000]\n",
            "loss: 0.377949  [57600/60000]\n",
            "Final test:\n",
            "Test Error: \n",
            " Accuracy: 84.5%, Avg loss: 0.436048 \n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "learning_rates = [1, 0.1, 0.01, 0.001]\n",
        "loss_history = {}\n",
        "\n",
        "def training_code(learning_rate, epochs=100):\n",
        "  print(f\"\\nTraining with learning rate: {learning_rate}\\n\")\n",
        "  \n",
        "  model = NeuralNetwork().to(device)\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "  \n",
        "  epoch_losses = []\n",
        "  \n",
        "  for t in range(epochs):\n",
        "    print(f\"\\nEpoch {t + 1}\")\n",
        "    average_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
        "    epoch_losses.append(average_loss)\n",
        "    \n",
        "  print(f\"Final test:\")\n",
        "  test(test_dataloader, model, loss_fn)\n",
        "  \n",
        "  return epoch_losses\n",
        "\n",
        "for rate in learning_rates:\n",
        "  losses = training_code(rate)\n",
        "  loss_history[rate] = losses\n",
        "  \n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "for learning_rate, losses in loss_history.items():\n",
        "  plt.plot(losses, label=f\"learning rate: {learning_rate}\")\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.title(\"loss curves\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "### Q1.4 (2 points) \n",
        "\n",
        "Compare the results in table 1 and table 2, what is your observation and your understanding of learning rate?\n",
        "\n",
        "\n",
        "### Q1.5 (5 points) \n",
        "\n",
        "Build a wider network by modifying the code that constructs the network so that the hidden layer(s) contain more perceptrons, and record the accuracy along with the number of trainable parameters in your model.  Now modify the original network to be deeper instead of wider (i.e. by adding more hidden layers). Record your accuracy and network size findings. Plot the loss curve for each experiment. Also plot the test accuracy and loss for both the wider and deeper architectures and discuss what you observe. Write down your conclusions about changing the network structure?  \n",
        "\n",
        "|Structures|Accuracy|Parameters|\n",
        "|---|---|---|\n",
        "|Base   |      ||\n",
        "|Deeper|          ||\n",
        "|Wider|         ||\n",
        "\n",
        "\n",
        "### Q1.6 (2 points) \n",
        "\n",
        "Calculate the mean of the gradients of the loss to all trainable parameters. Plot the gradients curve for the first 100 training steps. What are your observations? Note that this gradients will be saved with the training weight automatically after you call loss.backwards(). Hint: the mean of the gradients decrease.\n",
        "\n",
        "For more explanation of q1.7, you could refer to the following simple instructions: https://colab.research.google.com/drive/1XAsyNegGSvMf3_B6MrsXht7-fHqtJ7OW?usp=sharing\n",
        "\n",
        "### Q1.7 (5 points) \n",
        "\n",
        "Modify the network structure and training/test to use a small convolutional neural network instead of an MLP. Discuss your findings with regard to convergence, accuracy and number of parameters, relative to MLPs.  \n",
        "\n",
        "Hint: Look at the structure of the CNN in the Workshop 3 examples.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Q2 Optional Bonus Question  (5 points, upto 20% bonus marks of the assignment) \n",
        "\n",
        "Experiment with different activation functions (ReLU, Tanh, Sigmoid) and analyse their impact on training performance.(2 points) \n",
        "\n",
        "In particular, focus your analysis on the Sigmoid activation function and discuss your finding of training with and without Xavier initialization. You may use the provided code for Xavier initialisation for this. (1 points)\n",
        "\n",
        "Additionally, plot both the gradient and loss curves for your experiments. For gradient analysis, you may select one representative layer to monitor throughout training and briefly explain your choice. (1 points)\n",
        "\n",
        "Discuss how gradients and loss behave across the network for different activation functions and initialisation methods if you see any difference. (1 points) \n",
        "\n",
        "Note: the bonus marks wont replace marks for Q3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S16_96RS3O1H"
      },
      "source": [
        "# Question 3: Proposal for Practical Applications (40%)\n",
        "\n",
        "In this part of the assignment you need to write a report about an application of a computer vision algorithm or technique. This can either be an application that you are aware of and possibly even use, such as a phone app, or it could be speculation -- an application that you think would benefit from using computer vision.\n",
        "\n",
        "Begin by choosing a particular CV idea, method or problem area, such as:\n",
        "\n",
        "a. removing noise in an image\n",
        "\n",
        "b. increasing the resolution of an image\n",
        "\n",
        "c. detecting and/or identifying objects in an image\n",
        "\n",
        "d. segmenting images into constituents parts\n",
        "\n",
        "e. estimating the depth of an object from one or more images\n",
        "\n",
        "f. estimating the motion of two objects in different frames\n",
        "\n",
        "g. others\n",
        "\n",
        "Now think about various ways your chosen technique could be used. Here is a list of possible applications you could consider, but you are not restricted to this list, and there will be credit given for sensible invention outside this list (but no penalty if you don't want to be \"inventive\"): image editing systems in your phone; enhancement of images from old film; obstacle detection and avoidance for a domestic robot; facial recognition for phone security; cancer detection; person tracking and re-identification in security cameras; sport decision review systems; road-sign detection and interpretation for self-driving cars.\n",
        "\n",
        "This is a little bit back-to-front from what might happen in real life in which the application usually motivates the solution, but the emphasis here is on an understanding of the CV technique.\n",
        "\n",
        "You need to write a short report (800 words max) in which you do the following:\n",
        "1. Clearly define the CV problem/area and describe its application scenarios\n",
        "2. Briefly describe a solution based on image processing, computer vision and/or machine learning.\n",
        "3. Discuss the advantages and the limitations of this method in various application scenarios.\n",
        "4. It is important that you will define a useful metric to evaluate the performance of your method and discuss its tradeoff specific to the problem you have chosen.\n",
        "5. You are welcome to cite existing work and take inspiration form literature addressing the problem you choose.\n",
        "\n",
        "Hint1: Submit an individual pdf report for question 2.\n",
        "\n",
        "Hint2: Organise your report well\n",
        "\n",
        "Hint3: You can use diagrams, flow charts or other figures in your report for better understanding of your solution.  \n",
        "\n",
        "** For Q3, you do not need to implement your solution; just write the proposal/report and submit it as a separate PDF **\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The tutorial style code starts here, reuse parts as you like  while writing your report #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-sqkIpLjpVsh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # This is for mathematical operations\n",
        "\n",
        "# this is used in plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pylab as pl\n",
        "from IPython import display\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%reload_ext autoreload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1wy3xhEx_x-1"
      },
      "outputs": [],
      "source": [
        "#### Tutorial Code\n",
        "####PyTorch has two primitives to work with data: torch.utils.data.DataLoader and torch.utils.data.Dataset.\n",
        "#####Dataset stores samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset.\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Download training data from open datasets.\n",
        "##Every TorchVision Dataset includes two arguments:\n",
        "##transform and target_transform to modify the samples and labels respectively.\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNI4IusI_1ol"
      },
      "source": [
        "We pass the Dataset as an argument to DataLoader. This wraps an iterable over our dataset and supports automatic batching, sampling, shuffling, and multiprocess data loading. Here we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "nQZ5l5Zs_4C3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L1vl5rC52Un"
      },
      "source": [
        "Add in a code cell to inspect the training data, as per Q1.1. Each element of the training_data structure has a grayscale image (which you can use plt.imshow(img[0,:,:]) to display, just like you did in previous assignments.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "KpEhLSHg4Idw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Code cell for training image display\n",
        "image, label = training_data[0]\n",
        "\n",
        "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "plt.title(f\"label= {label}\")\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMtCU2LO_9Dk"
      },
      "source": [
        "To define a neural network in PyTorch, we create a class that inherits from nn.Module. We define the layers of the network in the init function and specify how data will pass through the network in the forward function. To accelerate operations in the neural network, we move it to the GPU if available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "TRSp7pd3_6bS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "       )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "nYAnKhOfABZr"
      },
      "outputs": [],
      "source": [
        "###Define the loss function and the optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFZYEHY7ADvS"
      },
      "source": [
        "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model’s parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "L741B0uXAFrf"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "A44xKKnjAINf"
      },
      "outputs": [],
      "source": [
        "##Define a test function\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "mJLACDm9AKxv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.307877  [    0/60000]\n",
            "loss: 2.288219  [ 6400/60000]\n",
            "loss: 2.270025  [12800/60000]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[34], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     test(test_dataloader, model, loss_fn)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[32], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 13\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Train and test the model\n",
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now we will apply xavier initialization to the model\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.330892  [    0/60000]\n",
            "loss: 2.144923  [ 6400/60000]\n",
            "loss: 1.905170  [12800/60000]\n",
            "loss: 1.854086  [19200/60000]\n",
            "loss: 1.617811  [25600/60000]\n",
            "loss: 1.484017  [32000/60000]\n",
            "loss: 1.479886  [38400/60000]\n",
            "loss: 1.331084  [44800/60000]\n",
            "loss: 1.323606  [51200/60000]\n",
            "loss: 1.206293  [57600/60000]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     test(test_dataloader, model, loss_fn)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[14], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      5\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Compute prediction error\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py:143\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    139\u001b[0m img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index])\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Lets apply the xavier initialization to the model\n",
        "model.apply(init_weights)\n",
        "\n",
        "# Now we will train and test the model again with the xavier initialization\n",
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
